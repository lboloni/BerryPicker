{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1aae1a",
   "metadata": {},
   "source": [
    "# Verify behavior cloning\n",
    "\n",
    "Visually verify a behavior cloning based robot controller.\n",
    "\n",
    "* Load the controller trained by the Train_BC notebook and the corresponding sp\n",
    "* Choose a demonstration, to which the SP/BC pair will be applied to the images\n",
    "* Visualize the path taken by the demonstration and what would be (autoregressively) recommended by the controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab463743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Loading pointer config file:\n",
      "\t/Users/lboloni/.config/BerryPicker/mainsettings.yaml\n",
      "***ExpRun**: Loading machine-specific config file:\n",
      "\t/Users/lboloni/Google Drive/My Drive/LotziStudy/Code/PackageTracking/BerryPicker/settings/settings-szenes.yaml\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from bc_factory import create_bc_model\n",
    "# FIXME: factor this out\n",
    "from bc_LSTM_MDN import bc_LSTM_MDN, mdn_loss\n",
    "\n",
    "torch.manual_seed(1)\n",
    "from sensorprocessing.sp_helper import get_transform_to_sp\n",
    "from sensorprocessing.sp_factory import create_sp\n",
    "from demonstration.demonstration import Demonstration\n",
    "\n",
    "from robot.al5d_position_controller import RobotPosition\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9184821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Configuration for exp/run: behavior_cloning/bc_verify_lstm_mdn_00 successfully loaded\n",
      "Experiment:\n",
      "    batch_size: 64\n",
      "    control_size: 6\n",
      "    data_dir: /Users/lboloni/Documents/Develop/Data/BerryPicker/behavior_cloning/bc_verify_lstm_mdn_00\n",
      "    epochs: 10\n",
      "    exp_bc: behavior_cloning\n",
      "    exp_robot: robot_al5d\n",
      "    exp_run_sys_indep_file: /Users/lboloni/Documents/Develop/Github/BerryPicker/BerryPicker/src/experiment_configs/behavior_cloning/bc_verify_lstm_mdn_00.yaml\n",
      "    exp_sp: sensorprocessing_conv_vae\n",
      "    experiment_name: behavior_cloning\n",
      "    loss: MSELoss\n",
      "    optimizer: Adam\n",
      "    optimizer_lr: 0.001\n",
      "    run_bc: bc_lstm_mdn_00\n",
      "    run_name: bc_verify_lstm_mdn_00\n",
      "    run_robot: position_controller_00\n",
      "    run_sp: sp_vae_256\n",
      "    sequence_length: 10\n",
      "    subrun_name: null\n",
      "    training_data:\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_15_53'\n",
      "      - dev2\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_16_57'\n",
      "      - dev2\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_19_12'\n",
      "      - dev2\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_21_28'\n",
      "      - dev2\n",
      "    validation_data:\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_23_19'\n",
      "      - dev2\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_24_52'\n",
      "      - dev2\n",
      "    verification_data:\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_21_28'\n",
      "      - dev2\n",
      "\n",
      "***ExpRun**: Configuration for exp/run: sensorprocessing_conv_vae/sp_vae_256 successfully loaded\n",
      "Warning: logging configuration file is not found in logger/logger_config.json.\n",
      "***ExpRun**: Configuration for exp/run: robot_al5d/position_controller_00 successfully loaded\n",
      "***ExpRun**: Configuration for exp/run: behavior_cloning/bc_lstm_mdn_00 successfully loaded\n",
      "***ExpRun**: Configuration for exp/run: behavior_cloning/mdn_for_bc_00 successfully loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = \"behavior_cloning\"\n",
    "# run = \"bc_verify_mlp_00\"\n",
    "# run = \"bc_verify_lstm_00\"\n",
    "# run = \"bc_verify_lstm_resid_00\"\n",
    "run = \"bc_verify_lstm_mdn_00\"\n",
    "\n",
    "exp = Config().get_experiment(experiment, run)\n",
    "pprint.pprint(exp)\n",
    "\n",
    "# Create the sp object described in the experiment\n",
    "exp_sp = Config().get_experiment(exp[\"exp_sp\"], exp[\"run_sp\"])\n",
    "sp = create_sp(exp_sp, device)\n",
    "transform = get_transform_to_sp(exp_sp)\n",
    "\n",
    "exp_robot = Config().get_experiment(exp[\"exp_robot\"], exp[\"run_robot\"])\n",
    "\n",
    "# Load the bc model described in the experiment\n",
    "exp_bc = Config().get_experiment(exp[\"exp_bc\"], exp[\"run_bc\"])\n",
    "model, _, _ = create_bc_model(exp_bc, exp_sp, device)\n",
    "model_path = pathlib.Path(exp_bc.data_dir(), exp_bc[\"controller_file\"])\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f22d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Experiment default config /Users/lboloni/Documents/Develop/Github/BerryPicker/BerryPicker/src/experiment_configs/demonstration/_defaults_demonstration.yaml was empty, ok.\n",
      "***ExpRun**: Configuration for exp/run: demonstration/random-both-cameras-video successfully loaded\n",
      "reading 0 successful\n",
      "reading 1 successful\n",
      "reading 2 successful\n",
      "reading 3 successful\n",
      "reading 4 successful\n",
      "reading 5 successful\n",
      "reading 6 successful\n",
      "reading 7 successful\n",
      "reading 8 successful\n",
      "reading 9 successful\n",
      "reading 1 successful\n",
      "reading 2 successful\n",
      "reading 3 successful\n",
      "reading 4 successful\n",
      "reading 5 successful\n",
      "reading 6 successful\n",
      "reading 7 successful\n",
      "reading 8 successful\n",
      "reading 9 successful\n",
      "reading 10 successful\n",
      "reading 2 successful\n",
      "reading 3 successful\n",
      "reading 4 successful\n",
      "reading 5 successful\n",
      "reading 6 successful\n",
      "reading 7 successful\n",
      "reading 8 successful\n",
      "reading 9 successful\n",
      "reading 10 successful\n",
      "reading 11 successful\n",
      "reading 3 successful\n",
      "reading 4 successful\n",
      "reading 5 successful\n",
      "reading 6 successful\n",
      "reading 7 successful\n",
      "reading 8 successful\n",
      "reading 9 successful\n",
      "reading 10 successful\n",
      "reading 11 successful\n",
      "reading 12 successful\n",
      "reading 4 successful\n",
      "reading 5 successful\n",
      "reading 6 successful\n",
      "reading 7 successful\n",
      "reading 8 successful\n",
      "reading 9 successful\n",
      "reading 10 successful\n",
      "reading 11 successful\n",
      "reading 12 successful\n",
      "reading 13 successful\n",
      "reading 5 successful\n",
      "reading 6 successful\n",
      "reading 7 successful\n",
      "reading 8 successful\n",
      "reading 9 successful\n",
      "reading 10 successful\n",
      "reading 11 successful\n",
      "reading 12 successful\n",
      "reading 13 successful\n",
      "reading 14 successful\n",
      "reading 6 successful\n",
      "reading 7 successful\n",
      "reading 8 successful\n",
      "reading 9 successful\n",
      "reading 10 successful\n",
      "reading 11 successful\n",
      "reading 12 successful\n",
      "reading 13 successful\n",
      "reading 14 successful\n",
      "reading 15 successful\n",
      "reading 7 successful\n",
      "reading 8 successful\n",
      "reading 9 successful\n",
      "reading 10 successful\n",
      "reading 11 successful\n",
      "reading 12 successful\n",
      "reading 13 successful\n",
      "reading 14 successful\n",
      "reading 15 successful\n",
      "reading 16 successful\n",
      "reading 8 successful\n",
      "reading 9 successful\n",
      "reading 10 successful\n",
      "reading 11 successful\n",
      "reading 12 successful\n",
      "reading 13 successful\n",
      "reading 14 successful\n",
      "reading 15 successful\n",
      "reading 16 successful\n",
      "reading 17 successful\n",
      "reading 9 successful\n",
      "reading 10 successful\n",
      "reading 11 successful\n",
      "reading 12 successful\n",
      "reading 13 successful\n",
      "reading 14 successful\n",
      "reading 15 successful\n",
      "reading 16 successful\n",
      "reading 17 successful\n",
      "reading 18 successful\n",
      "reading 10 successful\n",
      "reading 11 successful\n",
      "reading 12 successful\n",
      "reading 13 successful\n",
      "reading 14 successful\n",
      "reading 15 successful\n",
      "reading 16 successful\n",
      "reading 17 successful\n",
      "reading 18 successful\n",
      "reading 19 successful\n",
      "reading 11 successful\n",
      "reading 12 successful\n",
      "reading 13 successful\n",
      "reading 14 successful\n",
      "reading 15 successful\n",
      "reading 16 successful\n",
      "reading 17 successful\n",
      "reading 18 successful\n",
      "reading 19 successful\n",
      "reading 20 successful\n",
      "reading 12 successful\n",
      "reading 13 successful\n",
      "reading 14 successful\n",
      "reading 15 successful\n",
      "reading 16 successful\n",
      "reading 17 successful\n",
      "reading 18 successful\n",
      "reading 19 successful\n",
      "reading 20 successful\n",
      "reading 21 successful\n",
      "reading 13 successful\n",
      "reading 14 successful\n",
      "reading 15 successful\n",
      "reading 16 successful\n",
      "reading 17 successful\n",
      "reading 18 successful\n",
      "reading 19 successful\n",
      "reading 20 successful\n",
      "reading 21 successful\n",
      "reading 22 successful\n",
      "reading 14 successful\n",
      "reading 15 successful\n",
      "reading 16 successful\n",
      "reading 17 successful\n",
      "reading 18 successful\n",
      "reading 19 successful\n",
      "reading 20 successful\n",
      "reading 21 successful\n",
      "reading 22 successful\n",
      "reading 23 successful\n",
      "reading 15 successful\n",
      "reading 16 successful\n",
      "reading 17 successful\n",
      "reading 18 successful\n",
      "reading 19 successful\n",
      "reading 20 successful\n",
      "reading 21 successful\n",
      "reading 22 successful\n",
      "reading 23 successful\n",
      "reading 24 successful\n",
      "reading 16 successful\n",
      "reading 17 successful\n",
      "reading 18 successful\n",
      "reading 19 successful\n",
      "reading 20 successful\n",
      "reading 21 successful\n",
      "reading 22 successful\n",
      "reading 23 successful\n",
      "reading 24 successful\n",
      "reading 25 successful\n",
      "reading 17 successful\n",
      "reading 18 successful\n",
      "reading 19 successful\n",
      "reading 20 successful\n",
      "reading 21 successful\n",
      "reading 22 successful\n",
      "reading 23 successful\n",
      "reading 24 successful\n",
      "reading 25 successful\n",
      "reading 26 successful\n",
      "reading 18 successful\n",
      "reading 19 successful\n",
      "reading 20 successful\n",
      "reading 21 successful\n",
      "reading 22 successful\n",
      "reading 23 successful\n",
      "reading 24 successful\n",
      "reading 25 successful\n",
      "reading 26 successful\n",
      "reading 27 successful\n",
      "reading 19 successful\n",
      "reading 20 successful\n",
      "reading 21 successful\n",
      "reading 22 successful\n",
      "reading 23 successful\n",
      "reading 24 successful\n",
      "reading 25 successful\n",
      "reading 26 successful\n",
      "reading 27 successful\n",
      "reading 28 successful\n",
      "reading 20 successful\n",
      "reading 21 successful\n",
      "reading 22 successful\n",
      "reading 23 successful\n",
      "reading 24 successful\n",
      "reading 25 successful\n",
      "reading 26 successful\n",
      "reading 27 successful\n",
      "reading 28 successful\n",
      "reading 29 successful\n",
      "reading 21 successful\n",
      "reading 22 successful\n",
      "reading 23 successful\n",
      "reading 24 successful\n",
      "reading 25 successful\n",
      "reading 26 successful\n",
      "reading 27 successful\n",
      "reading 28 successful\n",
      "reading 29 successful\n",
      "reading 30 successful\n",
      "reading 22 successful\n",
      "reading 23 successful\n",
      "reading 24 successful\n",
      "reading 25 successful\n",
      "reading 26 successful\n",
      "reading 27 successful\n",
      "reading 28 successful\n",
      "reading 29 successful\n",
      "reading 30 successful\n",
      "reading 31 successful\n",
      "reading 23 successful\n",
      "reading 24 successful\n",
      "reading 25 successful\n",
      "reading 26 successful\n",
      "reading 27 successful\n",
      "reading 28 successful\n",
      "reading 29 successful\n",
      "reading 30 successful\n",
      "reading 31 successful\n",
      "reading 32 successful\n",
      "reading 24 successful\n",
      "reading 25 successful\n",
      "reading 26 successful\n",
      "reading 27 successful\n",
      "reading 28 successful\n",
      "reading 29 successful\n",
      "reading 30 successful\n",
      "reading 31 successful\n",
      "reading 32 successful\n",
      "reading 33 successful\n",
      "reading 25 successful\n",
      "reading 26 successful\n",
      "reading 27 successful\n",
      "reading 28 successful\n",
      "reading 29 successful\n",
      "reading 30 successful\n",
      "reading 31 successful\n",
      "reading 32 successful\n",
      "reading 33 successful\n",
      "reading 34 successful\n",
      "reading 26 successful\n",
      "reading 27 successful\n",
      "reading 28 successful\n",
      "reading 29 successful\n",
      "reading 30 successful\n",
      "reading 31 successful\n",
      "reading 32 successful\n",
      "reading 33 successful\n",
      "reading 34 successful\n",
      "reading 35 successful\n",
      "reading 27 successful\n",
      "reading 28 successful\n",
      "reading 29 successful\n",
      "reading 30 successful\n",
      "reading 31 successful\n",
      "reading 32 successful\n",
      "reading 33 successful\n",
      "reading 34 successful\n",
      "reading 35 successful\n",
      "reading 36 successful\n",
      "reading 28 successful\n",
      "reading 29 successful\n",
      "reading 30 successful\n",
      "reading 31 successful\n",
      "reading 32 successful\n",
      "reading 33 successful\n",
      "reading 34 successful\n",
      "reading 35 successful\n",
      "reading 36 successful\n",
      "reading 37 successful\n",
      "reading 29 successful\n",
      "reading 30 successful\n",
      "reading 31 successful\n",
      "reading 32 successful\n",
      "reading 33 successful\n",
      "reading 34 successful\n",
      "reading 35 successful\n",
      "reading 36 successful\n",
      "reading 37 successful\n",
      "reading 38 successful\n",
      "reading 30 successful\n",
      "reading 31 successful\n",
      "reading 32 successful\n",
      "reading 33 successful\n",
      "reading 34 successful\n",
      "reading 35 successful\n",
      "reading 36 successful\n",
      "reading 37 successful\n",
      "reading 38 successful\n",
      "reading 39 successful\n",
      "reading 31 successful\n",
      "reading 32 successful\n",
      "reading 33 successful\n",
      "reading 34 successful\n",
      "reading 35 successful\n",
      "reading 36 successful\n",
      "reading 37 successful\n",
      "reading 38 successful\n",
      "reading 39 successful\n",
      "reading 40 successful\n",
      "reading 32 successful\n",
      "reading 33 successful\n",
      "reading 34 successful\n",
      "reading 35 successful\n",
      "reading 36 successful\n",
      "reading 37 successful\n",
      "reading 38 successful\n",
      "reading 39 successful\n",
      "reading 40 successful\n",
      "reading 41 successful\n",
      "reading 33 successful\n",
      "reading 34 successful\n",
      "reading 35 successful\n",
      "reading 36 successful\n",
      "reading 37 successful\n",
      "reading 38 successful\n",
      "reading 39 successful\n",
      "reading 40 successful\n",
      "reading 41 successful\n",
      "reading 42 successful\n",
      "reading 34 successful\n",
      "reading 35 successful\n",
      "reading 36 successful\n",
      "reading 37 successful\n",
      "reading 38 successful\n",
      "reading 39 successful\n",
      "reading 40 successful\n",
      "reading 41 successful\n",
      "reading 42 successful\n",
      "reading 43 successful\n",
      "reading 35 successful\n",
      "reading 36 successful\n",
      "reading 37 successful\n",
      "reading 38 successful\n",
      "reading 39 successful\n",
      "reading 40 successful\n",
      "reading 41 successful\n",
      "reading 42 successful\n",
      "reading 43 successful\n",
      "reading 44 successful\n",
      "reading 36 successful\n",
      "reading 37 successful\n",
      "reading 38 successful\n",
      "reading 39 successful\n",
      "reading 40 successful\n",
      "reading 41 successful\n",
      "reading 42 successful\n",
      "reading 43 successful\n",
      "reading 44 successful\n",
      "reading 45 successful\n",
      "reading 37 successful\n",
      "reading 38 successful\n",
      "reading 39 successful\n",
      "reading 40 successful\n",
      "reading 41 successful\n",
      "reading 42 successful\n",
      "reading 43 successful\n",
      "reading 44 successful\n",
      "reading 45 successful\n",
      "reading 46 successful\n",
      "reading 38 successful\n",
      "reading 39 successful\n",
      "reading 40 successful\n",
      "reading 41 successful\n",
      "reading 42 successful\n",
      "reading 43 successful\n",
      "reading 44 successful\n",
      "reading 45 successful\n",
      "reading 46 successful\n",
      "reading 47 successful\n",
      "reading 39 successful\n",
      "reading 40 successful\n",
      "reading 41 successful\n",
      "reading 42 successful\n",
      "reading 43 successful\n",
      "reading 44 successful\n",
      "reading 45 successful\n",
      "reading 46 successful\n",
      "reading 47 successful\n",
      "reading 48 successful\n",
      "reading 40 successful\n",
      "reading 41 successful\n",
      "reading 42 successful\n",
      "reading 43 successful\n",
      "reading 44 successful\n",
      "reading 45 successful\n",
      "reading 46 successful\n",
      "reading 47 successful\n",
      "reading 48 successful\n",
      "reading 49 successful\n",
      "reading 41 successful\n",
      "reading 42 successful\n",
      "reading 43 successful\n",
      "reading 44 successful\n",
      "reading 45 successful\n",
      "reading 46 successful\n",
      "reading 47 successful\n",
      "reading 48 successful\n",
      "reading 49 successful\n",
      "reading 50 successful\n",
      "reading 42 successful\n",
      "reading 43 successful\n",
      "reading 44 successful\n",
      "reading 45 successful\n",
      "reading 46 successful\n",
      "reading 47 successful\n",
      "reading 48 successful\n",
      "reading 49 successful\n",
      "reading 50 successful\n",
      "reading 51 successful\n",
      "reading 43 successful\n",
      "reading 44 successful\n",
      "reading 45 successful\n",
      "reading 46 successful\n",
      "reading 47 successful\n",
      "reading 48 successful\n",
      "reading 49 successful\n",
      "reading 50 successful\n",
      "reading 51 successful\n",
      "reading 52 successful\n",
      "reading 44 successful\n",
      "reading 45 successful\n",
      "reading 46 successful\n",
      "reading 47 successful\n",
      "reading 48 successful\n",
      "reading 49 successful\n",
      "reading 50 successful\n",
      "reading 51 successful\n",
      "reading 52 successful\n",
      "reading 53 successful\n",
      "reading 45 successful\n",
      "reading 46 successful\n",
      "reading 47 successful\n",
      "reading 48 successful\n",
      "reading 49 successful\n",
      "reading 50 successful\n",
      "reading 51 successful\n",
      "reading 52 successful\n",
      "reading 53 successful\n",
      "reading 54 successful\n",
      "reading 46 successful\n",
      "reading 47 successful\n",
      "reading 48 successful\n",
      "reading 49 successful\n",
      "reading 50 successful\n",
      "reading 51 successful\n",
      "reading 52 successful\n",
      "reading 53 successful\n",
      "reading 54 successful\n",
      "reading 55 successful\n",
      "reading 47 successful\n",
      "reading 48 successful\n",
      "reading 49 successful\n",
      "reading 50 successful\n",
      "reading 51 successful\n",
      "reading 52 successful\n",
      "reading 53 successful\n",
      "reading 54 successful\n",
      "reading 55 successful\n",
      "reading 56 successful\n",
      "reading 48 successful\n",
      "reading 49 successful\n",
      "reading 50 successful\n",
      "reading 51 successful\n",
      "reading 52 successful\n",
      "reading 53 successful\n",
      "reading 54 successful\n",
      "reading 55 successful\n",
      "reading 56 successful\n",
      "reading 57 successful\n",
      "Could not read frame 49\n",
      "reading 49 not successful, returned none\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not successful, returned none\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43msensor_readings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m input_list\u001b[38;5;241m.\u001b[39mappend(z)\n\u001b[1;32m     28\u001b[0m input_nd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(input_list)\n",
      "File \u001b[0;32m~/Documents/Develop/Github/BerryPicker/BerryPicker/src/behavior_cloning/../sensorprocessing/sp_conv_vae.py:72\u001b[0m, in \u001b[0;36mConvVaeSensorProcessing.process\u001b[0;34m(self, sensor_readings)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Process a sensor readings object - in this case it must be an image prepared into a batch by load_image_to_tensor or load_capture_to_tensor. \u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03mReturns the z encoding in the form of a numpy array.\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 72\u001b[0m     output, mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msensor_readings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m mus \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(mu)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mus\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Develop/Github/Conv-VAE-PyTorch/Conv-VAE-PyTorch/model/model.py:237\u001b[0m, in \u001b[0;36mVanillaVAE.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(z), mu, log_var, log_det\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m      mu, log_var, z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m      \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(z), mu, log_var\n",
      "File \u001b[0;32m~/Documents/Develop/Github/Conv-VAE-PyTorch/Conv-VAE-PyTorch/model/model.py:171\u001b[0m, in \u001b[0;36mVanillaVAE.encode\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tensor]:\n\u001b[1;32m    160\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m    Encodes the input by passing through the convolutional network\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    and outputs the latent variables.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m        mu (Tensor) and log_var (Tensor) of latent variables\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(result, start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# Split the result into mu and var components\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# of the latent Gaussian distribution\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n"
     ]
    }
   ],
   "source": [
    "pred_path = pathlib.Path(exp.data_dir(), \"pred.npy\")\n",
    "real_path = pathlib.Path(exp.data_dir(), \"real.npy\")\n",
    "\n",
    "if pred_path.exists():\n",
    "    a_pred_np = np.load(pred_path)\n",
    "    a_real_np = np.load(real_path)\n",
    "    print(f\"Paths successfully loaded from\\n{pred_path.relative_to(pathlib.Path.home())}\")\n",
    "else:\n",
    "    a_real_list = []\n",
    "    a_pred_list = []\n",
    "    with torch.no_grad(): # disable gradient computation\n",
    "        for val in exp[\"verification_data\"]: # for all demonstrations\n",
    "            run, demo_name, camera = val\n",
    "            exp_demo = Config().get_experiment(\"demonstration\", run)\n",
    "            demo = Demonstration(exp_demo, demo_name)\n",
    "            for i in range(demo.metadata[\"maxsteps\"]-exp_bc[\"sequence_length\"]): # -1 because of lookahead\n",
    "                if exp_bc[\"sequence_length\"]:\n",
    "                    input_list = []\n",
    "                    # FIXME make it sliding window\n",
    "                    for j in range(exp_bc[\"sequence_length\"]):\n",
    "                        sensor_readings, _ = demo.get_image(i+j, device=device, transform=transform, camera=camera)\n",
    "                        if sensor_readings is not None:\n",
    "                            print(f\"reading {i+j} successful\")\n",
    "                        else:\n",
    "                            print(f\"reading {i+j} not successful, returned none\")\n",
    "                        z = sp.process(sensor_readings)\n",
    "                        input_list.append(z)\n",
    "                        input_nd = np.array(input_list)\n",
    "                        z_tensor = torch.tensor(input_nd).unsqueeze(0).to(device)\n",
    "                else:\n",
    "                    sensor_readings, _ = demo.get_image(i, device=device, transform=transform, camera=camera)\n",
    "                    z = sp.process(sensor_readings)\n",
    "                    z_tensor = torch.tensor(z).unsqueeze(0).to(device)\n",
    "                if not isinstance(model, bc_LSTM_MDN):                \n",
    "                    a_pred = model(z_tensor)\n",
    "                else:\n",
    "                    a_pred = model.forward_and_sample(z_tensor)\n",
    "                a_pred_list.append(a_pred.to(\"cpu\").squeeze(0))\n",
    "                a = demo.get_action(i)\n",
    "                rp = RobotPosition.from_vector(exp_robot, a)\n",
    "                a_real = rp.to_normalized_vector(exp_robot)            \n",
    "                a_real_list.append(a_real)\n",
    "    a_pred_np = np.array(a_pred_list)\n",
    "    a_real_np = np.array(a_real_list)\n",
    "\n",
    "    # save the comparison terms\n",
    "    np.save(pred_path, a_pred_np)\n",
    "    np.save(real_path, a_real_np)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b02810",
   "metadata": {},
   "source": [
    "## Plot the differences between the a_real and a_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6f570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axs = plt.subplots(2,3, figsize=(8, 6))\n",
    "titles = [\"height\",\"distance\", \"heading\", \"wrist_angle\", \"wrist_rotation\", \"gripper\"]\n",
    "for i in range(exp_bc[\"control_size\"]):\n",
    "    ax = axs[i//3, i%3]\n",
    "    #ax.set_ylim(0, 1.4)\n",
    "    ax.plot(a_real_np[:,i], label=\"ground truth\")\n",
    "    ax.plot(a_pred_np[:,i], label=exp_bc[\"name\"])\n",
    "    if i==0:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, ncol=2,\n",
    "            bbox_to_anchor=(0.5, 0), loc=\"upper center\")\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "graphfilename = pathlib.Path(exp.data_dir(), \"bccomparison.pdf\")\n",
    "plt.savefig(graphfilename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2789e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_real_np.shape\n",
    "a_real_np[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff6d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pred_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e051ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5750c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
