{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1aae1a",
   "metadata": {},
   "source": [
    "# Verify behavior cloning\n",
    "\n",
    "Visually verify a behavior cloning based robot controller.\n",
    "\n",
    "* Load the controller trained by the Train_BC notebook and the corresponding sp\n",
    "* Choose a demonstration, to which the SP/BC pair will be applied to the images\n",
    "* Visualize the path taken by the demonstration and what would be (autoregressively) recommended by the controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab463743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2032.0_x64__qbz5n2kfra8p0\\Lib\\pathlib\\__init__.py\n",
      "***ExpRun**: Loading pointer config file:\n",
      "\tC:\\Users\\lotzi\\.config\\BerryPicker\\mainsettings.yaml\n",
      "***ExpRun**: Loading machine-specific config file:\n",
      "\tc:\\Users\\lotzi\\Work\\_Config\\BerryPicker\\cfg\\settings.yaml\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from bc_factory import create_bc_model\n",
    "# FIXME: factor this out\n",
    "from bc_LSTM_MDN import bc_LSTM_MDN, mdn_loss\n",
    "\n",
    "torch.manual_seed(1)\n",
    "from sensorprocessing.sp_helper import get_transform_to_sp\n",
    "from sensorprocessing.sp_factory import create_sp\n",
    "from demonstration.demonstration import Demonstration\n",
    "\n",
    "from robot.al5d_position_controller import RobotPosition\n",
    "import bc_factory \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9184821",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# *** Initialize the variables with default values \n",
    "# *** This cell should be tagged as parameters     \n",
    "# *** If papermill is used, some of the values will be overwritten \n",
    "\n",
    "# If it is set to true, the exprun will be recreated from scratch\n",
    "creation_style = \"exist-ok\"\n",
    "\n",
    "# If not None, set an external experiment path\n",
    "external_path = None\n",
    "# If not None, set an output path\n",
    "data_path = None\n",
    "\n",
    "experiment = \"behavior_cloning\"\n",
    "# run = \"bc_verify_mlp_00\"\n",
    "# run = \"bc_verify_lstm_00\"\n",
    "# run = \"bc_verify_lstm_resid_00\"\n",
    "run = \"bc_verify_lstm_mdn_00\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if external_path:\n",
    "    external_path = pathlib.Path(external_path)\n",
    "    assert external_path.exists()\n",
    "    Config().set_experiment_path(external_path)\n",
    "    Config().copy_experiment(\"sensorprocessing_conv_vae\")\n",
    "    Config().copy_experiment(\"robot_al5d\")\n",
    "    Config().copy_experiment(\"demonstration\")\n",
    "    Config().copy_experiment(\"behavior_cloning\")\n",
    "if data_path:\n",
    "    data_path = pathlib.Path(data_path)\n",
    "    assert data_path.exists()\n",
    "    Config().set_experiment_data(data_path)\n",
    "    \n",
    "# temporary solution\n",
    "# Setting up a separate directory for generated and computed data\n",
    "\n",
    "exp = Config().get_experiment(experiment, run)\n",
    "pprint.pprint(exp)\n",
    "\n",
    "# Create the sp object described in the experiment\n",
    "exp_sp = Config().get_experiment(exp[\"exp_sp\"], exp[\"run_sp\"])\n",
    "sp = create_sp(exp_sp, device)\n",
    "transform = get_transform_to_sp(exp_sp)\n",
    "\n",
    "exp_robot = Config().get_experiment(exp[\"exp_robot\"], exp[\"run_robot\"])\n",
    "\n",
    "# Load the bc model described in the experiment\n",
    "exp_bc = Config().get_experiment(exp[\"exp_bc\"], exp[\"run_bc\"])\n",
    "model, _, _ = create_bc_model(exp_bc, exp_sp, device)\n",
    "model_path = pathlib.Path(exp_bc.data_dir(), exp_bc[\"controller_file\"])\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f22d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = pathlib.Path(exp.data_dir(), \"pred.npy\")\n",
    "real_path = pathlib.Path(exp.data_dir(), \"real.npy\")\n",
    "\n",
    "if pred_path.exists():\n",
    "    a_pred_np = np.load(pred_path)\n",
    "    a_real_np = np.load(real_path)\n",
    "    print(f\"Paths successfully loaded from\\n{pred_path.relative_to(pathlib.Path.home())}\")\n",
    "else:\n",
    "    a_real_list = []\n",
    "    a_pred_list = []\n",
    "    with torch.no_grad(): # disable gradient computation\n",
    "        for val in exp[\"verification_data\"]: # for all demonstrations\n",
    "            run, demo_name, camera = val\n",
    "            exp_demo = Config().get_experiment(\"demonstration\", run)\n",
    "            demo = Demonstration(exp_demo, demo_name)\n",
    "            for i in range(demo.metadata[\"maxsteps\"]-exp_bc[\"sequence_length\"]): # -1 because of lookahead\n",
    "                if exp_bc[\"sequence_length\"]:\n",
    "                    input_list = []\n",
    "                    # FIXME make it sliding window\n",
    "                    for j in range(exp_bc[\"sequence_length\"]):\n",
    "                        sensor_readings, _ = demo.get_image(i+j, device=device, transform=transform, camera=camera)\n",
    "                        if sensor_readings is not None:\n",
    "                            print(f\"reading {i+j} successful\")\n",
    "                        else:\n",
    "                            print(f\"reading {i+j} not successful, returned none\")\n",
    "                        z = sp.process(sensor_readings)\n",
    "                        input_list.append(z)\n",
    "                        input_nd = np.array(input_list)\n",
    "                        z_tensor = torch.tensor(input_nd).unsqueeze(0).to(device)\n",
    "                else:\n",
    "                    sensor_readings, _ = demo.get_image(i, device=device, transform=transform, camera=camera)\n",
    "                    z = sp.process(sensor_readings)\n",
    "                    z_tensor = torch.tensor(z).unsqueeze(0).to(device)\n",
    "                if not isinstance(model, bc_LSTM_MDN):                \n",
    "                    a_pred = model(z_tensor)\n",
    "                else:\n",
    "                    a_pred = model.forward_and_sample(z_tensor)\n",
    "                a_pred_list.append(a_pred.to(\"cpu\").squeeze(0))\n",
    "                a = demo.get_action(i)\n",
    "                rp = RobotPosition.from_vector(exp_robot, a)\n",
    "                a_real = rp.to_normalized_vector(exp_robot)            \n",
    "                a_real_list.append(a_real)\n",
    "    a_pred_np = np.array(a_pred_list)\n",
    "    a_real_np = np.array(a_real_list)\n",
    "\n",
    "    # save the comparison terms\n",
    "    np.save(pred_path, a_pred_np)\n",
    "    np.save(real_path, a_real_np)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b02810",
   "metadata": {},
   "source": [
    "## Plot the differences between the a_real and a_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6f570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axs = plt.subplots(2,3, figsize=(8, 6))\n",
    "titles = [\"height\",\"distance\", \"heading\", \"wrist_angle\", \"wrist_rotation\", \"gripper\"]\n",
    "for i in range(exp_bc[\"control_size\"]):\n",
    "    ax = axs[i//3, i%3]\n",
    "    #ax.set_ylim(0, 1.4)\n",
    "    ax.plot(a_real_np[:,i], label=\"ground truth\")\n",
    "    ax.plot(a_pred_np[:,i], label=exp_bc[\"name\"])\n",
    "    if i==0:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, ncol=2,\n",
    "            bbox_to_anchor=(0.5, 0), loc=\"upper center\")\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "graphfilename = pathlib.Path(exp.data_dir(), \"bccomparison.pdf\")\n",
    "plt.savefig(graphfilename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2789e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_real_np.shape\n",
    "a_real_np[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff6d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pred_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e051ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5750c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
