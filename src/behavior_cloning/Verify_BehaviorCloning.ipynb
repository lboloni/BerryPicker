{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1aae1a",
   "metadata": {},
   "source": [
    "# Verify behavior cloning\n",
    "\n",
    "Visually verify a behavior cloning based robot controller.\n",
    "\n",
    "__TODO as of June 1, 2025__\n",
    "\n",
    "* Load the controller trained by the Train_BC notebook and the corresponding sp\n",
    "* Choose a demonstration, to which the SP/BC pair will be applied to the images\n",
    "* Visualize the path taken by the demonstration and what would be (autoregressively) recommended by the controller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e16309",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab463743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pprint\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "from sensorprocessing.sp_helper import get_transform_to_sp\n",
    "from sensorprocessing.sp_factory import create_sp\n",
    "from demonstration.demonstration import Demonstration\n",
    "\n",
    "from bc_LSTM import LSTMXYPredictor, LSTMResidualController\n",
    "from robot.al5d_position_controller import RobotPosition\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9184821",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"behavior_cloning\"\n",
    "# run = \"bc_mlp_00\"\n",
    "run = \"lstm_00\"\n",
    "\n",
    "exp = Config().get_experiment(experiment, run)\n",
    "pprint.pprint(exp)\n",
    "\n",
    "# Create the sp object described in the experiment\n",
    "spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
    "sp = create_sp(spexp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0732419",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp[\"controller\"] != \"LSTMXYPredictor\":\n",
    "    raise Exception(f\"The controller specified {exp['controller']} is not LSTMXYPredictor\")\n",
    "\n",
    "latent_size = spexp[\"latent_size\"]\n",
    "output_size = exp[\"control_size\"]  # degrees of freedom in the robot\n",
    "num_layers = exp[\"controller_num_layers\"]\n",
    "hidden_size = exp[\"controller_hidden_size\"] \n",
    "\n",
    "# Instantiate model, loss function, and optimizer\n",
    "model = LSTMXYPredictor(latent_size=latent_size, hidden_size=hidden_size, output_size = output_size, num_layers=num_layers)\n",
    "\n",
    "controller_path = pathlib.Path(exp.data_dir(), exp[\"controller_file\"])\n",
    "model.load_state_dict(torch.load(controller_path))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c7194ed",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Get one demonstration\n",
    "task = \"proprioception-uncluttered\"\n",
    "sp = sp_conv_vae.ConvVaeSensorProcessing()\n",
    "\n",
    "demos_dir = pathlib.Path(Config()[\"demos\"][\"directory\"])\n",
    "task_dir = pathlib.Path(demos_dir, \"demos\", task)\n",
    "\n",
    "inputlist = []\n",
    "targetlist = []\n",
    "\n",
    "demo_dir = next(task_dir.iterdir())\n",
    "bcd = BCDemonstration(demo_dir, sensorprocessor=sp)\n",
    "z, a = bcd.read_z_a()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c33b570a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "z.shape[0]\n",
    "print(a[1])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da6f570d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "for i in range(z.shape[0]-1):\n",
    "    input = torch.from_numpy(z[i])\n",
    "    input = input.unsqueeze(0)\n",
    "    input = input.unsqueeze(0)\n",
    "    print(input)\n",
    "    a_pred = model.forward_keep_state(input)\n",
    "    a_real = a[i+1]\n",
    "    print(f\"a_real: {a_real}\\na_pred: {a_pred}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
