{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118c94f7",
   "metadata": {},
   "source": [
    "# Behavior cloning flow\n",
    "\n",
    "Create the full flow for training a model for behavior cloning which is completely separated from the other ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad1ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import socket\n",
    "import pathlib\n",
    "import yaml\n",
    "import tqdm\n",
    "import papermill\n",
    "from automate import automate_exprun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a079e126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname is szenes.local\n",
      "Path for external experiments: /Users/lboloni/Documents/Develop/Data/BerryPicker-BC/exprun\n",
      "Path for external data: /Users/lboloni/Documents/Develop/Data/BerryPicker-BC/result\n",
      "***ExpRun**: Loading pointer config file:\n",
      "\t/Users/lboloni/.config/BerryPicker/mainsettings.yaml\n",
      "***ExpRun**: Loading machine-specific config file:\n",
      "\t/Users/lboloni/Google Drive/My Drive/LotziStudy/Code/PackageTracking/BerryPicker/settings/settings-szenes.yaml\n",
      "***ExpRun**: Experiment config path changed to /Users/lboloni/Documents/Develop/Data/BerryPicker-BC/exprun\n",
      "***ExpRun**: Experiment data path changed to /Users/lboloni/Documents/Develop/Data/BerryPicker-BC/result\n"
     ]
    }
   ],
   "source": [
    "# host specific directories\n",
    "hostname = socket.gethostname()\n",
    "print(f\"Hostname is {hostname}\")\n",
    "if hostname == \"raven\":\n",
    "    raise Exception(\"Not configured yet\")\n",
    "elif hostname == \"szenes.local\":\n",
    "    bc_path = pathlib.Path(\"~/Documents/Develop/Data/BerryPicker-BC\").expanduser()\n",
    "    exprun_path = pathlib.Path(bc_path, \"exprun\")\n",
    "    result_path = pathlib.Path(bc_path, \"result\")\n",
    "else:\n",
    "    exprun_path = pathlib.Path(Config()[\"experiment_external\"]).expanduser()\n",
    "    result_path = pathlib.Path(Config()[\"data_external\"]).expanduser()\n",
    "\n",
    "print(f\"Path for external experiments: {exprun_path}\")\n",
    "exprun_path.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"Path for external data: {result_path}\")\n",
    "result_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "Config().set_experiment_path(exprun_path)\n",
    "Config().set_experiment_data(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5dfe2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Experiment demonstration copied to /Users/lboloni/Documents/Develop/Data/BerryPicker-BC/exprun/demonstration\n",
      "***ExpRun**: Experiment sensorprocessing_conv_vae copied to /Users/lboloni/Documents/Develop/Data/BerryPicker-BC/exprun/sensorprocessing_conv_vae\n",
      "***ExpRun**: Experiment robot_al5d copied to /Users/lboloni/Documents/Develop/Data/BerryPicker-BC/exprun/robot_al5d\n",
      "***ExpRun**: Experiment automate copied to /Users/lboloni/Documents/Develop/Data/BerryPicker-BC/exprun/automate\n"
     ]
    }
   ],
   "source": [
    "# Copy the necessary experiments into the external directory\n",
    "Config().copy_experiment(\"demonstration\")\n",
    "Config().copy_experiment(\"sensorprocessing_conv_vae\")\n",
    "Config().copy_experiment(\"robot_al5d\")\n",
    "Config().copy_experiment(\"automate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sensorprocessing_conv_vae(exprun_path, results_path, latent_size=128, epochs=5):\n",
    "    \"\"\"Generate the experiment for the conv-vae sensorprocessing with the right training data and parameters. \n",
    "    Returns the experiment and runname\n",
    "    FIXME there will be parameters etc\"\"\"\n",
    "    experiment = \"sensorprocessing_conv_vae\"\n",
    "    runname = \"bc_sensorprocessing_conv_vae\"\n",
    "    \n",
    "    val = {}\n",
    "    val[\"latent_size\"] = 128\n",
    "    val[\"epochs\"] = 5\n",
    "    val[\"save_period\"] = 5\n",
    "    # setting the training data\n",
    "    cam = \"dev0\"\n",
    "    demo = \"touch-apple\"\n",
    "    training_data = []\n",
    "    training_data.append([demo, \"2025_08-07___15_13_18\" , cam])\n",
    "    val[\"training_data\"] = training_data\n",
    "\n",
    "    # setting the validation data\n",
    "    validation_data = []\n",
    "    validation_data.append([demo, \"2025_08_07___15_28_02\" , cam])\n",
    "    val[\"validation_data\"] = validation_data\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_experiment_path(), experiment, runname + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    return [experiment, runname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d005c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_behaviorcloning(exprun_path, results_path, latent_size=128, epochs=5):\n",
    "    \"\"\"Generate the experiment for the behavior cloning with the right training data and parameters. \n",
    "    Returns the experiment and runname\n",
    "    FIXME there will be parameters etc\"\"\"\n",
    "    experiment = \"behaviorcloning\"\n",
    "    runname = \"bc_sensorprocessing_conv_vae\"\n",
    "    \n",
    "    val = {}\n",
    "    # FIXME: here create the parameters for the bc\n",
    "    val[\"latent_size\"] = latent_size\n",
    "    # FIXME: set the training data through some data structure passed as parameter....\n",
    "    # setting the training data\n",
    "    cam = \"dev0\"\n",
    "    demo = \"touch-apple\"\n",
    "    training_data = []\n",
    "    training_data.append([demo, \"2025_08-07___15_13_18\" , cam])\n",
    "    val[\"training_data\"] = training_data\n",
    "\n",
    "    # setting the validation data\n",
    "    validation_data = []\n",
    "    validation_data.append([demo, \"2025_08_07___15_28_02\" , cam])\n",
    "    val[\"validation_data\"] = validation_data\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_experiment_path(), experiment, runname + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"BehaviorCloning\"\n",
    "    v[\"notebook\"] = \"behavior_cloning/Train-BehaviorCloning.ipynb\"\n",
    "    params = {}\n",
    "    params[\"run\"] = runname\n",
    "    params[\"external_path\"] = exprun_path.as_posix()\n",
    "    params[\"data_path\"] = result_path.as_posix()\n",
    "    v[\"params\"] = params\n",
    "\n",
    "    return {\"experiment\": experiment, \"runname\": runname, \"automation_entry\": v}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea86368",
   "metadata": {},
   "source": [
    "### Generate a range of exp/runs to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06fb6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "expruns = []\n",
    "expruns.append(generate_sensorprocessing_conv_vae())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b2cd76",
   "metadata": {},
   "source": [
    "### Generate an automation script. \n",
    "\n",
    "* FIXME: the notebooks should have support to set the exprun and results directories from the automation exp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda9775",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = {}\n",
    "val = []\n",
    "value[\"exps_to_run\"] = val\n",
    "\n",
    "creation_style = \"exist-ok\"\n",
    "\n",
    "for exprun in expruns:\n",
    "    # exp = Config().get_experiment(exprun[0], exprun[1])\n",
    "    # FIXME: add the automation here or generate the automation script\n",
    "    v = exprun[\"automation_entry\"]\n",
    "    v[\"creation_style\"] = creation_style\n",
    "    val.append(v)\n",
    "\n",
    "path = pathlib.Path(Config().get_experiment_path(), \"automate\", \"flow_bc.yaml\")\n",
    "with open(path, \"w\") as f:\n",
    "    yaml.dump(value, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee7b64",
   "metadata": {},
   "source": [
    "### Run the automation script\n",
    "FIXME: the existing automation does not take into consideration the external directories the right way. I am trying to fix this. \n",
    "FIXME: this should be done such that I can also run it from command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce35cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Experiment default config /Users/lboloni/Documents/Develop/Data/BerryPicker-BC/exprun/automate/_defaults_automate.yaml was empty, ok.\n",
      "***ExpRun**: Configuration for exp/run: automate/flow_bc successfully loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/lboloni/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating SensorProcessing-ConvVae\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 11/11 [00:02<00:00,  4.83cell/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [7]\":\n",
      "---------------------------------------------------------------------------\n",
      "FileNotFoundError                         Traceback (most recent call last)\n",
      "Cell In[7], line 14\n",
      "     12 print(f'***Train-Conv-VAE***: Running the trainer from scratch for {vae_config[\"trainer\"][\"epochs\"]} epochs')\n",
      "     13 exp.start_timer(\"training\")\n",
      "---> 14 trainer = train(vae_config)\n",
      "     15 checkpoint_path = pathlib.Path(trainer.checkpoint_dir, f\"checkpoint-epoch{trainer.epochs}.pth\")\n",
      "     17 json_path = pathlib.Path(trainer.checkpoint_dir, \"config.json\")\n",
      "\n",
      "File ~/Documents/Develop/Github/BerryPicker/BerryPicker/src/sensorprocessing/conv_vae.py:77, in train(config)\n",
      "     73 logger = logging.getLogger(__name__)\n",
      "     76 # setup data_loader instances\n",
      "---> 77 data_loader = config.init_obj('data_loader', module_data)\n",
      "     78 valid_data_loader = data_loader.split_validation()\n",
      "     80 # build model architecture, then print to console\n",
      "\n",
      "File ~/Documents/Develop/Github/Conv-VAE-PyTorch/Conv-VAE-PyTorch/parse_config.py:93, in ConfigParser.init_obj(self, name, module, *args, **kwargs)\n",
      "     91 assert all([k not in module_args for k in kwargs]), 'Overwriting kwargs given in config file is not allowed'\n",
      "     92 module_args.update(kwargs)\n",
      "---> 93 return getattr(module, module_name)(*args, **module_args)\n",
      "\n",
      "File ~/Documents/Develop/Github/Conv-VAE-PyTorch/Conv-VAE-PyTorch/data_loader/data_loaders.py:35, in CelebDataLoader.__init__(self, data_dir, batch_size, shuffle, validation_split, num_workers, image_size)\n",
      "     29 transform = transforms.Compose([\n",
      "     30     transforms.Resize(image_size),\n",
      "     31     transforms.CenterCrop(image_size),\n",
      "     32     transforms.ToTensor(),\n",
      "     33 ])\n",
      "     34 self.data_dir = data_dir\n",
      "---> 35 self.dataset = datasets.ImageFolder(\n",
      "     36     self.data_dir, transform=transform)\n",
      "     37 super().__init__(self.dataset, batch_size, shuffle, validation_split, num_workers)\n",
      "\n",
      "File ~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torchvision/datasets/folder.py:328, in ImageFolder.__init__(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\n",
      "    319 def __init__(\n",
      "    320     self,\n",
      "    321     root: Union[str, Path],\n",
      "   (...)\n",
      "    326     allow_empty: bool = False,\n",
      "    327 ):\n",
      "--> 328     super().__init__(\n",
      "    329         root,\n",
      "    330         loader,\n",
      "    331         IMG_EXTENSIONS if is_valid_file is None else None,\n",
      "    332         transform=transform,\n",
      "    333         target_transform=target_transform,\n",
      "    334         is_valid_file=is_valid_file,\n",
      "    335         allow_empty=allow_empty,\n",
      "    336     )\n",
      "    337     self.imgs = self.samples\n",
      "\n",
      "File ~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torchvision/datasets/folder.py:150, in DatasetFolder.__init__(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\n",
      "    148 super().__init__(root, transform=transform, target_transform=target_transform)\n",
      "    149 classes, class_to_idx = self.find_classes(self.root)\n",
      "--> 150 samples = self.make_dataset(\n",
      "    151     self.root,\n",
      "    152     class_to_idx=class_to_idx,\n",
      "    153     extensions=extensions,\n",
      "    154     is_valid_file=is_valid_file,\n",
      "    155     allow_empty=allow_empty,\n",
      "    156 )\n",
      "    158 self.loader = loader\n",
      "    159 self.extensions = extensions\n",
      "\n",
      "File ~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torchvision/datasets/folder.py:203, in DatasetFolder.make_dataset(directory, class_to_idx, extensions, is_valid_file, allow_empty)\n",
      "    198 if class_to_idx is None:\n",
      "    199     # prevent potential bug since make_dataset() would use the class_to_idx logic of the\n",
      "    200     # find_classes() function, instead of using that of the find_classes() method, which\n",
      "    201     # is potentially overridden and thus could have a different logic.\n",
      "    202     raise ValueError(\"The class_to_idx parameter cannot be None.\")\n",
      "--> 203 return make_dataset(\n",
      "    204     directory, class_to_idx, extensions=extensions, is_valid_file=is_valid_file, allow_empty=allow_empty\n",
      "    205 )\n",
      "\n",
      "File ~/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages/torchvision/datasets/folder.py:104, in make_dataset(directory, class_to_idx, extensions, is_valid_file, allow_empty)\n",
      "    102     if extensions is not None:\n",
      "    103         msg += f\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\n",
      "--> 104     raise FileNotFoundError(msg)\n",
      "    106 return instances\n",
      "\n",
      "FileNotFoundError: Found no valid file for the classes Images. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = \"automate\"\n",
    "run = \"flow_bc\"\n",
    "exp = Config().get_experiment(experiment, run)\n",
    "\n",
    "#output_path = pathlib.Path(ext_path, \"_automation_output\")\n",
    "#output_filename = f\"{notebook_path.stem}_{name}_output{ notebook_path.suffix}\"\n",
    "#output = pathlib.Path(output_path, notebook_path.parent, output_filename)\n",
    "#output.parent.mkdir(exist_ok=True, parents=True)\n",
    "#print(output)\n",
    "\n",
    "\n",
    "for item in tqdm.tqdm(exp[\"exps_to_run\"]):\n",
    "    print(f\"***Automating {item['name']}\")\n",
    "    # FIXME set the output in a complicated way to keep everything at the right position\n",
    "    \n",
    "    output = pathlib.Path(result_path, \"temporary_notebook_output.ipynb\")\n",
    "\n",
    "    notebook = pathlib.Path(\"..\", item[\"notebook\"])\n",
    "    print(notebook.exists())\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        papermill.execute_notebook(\n",
    "            notebook,\n",
    "            output.absolute(),\n",
    "            cwd=notebook.parent,\n",
    "            parameters=item[\"params\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"There was an exception {e}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe71c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
