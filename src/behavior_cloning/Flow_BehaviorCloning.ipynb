{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118c94f7",
   "metadata": {},
   "source": [
    "# Behavior cloning flow\n",
    "\n",
    "Create the full flow for training a model for behavior cloning. This notebook programmatically generates a new set of exp/runs that cover all the necessary components for a behavior cloning system (sensor processing, behavior cloning training and verification notebooks)\n",
    "\n",
    "It writes the exp/runs into an external directory fully separated from the github source, and creates an automation script that runs them. A separate directory for results is also created. \n",
    "\n",
    "Finally, it runs the necessary notebooks to execute the whole flow using papermill.\n",
    "\n",
    "The results directory contain the output of this flow, both in terms of trained models, as well as results (in the verification exp/run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad1ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pprint\n",
    "import socket\n",
    "import pathlib\n",
    "import yaml\n",
    "import tqdm\n",
    "import papermill\n",
    "# from automate import automate_exprun\n",
    "import bc_factory \n",
    "from demonstration.demonstration import list_demos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133bfc28",
   "metadata": {},
   "source": [
    "# Setting up the separate directory\n",
    "Setting up a separate directory for generated exp/run config files and the results. This cell will create a new directory. \n",
    "\n",
    "__Note__\n",
    "Currently, as of 2025-09-03, we don't have a way to put the training data into this directory. Which means that once the code below creates the new directories, we need to manually copy the demonstrations as follows:\n",
    "* the demonstration descriptor (eg. {demonstration_run}.yaml) into {directory_name}/exprun/demonstration\n",
    "* the demonstration runs into {directory_name}/result/demonstration/{demonstration_run}/\n",
    "\n",
    "It would be useful to set up a special import mechanism for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a separate directory for generated exp/run config files and the results\n",
    "\n",
    "# the most likely changing names.\n",
    "directory_name = \"BerryPicker-BC\"\n",
    "demonstration_cam = \"dev0\"\n",
    "demonstration_run = \"touch-apple\"\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "print(f\"***Hostname is {hostname}\")\n",
    "if hostname == \"raven\":\n",
    "    rootdir = pathlib.Path(f\"~/WORK/_DataExternal/\").expanduser()\n",
    "elif hostname == \"szenes.local\":\n",
    "    rootdir = pathlib.Path(f\"~/Documents/Develop/Data/\").expanduser()\n",
    "elif hostname == \"glassy\":\n",
    "    rootdir = pathlib.Path(f\"~/Work/_DataExternal/\").expanduser()\n",
    "else:\n",
    "    rootdir = pathlib.Path(Config()[\"experiment_external\"])\n",
    "\n",
    "exprun_path, result_path = bc_factory.external_setup(directory_name, rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sensorprocessing_conv_vae(exprun_path, result_path, params):\n",
    "    \"\"\"Generate the experiment for the conv-vae sensorprocessing with the right training data and parameters. Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation. \"\"\"\n",
    "    val = {}\n",
    "    val[\"latent_size\"] = params[\"latent_size\"]\n",
    "    val[\"epochs\"] = params[\"epochs\"]\n",
    "    val[\"save_period\"] = 5\n",
    "    val[\"training_data\"] = params[\"training_data\"]\n",
    "    val[\"validation_data\"] = params[\"validation_data\"]\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_experiment_path(), params[\"exp_sp\"], params[\"run_sp\"] + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"TrainVAE\"\n",
    "    v[\"notebook\"] = \"sensorprocessing/Train-Conv-VAE.ipynb\"\n",
    "    vparams = {}\n",
    "    vparams[\"experiment\"] = params[\"exp_sp\"]\n",
    "    vparams[\"run\"] = params[\"run_sp\"]\n",
    "    vparams[\"external_path\"] = exprun_path.as_posix()\n",
    "    vparams[\"data_path\"] = result_path.as_posix()\n",
    "    v[\"params\"] = vparams\n",
    "\n",
    "    return {\"experiment\": params[\"exp_sp\"], \"runname\": params[\"run_sp\"], \"automation_entry\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d005c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bc_train(exprun_path, result_path, params):\n",
    "    \"\"\"Generate the experiment for the training of behavior cloning with the right training data and parameters. At the same time, it also generates the corresponding bcrun experiment, which will be used to drive the robot.  \n",
    "    \"\"\"    \n",
    "    val = {}\n",
    "    val[\"name\"] = params[\"name\"]\n",
    "    val[\"exp_sp\"] = params[\"exp_sp\"]\n",
    "    val[\"run_sp\"] = params[\"run_sp\"]\n",
    "    # these had not yet been studied for alternatives\n",
    "    val[\"sequence_length\"] = params[\"sequence_length\"]\n",
    "    val[\"loss\"] = params[\"loss\"]\n",
    "    val[\"latent_size\"] = params[\"latent_size\"]\n",
    "    val[\"epochs\"] = params[\"epochs\"]\n",
    "\n",
    "    if params[\"algorithm\"] == \"lstm-mdn\": \n",
    "        val[\"exp_mdn\"] = \"behavior_cloning\"\n",
    "        val[\"run_mdn\"] = \"mdn_for_bc_00\"\n",
    "        val[\"controller\"] = \"bc_LSTM_MDN\"\n",
    "        val[\"controller_file\"] = \"controller.pth\"\n",
    "        val[\"hidden_size\"] = params[\"hidden_size\"]\n",
    "    elif params[\"algorithm\"] == \"lstm\":\n",
    "        val[\"controller\"] = \"bc_LSTM\"\n",
    "        val[\"controller_file\"] = \"controller.pth\"\n",
    "        val[\"num_layers\"] = params[\"num_layers\"]\n",
    "        val[\"hidden_size\"] = params[\"hidden_size\"]\n",
    "    elif params[\"algorithm\"] == \"lstm-residual\":\n",
    "        val[\"controller\"] = \"bc_LSTM_Residual\"\n",
    "        val[\"controller_file\"] = \"controller.pth\"\n",
    "        val[\"hidden_size\"] = params[\"hidden_size\"]\n",
    "    elif params[\"algorithm\"] == \"mlp\":\n",
    "        val[\"controller\"] = \"bc_MLP\"\n",
    "        val[\"controller_file\"] = \"controller.pth\"\n",
    "        val[\"hidden_layers\"] = params[\"hidden_layers\"]\n",
    "        val[\"hidden_layer_1\"] = params[\"hidden_layer_1\"]\n",
    "        val[\"hidden_layer_2\"] = params[\"hidden_layer_2\"]\n",
    "        \n",
    "    else:\n",
    "        raise Exception(f\"*** generate_behaviorcloning: algorithm {params['algorithm']} not yet supported\")\n",
    "    \n",
    "    val[\"control_size\"] = 6 \n",
    "    val[\"training_data\"] = params[\"training_data\"]\n",
    "    val[\"validation_data\"] = params[\"validation_data\"]\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_experiment_path(), params[\"exp_bc\"], params[\"run_bc\"] + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"BehaviorCloning\"\n",
    "    v[\"notebook\"] = \"behavior_cloning/Train_BehaviorCloning.ipynb\"\n",
    "    vparams = {}\n",
    "    vparams[\"run\"] = params[\"run_bc\"]\n",
    "    vparams[\"experiment\"] = params[\"exp_bc\"]\n",
    "    vparams[\"external_path\"] = exprun_path.as_posix()\n",
    "    vparams[\"data_path\"] = result_path.as_posix()\n",
    "    v[\"params\"] = vparams\n",
    "\n",
    "    # now, generate the bcrun experiment file, which is the same with the \"runbc_\" prefix\n",
    "    # FIXME: these need to be configurable\n",
    "    valrun = {}\n",
    "    valrun[\"name\"] = f\"generated_run_{params['run_bc']}\"\n",
    "    valrun[\"exp_robot_controller\"] = \"robot_al5d\"\n",
    "    valrun[\"run_robot_controller\"] = \"position_controller_00\"\n",
    "    valrun[\"exp_camera_controller\"] = \"controllers\"\n",
    "    valrun[\"run_camera_controller\"] = \"camera_cam0_controller\"\n",
    "    valrun[\"control_camera\"] = \"dev0\"\n",
    "    valrun[\"exp_bc\"] = \"behavior_cloning\"\n",
    "    valrun[\"run_bc\"] = \"bc_lstm_0001\"\n",
    "\n",
    "    path = pathlib.Path(Config().get_experiment_path(), params[\"exp_bc\"], \"runbc_\"+ params[\"run_bc\"] + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(valrun, f)\n",
    "\n",
    "    return {\"experiment\": params[\"exp_bc\"], \"runname\": params[\"run_bc\"], \"automation_entry\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586402e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bc_verify(exprun_path, result_path, params):\n",
    "    \"\"\"Generate the experiment for the behavior cloning with the right training data and parameters. At the same time, it also generates the corresponding bcrun experiment, which will be used to drive the robot.  \n",
    "    \"\"\"    \n",
    "    val = {}\n",
    "    val[\"exp_sp\"] = params[\"exp_sp\"]\n",
    "    val[\"run_sp\"] = params[\"run_sp\"]\n",
    "    val[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "    val[\"run_bc\"] = params[\"run_bc\"]\n",
    "    val[\"exp_bc_verify\"] = params[\"exp_bc_verify\"]\n",
    "    val[\"run_bc_verify\"] = params[\"run_bc_verify\"]\n",
    "    val[\"verification_data\"] = params[\"verification_data\"]\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_experiment_path(), params[\"exp_bc\"], params[\"run_bc\"] + \"_verify.yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"BehaviorCloning\"\n",
    "    v[\"notebook\"] = \"behavior_cloning/Verify_BehaviorCloning.ipynb\"\n",
    "    vparams = {}\n",
    "    vparams[\"run\"] = params[\"run_bc_verify\"]\n",
    "    vparams[\"experiment\"] = params[\"exp_bc_verify\"]\n",
    "    vparams[\"external_path\"] = exprun_path.as_posix()\n",
    "    vparams[\"data_path\"] = result_path.as_posix()\n",
    "    v[\"params\"] = vparams\n",
    "\n",
    "    return {\"experiment\": params[\"exp_bc_verify\"], \"runname\": params[\"run_bc_verify\"], \"automation_entry\": v}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea86368",
   "metadata": {},
   "source": [
    "### Generate a range of exp/runs to be run\n",
    "\n",
    "define which demonstrations will be used for:\n",
    "* training the sensor processing (sp_training_data)\n",
    "* training the behavior cloning (bc_training_data)\n",
    "* verifying the behavior cloning (bc_verification_data) \n",
    "   etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "expruns = []\n",
    "\n",
    "# overall values\n",
    "latent_size = 128\n",
    "\n",
    "# FIXME: set the training data through some data structure passed as parameter....\n",
    "# setting the training data\n",
    "cam = \"dev0\"\n",
    "#run_demo = \"touch-apple\"\n",
    "experiment = \"demonstration\"\n",
    "# run = \"freeform\"\n",
    "# run = \"random-both-cameras\"\n",
    "# run = \"random-both-cameras-video\"\n",
    "exp = Config().get_experiment(experiment, demonstration_run)\n",
    "demos = list_demos(exp)\n",
    "print(\"***The demos considered\")\n",
    "pprint.pprint(demos)\n",
    "\n",
    "data = []\n",
    "for demo in demos:\n",
    "    data.append([demonstration_run, demo, demonstration_cam])\n",
    "\n",
    "training_data = data[0:-2]\n",
    "sp_training_data = training_data\n",
    "bc_training_data = training_data\n",
    "\n",
    "# setting the validation data\n",
    "validation_data = data[-2:]\n",
    "sp_validation_data = validation_data\n",
    "bc_validation_data = validation_data\n",
    "# experiment, let's run the verification\n",
    "# also on the data which was present in the training\n",
    "bc_verification_data = data\n",
    "\n",
    "# determine these values based on experience\n",
    "epochs_sp = 300\n",
    "epochs_bc = 500\n",
    "\n",
    "# generate sensor processing expruns\n",
    "exp_sp = \"sensorprocessing_conv_vae\"\n",
    "run_sp = \"sp_conv_vae_0001\"\n",
    "params = {}\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"epochs\"] = epochs_sp\n",
    "params[\"training_data\"] = sp_training_data\n",
    "params[\"validation_data\"] = sp_validation_data\n",
    "exprun = generate_sensorprocessing_conv_vae(\n",
    "    exprun_path = exprun_path, result_path = result_path, params = params)\n",
    "expruns.append(exprun)\n",
    "\n",
    "# generate the behavior cloning expruns to match with the sensor processing components from above\n",
    "\n",
    "exp_bc = \"behavior_cloning\"\n",
    "\n",
    "# an MLP model\n",
    "params = {}\n",
    "params[\"name\"] = \"MLP 2 hidden\" # should be descriptive\n",
    "params[\"exp_bc\"] = exp_bc\n",
    "params[\"run_bc\"] = \"bc_mlp_0001\"\n",
    "params[\"algorithm\"] = \"mlp\"\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"hidden_layers\"] = 2\n",
    "params[\"hidden_layer_1\"] = 50\n",
    "params[\"hidden_layer_2\"] = 20\n",
    "params[\"epochs\"] = epochs_bc\n",
    "params[\"sequence_length\"] = 1\n",
    "params[\"loss\"] = \"MSELoss\"\n",
    "params[\"training_data\"] = bc_training_data\n",
    "params[\"validation_data\"] = bc_validation_data\n",
    "exprun = generate_bc_train(exprun_path=exprun_path, result_path=result_path, params=params)\n",
    "expruns.append(exprun)\n",
    "# the verification for the MLP model\n",
    "paramsv = {}\n",
    "paramsv[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "paramsv[\"run_bc\"] = params[\"run_bc\"]\n",
    "paramsv[\"exp_sp\"] = exp_sp\n",
    "paramsv[\"run_sp\"] = run_sp\n",
    "paramsv[\"exp_bc_verify\"] = exp_bc\n",
    "paramsv[\"run_bc_verify\"] = \"bc_mlp_0001_verify\"\n",
    "paramsv[\"verification_data\"] = bc_verification_data\n",
    "exprun = generate_bc_verify(exprun_path=exprun_path, result_path=result_path, params=paramsv)\n",
    "expruns.append(exprun)\n",
    "\n",
    "\n",
    "# a pure LSTM model\n",
    "params = {}\n",
    "params[\"name\"] = \"LSTM 2 layers\"\n",
    "params[\"exp_bc\"] = exp_bc\n",
    "params[\"run_bc\"] = \"bc_lstm_0001\"\n",
    "params[\"algorithm\"] = \"lstm\"\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"hidden_size\"] = 32\n",
    "params[\"num_layers\"] = 2\n",
    "params[\"epochs\"] = epochs_bc\n",
    "params[\"sequence_length\"] = 10\n",
    "params[\"loss\"] = \"MSELoss\"\n",
    "params[\"training_data\"] = bc_training_data\n",
    "params[\"validation_data\"] = bc_verification_data\n",
    "exprun = generate_bc_train(exprun_path=exprun_path, result_path=result_path, params=params)\n",
    "expruns.append(exprun)\n",
    "# the verification for the LSTM model\n",
    "paramsv = {}\n",
    "paramsv[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "paramsv[\"run_bc\"] = params[\"run_bc\"]\n",
    "paramsv[\"exp_sp\"] = exp_sp\n",
    "paramsv[\"run_sp\"] = run_sp\n",
    "paramsv[\"exp_bc_verify\"] = exp_bc\n",
    "paramsv[\"run_bc_verify\"] = \"bc_lstm_0001_verify\"\n",
    "paramsv[\"verification_data\"] = bc_verification_data\n",
    "exprun = generate_bc_verify(exprun_path=exprun_path, result_path=result_path, params=paramsv)\n",
    "expruns.append(exprun)\n",
    "\n",
    "# a residual LSTM model\n",
    "params = {}\n",
    "params[\"name\"] = \"LSTM residual\"\n",
    "params[\"exp_bc\"] = exp_bc\n",
    "params[\"run_bc\"] = \"bc_lstm_residual_0001\"\n",
    "params[\"algorithm\"] = \"lstm-residual\"\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"hidden_size\"] = 32\n",
    "params[\"epochs\"] = epochs_bc\n",
    "params[\"sequence_length\"] = 10\n",
    "params[\"loss\"] = \"MSELoss\"\n",
    "params[\"training_data\"] = bc_training_data\n",
    "params[\"validation_data\"] = bc_validation_data\n",
    "exprun = generate_bc_train(exprun_path=exprun_path, result_path=result_path, params=params)\n",
    "expruns.append(exprun)\n",
    "# the verification for the LSTM model\n",
    "paramsv = {}\n",
    "paramsv[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "paramsv[\"run_bc\"] = params[\"run_bc\"]\n",
    "paramsv[\"exp_sp\"] = exp_sp\n",
    "paramsv[\"run_sp\"] = run_sp\n",
    "paramsv[\"exp_bc_verify\"] = exp_bc\n",
    "paramsv[\"run_bc_verify\"] = \"bc_lstm_residual_0001_verify\"\n",
    "paramsv[\"verification_data\"] = bc_verification_data\n",
    "exprun = generate_bc_verify(exprun_path=exprun_path, result_path=result_path, params=paramsv)\n",
    "expruns.append(exprun)\n",
    "\n",
    "# an LSTM-MDN based model\n",
    "params = {}\n",
    "params[\"name\"] = \"LSTM MDN\"\n",
    "params[\"exp_bc\"] = exp_bc\n",
    "params[\"run_bc\"] = \"bc_lstm_mdn_0001\"\n",
    "params[\"algorithm\"] = \"lstm-mdn\"\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"hidden_size\"] = 32\n",
    "params[\"epochs\"] = epochs_bc\n",
    "params[\"sequence_length\"] = 10\n",
    "params[\"loss\"] = \"MSELoss\"\n",
    "params[\"training_data\"] = bc_training_data\n",
    "params[\"validation_data\"] = bc_validation_data\n",
    "exprun = generate_bc_train(exprun_path=exprun_path, result_path=result_path, params=params)\n",
    "expruns.append(exprun)\n",
    "# the verification for the LSTM-MDN model\n",
    "paramsv = {}\n",
    "paramsv[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "paramsv[\"run_bc\"] = params[\"run_bc\"]\n",
    "paramsv[\"exp_sp\"] = exp_sp\n",
    "paramsv[\"run_sp\"] = run_sp\n",
    "paramsv[\"exp_bc_verify\"] = exp_bc\n",
    "paramsv[\"run_bc_verify\"] = \"bc_lstm_mdn_0001_verify\"\n",
    "paramsv[\"verification_data\"] = bc_verification_data\n",
    "exprun = generate_bc_verify(exprun_path=exprun_path, result_path=result_path, params=paramsv)\n",
    "expruns.append(exprun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b2cd76",
   "metadata": {},
   "source": [
    "### Generate an automation\n",
    "\n",
    "Generate an exp/run of the type \"automate\" based on the list expruns. The individual automation entries should be already in the \"automation_entry\" field. The only thing that is really decided here is the \"creation_style\", which can be exist-ok or discard-old, if we want to start this from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda9775",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = {}\n",
    "val = []\n",
    "value[\"exps_to_run\"] = val\n",
    "\n",
    "# Use exist_ok not to-re-run previously successfully run models\n",
    "creation_style = \"exist-ok\"\n",
    "# creation_style = \"discard-old\"\n",
    "\n",
    "for exprun in expruns:\n",
    "    v = exprun[\"automation_entry\"]\n",
    "    if \"verify\" in v[\"params\"][\"run\"]:\n",
    "        v[\"params\"][\"creation_style\"] = \"discard-old\"\n",
    "    else:\n",
    "        v[\"params\"][\"creation_style\"] = creation_style\n",
    "    val.append(v)\n",
    "\n",
    "path = pathlib.Path(Config().get_experiment_path(), \"automate\", \"flow_bc.yaml\")\n",
    "with open(path, \"w\") as f:\n",
    "    yaml.dump(value, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee7b64",
   "metadata": {},
   "source": [
    "### Run the automation script\n",
    "\n",
    "Run the automation script, as a series of notebooks. In order to follow the execution inside these notebooks, one needs to open the output notebook, which is in the output_filename. \n",
    "\n",
    "* FIXME: this should be done such that I can also run it from command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce35cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"automate\"\n",
    "run = \"flow_bc\"\n",
    "exp = Config().get_experiment(experiment, run)\n",
    "\n",
    "print(f\"***Starting automated running of the flow.\\n The path for the output notebooks is\\n{result_path}\")\n",
    "\n",
    "for item in tqdm.tqdm(exp[\"exps_to_run\"]):\n",
    "    print(f\"***Automating {item['notebook']} :\\n {item['params']['experiment']}/{item['params']['run']}\")\n",
    "    notebook_path = pathlib.Path(\"..\", item[\"notebook\"])\n",
    "    output_filename = f\"{notebook_path.stem}_{item['params']['experiment']}_{item['params']['run']}_output{notebook_path.suffix}\"\n",
    "    print(f\"--> {output_filename}\")\n",
    "    # pprint.pprint(item[\"params\"])\n",
    "    output_path = pathlib.Path(result_path, output_filename)\n",
    "    try:\n",
    "        papermill.execute_notebook(\n",
    "            notebook_path,\n",
    "            output_path.absolute(),\n",
    "            cwd=notebook_path.parent,\n",
    "            parameters=item[\"params\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"There was an exception {e}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37c8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
