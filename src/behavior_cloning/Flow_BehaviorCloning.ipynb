{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118c94f7",
   "metadata": {},
   "source": [
    "# Behavior cloning flow\n",
    "\n",
    "Create the full flow for training a model for behavior cloning which is completely separated from the other ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad1ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pprint\n",
    "import socket\n",
    "import pathlib\n",
    "import yaml\n",
    "import tqdm\n",
    "import papermill\n",
    "# from automate import automate_exprun\n",
    "import bc_factory \n",
    "from demonstration.demonstration import list_demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a separate directory for generated and computed data\n",
    "exprun_path, result_path = bc_factory.external_setup(\"BerryPicker-BC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sensorprocessing_conv_vae(exprun_path, result_path, params):\n",
    "    \"\"\"Generate the experiment for the conv-vae sensorprocessing with the right training data and parameters. Returns the experiment and runname\"\"\"\n",
    "    val = {}\n",
    "    val[\"latent_size\"] = params[\"latent_size\"]\n",
    "    val[\"epochs\"] = params[\"epochs\"]\n",
    "    val[\"save_period\"] = 5\n",
    "    val[\"training_data\"] = params[\"training_data\"]\n",
    "    val[\"validation_data\"] = params[\"validation_data\"]\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_experiment_path(), params[\"exp_sp\"], params[\"run_sp\"] + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"TrainVAE\"\n",
    "    v[\"notebook\"] = \"sensorprocessing/Train-Conv-VAE.ipynb\"\n",
    "    vparams = {}\n",
    "    vparams[\"experiment\"] = params[\"exp_sp\"]\n",
    "    vparams[\"run\"] = params[\"run_sp\"]\n",
    "    vparams[\"external_path\"] = exprun_path.as_posix()\n",
    "    vparams[\"data_path\"] = result_path.as_posix()\n",
    "    v[\"params\"] = vparams\n",
    "\n",
    "    return {\"experiment\": params[\"exp_sp\"], \"runname\": params[\"run_sp\"], \"automation_entry\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d005c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bc_train(exprun_path, result_path, params):\n",
    "    \"\"\"Generate the experiment for the training of behavior cloning with the right training data and parameters. At the same time, it also generates the corresponding bcrun experiment, which will be used to drive the robot.  \n",
    "    \"\"\"    \n",
    "    val = {}\n",
    "    val[\"exp_sp\"] = params[\"exp_sp\"]\n",
    "    val[\"run_sp\"] = params[\"run_sp\"]\n",
    "    # these had not yet been studied for alternatives\n",
    "    val[\"sequence_length\"] = params[\"sequence_length\"]\n",
    "    val[\"loss\"] = params[\"loss\"]\n",
    "    val[\"latent_size\"] = params[\"latent_size\"]\n",
    "    val[\"epochs\"] = params[\"epochs\"]\n",
    "\n",
    "    if params[\"algorithm\"] == \"lstm-mdn\": \n",
    "        val[\"exp_mdn\"] = \"behavior_cloning\"\n",
    "        val[\"run_mdn\"] = \"mdn_for_bc_00\"\n",
    "        val[\"controller\"] = \"bc_LSTM_MDN\"\n",
    "        val[\"controller_file\"] = \"controller.pth\"\n",
    "        val[\"hidden_size\"] = params[\"hidden_size\"]\n",
    "    elif params[\"algorithm\"] == \"lstm\":\n",
    "        val[\"controller\"] = \"bc_LSTM\"\n",
    "        val[\"controller_file\"] = \"controller.pth\"\n",
    "        val[\"num_layers\"] = params[\"num_layers\"]\n",
    "        val[\"hidden_size\"] = params[\"hidden_size\"]\n",
    "    elif params[\"algorithm\"] == \"lstm-residual\":\n",
    "        val[\"controller\"] = \"bc_LSTM_Residual\"\n",
    "        val[\"controller_file\"] = \"controller.pth\"\n",
    "        val[\"hidden_size\"] = params[\"hidden_size\"]\n",
    "    elif params[\"algorithm\"] == \"mlp\":\n",
    "        val[\"controller\"] = \"bc_MLP\"\n",
    "        val[\"controller_file\"] = \"controller.pth\"\n",
    "        val[\"hidden_layers\"] = params[\"hidden_layers\"]\n",
    "        val[\"hidden_layer_1\"] = params[\"hidden_layer_1\"]\n",
    "        val[\"hidden_layer_2\"] = params[\"hidden_layer_2\"]\n",
    "        \n",
    "    else:\n",
    "        raise Exception(f\"*** generate_behaviorcloning: algorithm {params['algorithm']} not yet supported\")\n",
    "    \n",
    "    val[\"control_size\"] = 6 \n",
    "    val[\"training_data\"] = params[\"training_data\"]\n",
    "    val[\"validation_data\"] = params[\"validation_data\"]\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_experiment_path(), params[\"exp_bc\"], params[\"run_bc\"] + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"BehaviorCloning\"\n",
    "    v[\"notebook\"] = \"behavior_cloning/Train_BehaviorCloning.ipynb\"\n",
    "    vparams = {}\n",
    "    vparams[\"run\"] = params[\"run_bc\"]\n",
    "    vparams[\"experiment\"] = params[\"exp_bc\"]\n",
    "    vparams[\"external_path\"] = exprun_path.as_posix()\n",
    "    vparams[\"data_path\"] = result_path.as_posix()\n",
    "    v[\"params\"] = vparams\n",
    "\n",
    "    # now, generate the bcrun experiment file, which is the same with the \"runbc_\" prefix\n",
    "    # FIXME: these need to be configurable\n",
    "    valrun = {}\n",
    "    valrun[\"name\"] = f\"generated_run_{params['run_bc']}\"\n",
    "    valrun[\"exp_robot_controller\"] = \"robot_al5d\"\n",
    "    valrun[\"run_robot_controller\"] = \"position_controller_00\"\n",
    "    valrun[\"exp_camera_controller\"] = \"controllers\"\n",
    "    valrun[\"run_camera_controller\"] = \"camera_cam0_controller\"\n",
    "    valrun[\"control_camera\"] = \"dev0\"\n",
    "    valrun[\"exp_bc\"] = \"behavior_cloning\"\n",
    "    valrun[\"run_bc\"] = \"bc_lstm_0001\"\n",
    "\n",
    "    path = pathlib.Path(Config().get_experiment_path(), params[\"exp_bc\"], \"runbc_\"+ params[\"run_bc\"] + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(valrun, f)\n",
    "\n",
    "    return {\"experiment\": params[\"exp_bc\"], \"runname\": params[\"run_bc\"], \"automation_entry\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586402e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bc_verify(exprun_path, result_path, params):\n",
    "    \"\"\"Generate the experiment for the behavior cloning with the right training data and parameters. At the same time, it also generates the corresponding bcrun experiment, which will be used to drive the robot.  \n",
    "\n",
    "    FIXME: not yet implemented, this is the copy of the generate bc train\n",
    "\n",
    "    \"\"\"    \n",
    "    val = {}\n",
    "    val[\"exp_sp\"] = params[\"exp_sp\"]\n",
    "    val[\"run_sp\"] = params[\"run_sp\"]\n",
    "    val[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "    val[\"run_bc\"] = params[\"run_bc\"]\n",
    "    val[\"exp_bc_verify\"] = params[\"exp_bc_verify\"]\n",
    "    val[\"run_bc_verify\"] = params[\"run_bc_verify\"]\n",
    "    val[\"verification_data\"] = params[\"verification_data\"]\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_experiment_path(), params[\"exp_bc\"], params[\"run_bc\"] + \"_verify.yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"BehaviorCloning\"\n",
    "    v[\"notebook\"] = \"behavior_cloning/Verify_BehaviorCloning.ipynb\"\n",
    "    vparams = {}\n",
    "    vparams[\"run\"] = params[\"run_bc_verify\"]\n",
    "    vparams[\"experiment\"] = params[\"exp_bc_verify\"]\n",
    "    vparams[\"external_path\"] = exprun_path.as_posix()\n",
    "    vparams[\"data_path\"] = result_path.as_posix()\n",
    "    v[\"params\"] = vparams\n",
    "\n",
    "    return {\"experiment\": params[\"exp_bc_verify\"], \"runname\": params[\"run_bc_verify\"], \"automation_entry\": v}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea86368",
   "metadata": {},
   "source": [
    "### Generate a range of exp/runs to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "expruns = []\n",
    "\n",
    "# overall values\n",
    "latent_size = 128\n",
    "\n",
    "# FIXME: set the training data through some data structure passed as parameter....\n",
    "# setting the training data\n",
    "cam = \"dev0\"\n",
    "run_demo = \"touch-apple\"\n",
    "experiment = \"demonstration\"\n",
    "# run = \"freeform\"\n",
    "# run = \"random-both-cameras\"\n",
    "run = \"random-both-cameras-video\"\n",
    "exp = Config().get_experiment(experiment, run_demo)\n",
    "demos = list_demos(exp)\n",
    "print(demos)\n",
    "\n",
    "data = []\n",
    "for demo in demos:\n",
    "    data.append([run_demo, demo, cam])\n",
    "\n",
    "training_data = data[0:-2]\n",
    "sp_training_data = training_data\n",
    "bc_training_data = training_data\n",
    "\n",
    "# setting the validation data\n",
    "validation_data = data[-2:]\n",
    "sp_validation_data = validation_data\n",
    "bc_validation_data = validation_data\n",
    "\n",
    "# determine these values based on experience\n",
    "epochs_sp = 300\n",
    "epochs_bc = 500\n",
    "\n",
    "# generate sensor processing expruns\n",
    "exp_sp = \"sensorprocessing_conv_vae\"\n",
    "run_sp = \"sp_conv_vae_0001\"\n",
    "params = {}\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"epochs\"] = epochs_sp\n",
    "params[\"training_data\"] = sp_training_data\n",
    "params[\"validation_data\"] = sp_validation_data\n",
    "exprun = generate_sensorprocessing_conv_vae(\n",
    "    exprun_path = exprun_path, result_path = result_path, params = params)\n",
    "expruns.append(exprun)\n",
    "\n",
    "# generate the behavior cloning expruns to match with the sensor processing components from above\n",
    "\n",
    "exp_bc = \"behavior_cloning\"\n",
    "\n",
    "# an MLP model\n",
    "params = {}\n",
    "params[\"exp_bc\"] = exp_bc\n",
    "params[\"run_bc\"] = \"bc_mlp_0001\"\n",
    "params[\"algorithm\"] = \"mlp\"\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"hidden_layers\"] = 2\n",
    "params[\"hidden_layer_1\"] = 50\n",
    "params[\"hidden_layer_2\"] = 20\n",
    "params[\"epochs\"] = epochs_bc\n",
    "params[\"sequence_length\"] = 1\n",
    "params[\"loss\"] = \"MSELoss\"\n",
    "params[\"training_data\"] = bc_training_data\n",
    "params[\"validation_data\"] = bc_validation_data\n",
    "exprun = generate_bc_train(exprun_path=exprun_path, result_path=result_path, params=params)\n",
    "expruns.append(exprun)\n",
    "# the verification for the MLP model\n",
    "paramsv = {}\n",
    "paramsv[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "paramsv[\"run_bc\"] = params[\"run_bc\"]\n",
    "paramsv[\"exp_sp\"] = exp_sp\n",
    "paramsv[\"run_sp\"] = run_sp\n",
    "paramsv[\"exp_bc_verify\"] = exp_bc\n",
    "paramsv[\"run_bc_verify\"] = \"bc_mlp_0001_verify\"\n",
    "paramsv[\"verification_data\"] = bc_validation_data\n",
    "exprun = generate_bc_verify(exprun_path=exprun_path, result_path=result_path, params=paramsv)\n",
    "expruns.append(exprun)\n",
    "\n",
    "\n",
    "# a pure LSTM model\n",
    "params = {}\n",
    "params[\"exp_bc\"] = exp_bc\n",
    "params[\"run_bc\"] = \"bc_lstm_0001\"\n",
    "params[\"algorithm\"] = \"lstm\"\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"hidden_size\"] = 32\n",
    "params[\"num_layers\"] = 2\n",
    "params[\"epochs\"] = epochs_bc\n",
    "params[\"sequence_length\"] = 10\n",
    "params[\"loss\"] = \"MSELoss\"\n",
    "params[\"training_data\"] = bc_training_data\n",
    "params[\"validation_data\"] = bc_validation_data\n",
    "exprun = generate_bc_train(exprun_path=exprun_path, result_path=result_path, params=params)\n",
    "expruns.append(exprun)\n",
    "# the verification for the LSTM model\n",
    "paramsv = {}\n",
    "paramsv[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "paramsv[\"run_bc\"] = params[\"run_bc\"]\n",
    "paramsv[\"exp_sp\"] = exp_sp\n",
    "paramsv[\"run_sp\"] = run_sp\n",
    "paramsv[\"exp_bc_verify\"] = exp_bc\n",
    "paramsv[\"run_bc_verify\"] = \"bc_lstm_0001_verify\"\n",
    "paramsv[\"verification_data\"] = bc_validation_data\n",
    "exprun = generate_bc_verify(exprun_path=exprun_path, result_path=result_path, params=paramsv)\n",
    "expruns.append(exprun)\n",
    "\n",
    "# a residual LSTM model\n",
    "params = {}\n",
    "params[\"exp_bc\"] = exp_bc\n",
    "params[\"run_bc\"] = \"bc_lstm_residual_0001\"\n",
    "params[\"algorithm\"] = \"lstm-residual\"\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"hidden_size\"] = 32\n",
    "params[\"epochs\"] = epochs_bc\n",
    "params[\"sequence_length\"] = 10\n",
    "params[\"loss\"] = \"MSELoss\"\n",
    "params[\"training_data\"] = bc_training_data\n",
    "params[\"validation_data\"] = bc_validation_data\n",
    "exprun = generate_bc_train(exprun_path=exprun_path, result_path=result_path, params=params)\n",
    "expruns.append(exprun)\n",
    "# the verification for the LSTM model\n",
    "paramsv = {}\n",
    "paramsv[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "paramsv[\"run_bc\"] = params[\"run_bc\"]\n",
    "paramsv[\"exp_sp\"] = exp_sp\n",
    "paramsv[\"run_sp\"] = run_sp\n",
    "paramsv[\"exp_bc_verify\"] = exp_bc\n",
    "paramsv[\"run_bc_verify\"] = \"bc_lstm_residual_0001_verify\"\n",
    "paramsv[\"verification_data\"] = bc_validation_data\n",
    "exprun = generate_bc_verify(exprun_path=exprun_path, result_path=result_path, params=paramsv)\n",
    "expruns.append(exprun)\n",
    "\n",
    "# an LSTM-MDN based model\n",
    "params = {}\n",
    "params[\"exp_bc\"] = exp_bc\n",
    "params[\"run_bc\"] = \"bc_lstm_mdn_0001\"\n",
    "params[\"algorithm\"] = \"lstm-mdn\"\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"hidden_size\"] = 32\n",
    "params[\"epochs\"] = epochs_bc\n",
    "params[\"sequence_length\"] = 10\n",
    "params[\"loss\"] = \"MSELoss\"\n",
    "params[\"training_data\"] = bc_training_data\n",
    "params[\"validation_data\"] = bc_validation_data\n",
    "exprun = generate_bc_train(exprun_path=exprun_path, result_path=result_path, params=params)\n",
    "expruns.append(exprun)\n",
    "# the verification for the LSTM-MDN model\n",
    "paramsv = {}\n",
    "paramsv[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "paramsv[\"run_bc\"] = params[\"run_bc\"]\n",
    "paramsv[\"exp_sp\"] = exp_sp\n",
    "paramsv[\"run_sp\"] = run_sp\n",
    "paramsv[\"exp_bc_verify\"] = exp_bc\n",
    "paramsv[\"run_bc_verify\"] = \"bc_lstm_mdn_0001_verify\"\n",
    "paramsv[\"verification_data\"] = bc_validation_data\n",
    "exprun = generate_bc_verify(exprun_path=exprun_path, result_path=result_path, params=paramsv)\n",
    "expruns.append(exprun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b2cd76",
   "metadata": {},
   "source": [
    "### Generate an automation script. \n",
    "\n",
    "* FIXME: the notebooks should have support to set the exprun and results directories from the automation exp. (This seems to actually exist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda9775",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = {}\n",
    "val = []\n",
    "value[\"exps_to_run\"] = val\n",
    "\n",
    "creation_style = \"exist-ok\"\n",
    "# creation_style = \"discard-old\"\n",
    "\n",
    "for exprun in expruns:\n",
    "    v = exprun[\"automation_entry\"]\n",
    "    v[\"params\"][\"creation_style\"] = creation_style\n",
    "    val.append(v)\n",
    "\n",
    "path = pathlib.Path(Config().get_experiment_path(), \"automate\", \"flow_bc.yaml\")\n",
    "with open(path, \"w\") as f:\n",
    "    yaml.dump(value, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee7b64",
   "metadata": {},
   "source": [
    "### Run the automation script\n",
    "* FIXME: the existing automation does not take into consideration the external directories the right way. I am trying to fix this. \n",
    "* FIXME: this should be done such that I can also run it from command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce35cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"automate\"\n",
    "run = \"flow_bc\"\n",
    "exp = Config().get_experiment(experiment, run)\n",
    "\n",
    "for item in tqdm.tqdm(exp[\"exps_to_run\"]):\n",
    "    print(f\"***Automating {item['name']}\")\n",
    "    notebook_path = pathlib.Path(\"..\", item[\"notebook\"])\n",
    "    output_filename = f\"{notebook_path.stem}_{item['params']['experiment']}_{item['params']['run']}_output{notebook_path.suffix}\"\n",
    "    # FIXME: this should go into the data dir of the appropriate exp... but I don't have access to it... \n",
    "    pprint.pprint(item[\"params\"])\n",
    "    output_path = pathlib.Path(result_path, output_filename)\n",
    "    try:\n",
    "        papermill.execute_notebook(\n",
    "            notebook_path,\n",
    "            output_path.absolute(),\n",
    "            cwd=notebook_path.parent,\n",
    "            parameters=item[\"params\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"There was an exception {e}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37c8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
