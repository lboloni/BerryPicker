{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118c94f7",
   "metadata": {},
   "source": [
    "# Behavior cloning flow\n",
    "\n",
    "Create the full flow for training a model for behavior cloning. This notebook programmatically generates a new set of exp/runs that cover all the necessary components for a behavior cloning system (sensor processing, behavior cloning training and verification notebooks)\n",
    "\n",
    "It writes the exp/runs into an external directory fully separated from the github source, and creates an automation script that runs them. A separate directory for results is also created. \n",
    "\n",
    "Finally, it runs the necessary notebooks to execute the whole flow using papermill.\n",
    "\n",
    "The results directory contain the output of this flow, both in terms of trained models, as well as results (in the verification exp/run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad1ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pprint\n",
    "import pathlib\n",
    "import yaml\n",
    "import tqdm\n",
    "import papermill\n",
    "# from automate import automate_exprun\n",
    "import bc_factory \n",
    "from demonstration.demonstration import list_demos\n",
    "from demonstration.demopack import import_demopack, group_chooser_sp_bc_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133bfc28",
   "metadata": {},
   "source": [
    "# Setting up the flow directory and the demonstrations used as data\n",
    "Setting up a separate directory for the flow, which includes an ```exprun``` directory for the generated exp/run config files and a ```results``` directory where the data goes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7388e604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Loading pointer config file:\n",
      "\tC:\\Users\\lotzi\\.config\\BerryPicker\\mainsettings.yaml\n",
      "***ExpRun**: Loading machine-specific config file:\n",
      "\tc:\\Users\\lotzi\\Work\\_Config\\BerryPicker\\cfg\\settings.yaml\n",
      "***Path for external experiments:\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BerryPicker-BC-2\\exprun\n",
      "***Path for external data:\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BerryPicker-BC-2\\result\n",
      "***ExpRun**: Experiment config path changed to c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BerryPicker-BC-2\\exprun\n",
      "***ExpRun**: Experiment data path changed to c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BerryPicker-BC-2\\result\n",
      "***ExpRun**: Experiment demonstration copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BerryPicker-BC-2\\exprun\\demonstration\n",
      "***ExpRun**: Experiment sensorprocessing_conv_vae copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BerryPicker-BC-2\\exprun\\sensorprocessing_conv_vae\n",
      "***ExpRun**: Experiment robot_al5d copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BerryPicker-BC-2\\exprun\\robot_al5d\n",
      "***ExpRun**: Experiment automate copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BerryPicker-BC-2\\exprun\\automate\n",
      "***ExpRun**: Experiment behavior_cloning copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BerryPicker-BC-2\\exprun\\behavior_cloning\n",
      "***ExpRun**: Experiment controllers copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BerryPicker-BC-2\\exprun\\controllers\n"
     ]
    }
   ],
   "source": [
    "# The primary parameters. These are the ones that one most likely want to change \n",
    "\n",
    "flow_name = \"BerryPicker-BC-2\"\n",
    "# demopack_name = \"touch-apple\"\n",
    "# demopack_name = \"random-both-cameras-video\"\n",
    "demopack_name = \"automove-pack-01\"\n",
    "demonstration_cam = \"dev2\"\n",
    "\n",
    "# The number of epochs used for training.\n",
    "# -- low values for debugging the flow\n",
    "# epochs_sp = 15\n",
    "# epochs_bc = 15\n",
    "# -- realistic values determined experimentally\n",
    "epochs_sp = 300\n",
    "epochs_bc = 500\n",
    "\n",
    "exprun_path, result_path = bc_factory.external_setup(flow_name, Config()[\"flows_path\"])\n",
    "\n",
    "demopack_path = pathlib.Path(Config()[\"demopacks_path\"], demopack_name)\n",
    "selection = import_demopack(demopack_path, group_chooser_sp_bc_standard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "712da32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Configuration for exp/run: demonstration/automove-pack-01 successfully loaded\n",
      "***The demos considered\n",
      "['bc_testing_00000',\n",
      " 'bc_testing_00001',\n",
      " 'bc_training_00000',\n",
      " 'bc_training_00001',\n",
      " 'bc_training_00002',\n",
      " 'bc_training_00003',\n",
      " 'bc_validation_00000',\n",
      " 'bc_validation_00001',\n",
      " 'sp_testing_00000',\n",
      " 'sp_testing_00001',\n",
      " 'sp_training_00000',\n",
      " 'sp_training_00001',\n",
      " 'sp_training_00002',\n",
      " 'sp_training_00003',\n",
      " 'sp_validation_00000',\n",
      " 'sp_validation_00001']\n"
     ]
    }
   ],
   "source": [
    "# the latent size used throughout this experiment\n",
    "latent_size = 128\n",
    "\n",
    "# FIXME: set the training data through some data structure passed as parameter....\n",
    "# setting the training data\n",
    "# cam = \"dev0\"\n",
    "#run_demo = \"touch-apple\"\n",
    "experiment = \"demonstration\"\n",
    "# run = \"freeform\"\n",
    "# run = \"random-both-cameras\"\n",
    "# run = \"random-both-cameras-video\"\n",
    "exp = Config().get_experiment(experiment, demopack_name)\n",
    "demos = list_demos(exp)\n",
    "print(\"***The demos considered\")\n",
    "pprint.pprint(demos)\n",
    "\n",
    "sp_training_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"sp_training\"]]\n",
    "sp_validation_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"sp_validation\"]]\n",
    "bc_training_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"bc_training\"]]\n",
    "bc_validation_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"bc_validation\"]]\n",
    "\n",
    "\n",
    "# sp_training_data = []\n",
    "# temp = list_demos(exp, \"sp_training\")\n",
    "\n",
    "# for demo in list_demos(exp, \"sp_training\"):\n",
    "#     sp_training_data.append([demopack_name, demo, demonstration_cam])\n",
    "# print(\"***sp_training_data\")\n",
    "# pprint.pprint(sp_training_data)\n",
    "\n",
    "# sp_validation_data = []\n",
    "# for demo in list_demos(exp, \"sp_validation\"):\n",
    "#     sp_validation_data.append([demopack_name, demo, demonstration_cam])\n",
    "\n",
    "# bc_training_data = []\n",
    "# for demo in list_demos(exp, \"bc_training\"):\n",
    "#     bc_training_data.append([demopack_name, demo, demonstration_cam])\n",
    "\n",
    "# bc_validation_data = []\n",
    "# for demo in list_demos(exp, \"bc_validation\"):\n",
    "#     bc_validation_data.append([demopack_name, demo, demonstration_cam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58aa568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sensorprocessing_conv_vae(exprun_path, result_path, params):\n",
    "    \"\"\"Generate the experiment for the conv-vae sensorprocessing with the right training data and parameters. Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation. \"\"\"\n",
    "    val = {}\n",
    "    val[\"latent_size\"] = params[\"latent_size\"]\n",
    "    val[\"epochs\"] = params[\"epochs\"]\n",
    "    val[\"save_period\"] = 5\n",
    "    val[\"training_data\"] = params[\"training_data\"]\n",
    "    val[\"validation_data\"] = params[\"validation_data\"]\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), params[\"exp_sp\"], params[\"run_sp\"] + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"TrainVAE\"\n",
    "    v[\"notebook\"] = \"sensorprocessing/Train_Conv_VAE.ipynb\"\n",
    "    vparams = {}\n",
    "    vparams[\"experiment\"] = params[\"exp_sp\"]\n",
    "    vparams[\"run\"] = params[\"run_sp\"]\n",
    "    vparams[\"external_path\"] = exprun_path.as_posix()\n",
    "    vparams[\"data_path\"] = result_path.as_posix()\n",
    "    v[\"params\"] = vparams\n",
    "\n",
    "    return {\"experiment\": params[\"exp_sp\"], \"runname\": params[\"run_sp\"], \"automation_entry\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d005c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bc_train(exprun_path, result_path, params):\n",
    "    \"\"\"Generate the experiment for the training of behavior cloning with the right training data and parameters. At the same time, it also generates the corresponding bcrun experiment, which will be used to drive the robot.  \n",
    "    \"\"\"    \n",
    "    val = {}\n",
    "    val[\"name\"] = params[\"name\"]\n",
    "    val[\"exp_sp\"] = params[\"exp_sp\"]\n",
    "    val[\"run_sp\"] = params[\"run_sp\"]\n",
    "    # these had not yet been studied for alternatives\n",
    "    val[\"sequence_length\"] = params[\"sequence_length\"]\n",
    "    val[\"loss\"] = params[\"loss\"]\n",
    "    val[\"latent_size\"] = params[\"latent_size\"]\n",
    "    val[\"epochs\"] = params[\"epochs\"]\n",
    "\n",
    "    if params[\"algorithm\"] == \"lstm-mdn\": \n",
    "        val[\"exp_mdn\"] = \"behavior_cloning\"\n",
    "        val[\"run_mdn\"] = \"mdn_for_bc_00\"\n",
    "        val[\"controller\"] = \"bc_LSTM_MDN\"\n",
    "        val[\"controller_file\"] = \"controller.pth\"\n",
    "        val[\"hidden_size\"] = params[\"hidden_size\"]\n",
    "    elif params[\"algorithm\"] == \"lstm\":\n",
    "        val[\"controller\"] = \"bc_LSTM\"\n",
    "        val[\"controller_file\"] = \"controller.pth\"\n",
    "        val[\"num_layers\"] = params[\"num_layers\"]\n",
    "        val[\"hidden_size\"] = params[\"hidden_size\"]\n",
    "    elif params[\"algorithm\"] == \"lstm-residual\":\n",
    "        val[\"controller\"] = \"bc_LSTM_Residual\"\n",
    "        val[\"controller_file\"] = \"controller.pth\"\n",
    "        val[\"hidden_size\"] = params[\"hidden_size\"]\n",
    "    elif params[\"algorithm\"] == \"mlp\":\n",
    "        val[\"controller\"] = \"bc_MLP\"\n",
    "        val[\"controller_file\"] = \"controller.pth\"\n",
    "        val[\"hidden_layers\"] = params[\"hidden_layers\"]\n",
    "        val[\"hidden_layer_1\"] = params[\"hidden_layer_1\"]\n",
    "        val[\"hidden_layer_2\"] = params[\"hidden_layer_2\"]\n",
    "        \n",
    "    else:\n",
    "        raise Exception(f\"*** generate_behaviorcloning: algorithm {params['algorithm']} not yet supported\")\n",
    "    \n",
    "    val[\"control_size\"] = 6 \n",
    "    val[\"training_data\"] = params[\"training_data\"]\n",
    "    val[\"validation_data\"] = params[\"validation_data\"]\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), params[\"exp_bc\"], params[\"run_bc\"] + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"BehaviorCloning\"\n",
    "    v[\"notebook\"] = \"behavior_cloning/Train_BehaviorCloning.ipynb\"\n",
    "    vparams = {}\n",
    "    vparams[\"run\"] = params[\"run_bc\"]\n",
    "    vparams[\"experiment\"] = params[\"exp_bc\"]\n",
    "    vparams[\"external_path\"] = exprun_path.as_posix()\n",
    "    vparams[\"data_path\"] = result_path.as_posix()\n",
    "    v[\"params\"] = vparams\n",
    "\n",
    "    # now, generate the bcrun experiment file, which is the same with the \"runbc_\" prefix\n",
    "    # FIXME: these need to be configurable\n",
    "    valrun = {}\n",
    "    valrun[\"name\"] = f\"generated_run_{params['run_bc']}\"\n",
    "    valrun[\"exp_robot_controller\"] = \"robot_al5d\"\n",
    "    valrun[\"run_robot_controller\"] = \"position_controller_00\"\n",
    "    valrun[\"exp_camera_controller\"] = \"controllers\"\n",
    "    valrun[\"run_camera_controller\"] = \"camera_cam0_controller\"\n",
    "    valrun[\"control_camera\"] = \"dev0\"\n",
    "    valrun[\"exp_bc\"] = \"behavior_cloning\"\n",
    "    valrun[\"run_bc\"] = \"bc_lstm_0001\"\n",
    "\n",
    "    path = pathlib.Path(Config().get_exprun_path(), params[\"exp_bc\"], \"runbc_\"+ params[\"run_bc\"] + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(valrun, f)\n",
    "\n",
    "    return {\"experiment\": params[\"exp_bc\"], \"runname\": params[\"run_bc\"], \"automation_entry\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586402e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bc_verify(exprun_path, result_path, params):\n",
    "    \"\"\"Generate the experiment for the behavior cloning with the right training data and parameters. At the same time, it also generates the corresponding bcrun experiment, which will be used to drive the robot.  \n",
    "    \"\"\"    \n",
    "    val = {}\n",
    "    val[\"exp_sp\"] = params[\"exp_sp\"]\n",
    "    val[\"run_sp\"] = params[\"run_sp\"]\n",
    "    val[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "    val[\"run_bc\"] = params[\"run_bc\"]\n",
    "    val[\"exp_bc_verify\"] = params[\"exp_bc_verify\"]\n",
    "    val[\"run_bc_verify\"] = params[\"run_bc_verify\"]\n",
    "    val[\"verification_data\"] = params[\"verification_data\"]\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), params[\"exp_bc\"], params[\"run_bc\"] + \"_verify.yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"BehaviorCloning\"\n",
    "    v[\"notebook\"] = \"behavior_cloning/Verify_BehaviorCloning.ipynb\"\n",
    "    vparams = {}\n",
    "    vparams[\"run\"] = params[\"run_bc_verify\"]\n",
    "    vparams[\"experiment\"] = params[\"exp_bc_verify\"]\n",
    "    vparams[\"external_path\"] = exprun_path.as_posix()\n",
    "    vparams[\"data_path\"] = result_path.as_posix()\n",
    "    v[\"params\"] = vparams\n",
    "\n",
    "    return {\"experiment\": params[\"exp_bc_verify\"], \"runname\": params[\"run_bc_verify\"], \"automation_entry\": v}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea86368",
   "metadata": {},
   "source": [
    "### Generate a range of exp/runs to be run\n",
    "\n",
    "define which demonstrations will be used for:\n",
    "* training the sensor processing (sp_training_data)\n",
    "* training the behavior cloning (bc_training_data)\n",
    "* verifying the behavior cloning (bc_verification_data) \n",
    "   etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06fb6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# generate sensor processing expruns\n",
    "expruns = []\n",
    "\n",
    "exp_sp = \"sensorprocessing_conv_vae\"\n",
    "run_sp = \"sp_conv_vae_0001\"\n",
    "params = {}\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"epochs\"] = epochs_sp\n",
    "params[\"training_data\"] = sp_training_data\n",
    "params[\"validation_data\"] = sp_validation_data\n",
    "exprun = generate_sensorprocessing_conv_vae(\n",
    "    exprun_path = exprun_path, result_path = result_path, params = params)\n",
    "expruns.append(exprun)\n",
    "\n",
    "# generate the behavior cloning expruns to match with the sensor processing components from above\n",
    "\n",
    "exp_bc = \"behavior_cloning\"\n",
    "\n",
    "# an MLP model\n",
    "params = {}\n",
    "params[\"name\"] = \"MLP 2 hidden\" # should be descriptive\n",
    "params[\"exp_bc\"] = exp_bc\n",
    "params[\"run_bc\"] = \"bc_mlp_0001\"\n",
    "params[\"algorithm\"] = \"mlp\"\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"hidden_layers\"] = 2\n",
    "params[\"hidden_layer_1\"] = 50\n",
    "params[\"hidden_layer_2\"] = 20\n",
    "params[\"epochs\"] = epochs_bc\n",
    "params[\"sequence_length\"] = 1\n",
    "params[\"loss\"] = \"MSELoss\"\n",
    "params[\"training_data\"] = bc_training_data\n",
    "params[\"validation_data\"] = bc_validation_data\n",
    "exprun = generate_bc_train(exprun_path=exprun_path, result_path=result_path, params=params)\n",
    "expruns.append(exprun)\n",
    "# the verification for the MLP model\n",
    "paramsv = {}\n",
    "paramsv[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "paramsv[\"run_bc\"] = params[\"run_bc\"]\n",
    "paramsv[\"exp_sp\"] = exp_sp\n",
    "paramsv[\"run_sp\"] = run_sp\n",
    "paramsv[\"exp_bc_verify\"] = exp_bc\n",
    "paramsv[\"run_bc_verify\"] = \"bc_mlp_0001_verify\"\n",
    "paramsv[\"verification_data\"] = bc_validation_data\n",
    "exprun = generate_bc_verify(exprun_path=exprun_path, result_path=result_path, params=paramsv)\n",
    "expruns.append(exprun)\n",
    "\n",
    "\n",
    "# a pure LSTM model\n",
    "params = {}\n",
    "params[\"name\"] = \"LSTM 2 layers\"\n",
    "params[\"exp_bc\"] = exp_bc\n",
    "params[\"run_bc\"] = \"bc_lstm_0001\"\n",
    "params[\"algorithm\"] = \"lstm\"\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"hidden_size\"] = 32\n",
    "params[\"num_layers\"] = 2\n",
    "params[\"epochs\"] = epochs_bc\n",
    "params[\"sequence_length\"] = 10\n",
    "params[\"loss\"] = \"MSELoss\"\n",
    "params[\"training_data\"] = bc_training_data\n",
    "params[\"validation_data\"] = bc_validation_data\n",
    "exprun = generate_bc_train(exprun_path=exprun_path, result_path=result_path, params=params)\n",
    "expruns.append(exprun)\n",
    "# the verification for the LSTM model\n",
    "paramsv = {}\n",
    "paramsv[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "paramsv[\"run_bc\"] = params[\"run_bc\"]\n",
    "paramsv[\"exp_sp\"] = exp_sp\n",
    "paramsv[\"run_sp\"] = run_sp\n",
    "paramsv[\"exp_bc_verify\"] = exp_bc\n",
    "paramsv[\"run_bc_verify\"] = \"bc_lstm_0001_verify\"\n",
    "paramsv[\"verification_data\"] = bc_validation_data\n",
    "exprun = generate_bc_verify(exprun_path=exprun_path, result_path=result_path, params=paramsv)\n",
    "expruns.append(exprun)\n",
    "\n",
    "# a residual LSTM model\n",
    "params = {}\n",
    "params[\"name\"] = \"LSTM residual\"\n",
    "params[\"exp_bc\"] = exp_bc\n",
    "params[\"run_bc\"] = \"bc_lstm_residual_0001\"\n",
    "params[\"algorithm\"] = \"lstm-residual\"\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"hidden_size\"] = 32\n",
    "params[\"epochs\"] = epochs_bc\n",
    "params[\"sequence_length\"] = 10\n",
    "params[\"loss\"] = \"MSELoss\"\n",
    "params[\"training_data\"] = bc_training_data\n",
    "params[\"validation_data\"] = bc_validation_data\n",
    "exprun = generate_bc_train(exprun_path=exprun_path, result_path=result_path, params=params)\n",
    "expruns.append(exprun)\n",
    "# the verification for the LSTM model\n",
    "paramsv = {}\n",
    "paramsv[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "paramsv[\"run_bc\"] = params[\"run_bc\"]\n",
    "paramsv[\"exp_sp\"] = exp_sp\n",
    "paramsv[\"run_sp\"] = run_sp\n",
    "paramsv[\"exp_bc_verify\"] = exp_bc\n",
    "paramsv[\"run_bc_verify\"] = \"bc_lstm_residual_0001_verify\"\n",
    "paramsv[\"verification_data\"] = bc_validation_data\n",
    "exprun = generate_bc_verify(exprun_path=exprun_path, result_path=result_path, params=paramsv)\n",
    "expruns.append(exprun)\n",
    "\n",
    "# an LSTM-MDN based model\n",
    "params = {}\n",
    "params[\"name\"] = \"LSTM MDN\"\n",
    "params[\"exp_bc\"] = exp_bc\n",
    "params[\"run_bc\"] = \"bc_lstm_mdn_0001\"\n",
    "params[\"algorithm\"] = \"lstm-mdn\"\n",
    "params[\"exp_sp\"] = exp_sp\n",
    "params[\"run_sp\"] = run_sp\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"hidden_size\"] = 32\n",
    "params[\"epochs\"] = epochs_bc\n",
    "params[\"sequence_length\"] = 10\n",
    "params[\"loss\"] = \"MSELoss\"\n",
    "params[\"training_data\"] = bc_training_data\n",
    "params[\"validation_data\"] = bc_validation_data\n",
    "exprun = generate_bc_train(exprun_path=exprun_path, result_path=result_path, params=params)\n",
    "expruns.append(exprun)\n",
    "# the verification for the LSTM-MDN model\n",
    "paramsv = {}\n",
    "paramsv[\"exp_bc\"] = params[\"exp_bc\"]\n",
    "paramsv[\"run_bc\"] = params[\"run_bc\"]\n",
    "paramsv[\"exp_sp\"] = exp_sp\n",
    "paramsv[\"run_sp\"] = run_sp\n",
    "paramsv[\"exp_bc_verify\"] = exp_bc\n",
    "paramsv[\"run_bc_verify\"] = \"bc_lstm_mdn_0001_verify\"\n",
    "paramsv[\"verification_data\"] = bc_validation_data\n",
    "exprun = generate_bc_verify(exprun_path=exprun_path, result_path=result_path, params=paramsv)\n",
    "expruns.append(exprun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b2cd76",
   "metadata": {},
   "source": [
    "### Generate an automation\n",
    "\n",
    "Generate an exp/run of the type \"automate\" based on the list expruns. The individual automation entries should be already in the \"automation_entry\" field. The only thing that is really decided here is the \"creation_style\", which can be exist-ok or discard-old, if we want to start this from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bda9775",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = {}\n",
    "val = []\n",
    "value[\"exps_to_run\"] = val\n",
    "\n",
    "# Use exist_ok not to-re-run previously successfully run models\n",
    "creation_style = \"exist-ok\"\n",
    "# creation_style = \"discard-old\"\n",
    "\n",
    "for exprun in expruns:\n",
    "    v = exprun[\"automation_entry\"]\n",
    "    if \"verify\" in v[\"params\"][\"run\"]:\n",
    "        v[\"params\"][\"creation_style\"] = \"discard-old\"\n",
    "    else:\n",
    "        v[\"params\"][\"creation_style\"] = creation_style\n",
    "    val.append(v)\n",
    "\n",
    "path = pathlib.Path(Config().get_exprun_path(), \"automate\", \"flow_bc.yaml\")\n",
    "with open(path, \"w\") as f:\n",
    "    yaml.dump(value, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee7b64",
   "metadata": {},
   "source": [
    "### Run the automation script\n",
    "\n",
    "Run the automation script, as a series of notebooks. In order to follow the execution inside these notebooks, one needs to open the output notebook, which is in the output_filename. \n",
    "\n",
    "* FIXME: this should be done such that I can also run it from command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce35cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Experiment default config c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BerryPicker-BC-2\\exprun\\automate\\_defaults_automate.yaml was empty, ok.\n",
      "***ExpRun**: Configuration for exp/run: automate/flow_bc successfully loaded\n",
      "***Starting automated running of the flow.\n",
      " The path for the output notebooks is\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BerryPicker-BC-2\\result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating sensorprocessing/Train_Conv_VAE.ipynb :\n",
      " sensorprocessing_conv_vae/sp_conv_vae_0001\n",
      "--> Train_Conv_VAE_sensorprocessing_conv_vae_sp_conv_vae_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0351758b1dc427ebd140107761f7eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/11 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [18:28<2:27:47, 1108.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating behavior_cloning/Train_BehaviorCloning.ipynb :\n",
      " behavior_cloning/bc_mlp_0001\n",
      "--> Train_BehaviorCloning_behavior_cloning_bc_mlp_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb65dd5ab34841d29cf6f10fde2d111b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [18:55<55:05, 472.28s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating behavior_cloning/Verify_BehaviorCloning.ipynb :\n",
      " behavior_cloning/bc_mlp_0001_verify\n",
      "--> Verify_BehaviorCloning_behavior_cloning_bc_mlp_0001_verify_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff92eba761742818bd2b4a48e0a7c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [19:03<26:02, 260.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating behavior_cloning/Train_BehaviorCloning.ipynb :\n",
      " behavior_cloning/bc_lstm_0001\n",
      "--> Train_BehaviorCloning_behavior_cloning_bc_lstm_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e83c99ee51b45f7a37f84f7973a3cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [19:37<14:14, 170.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating behavior_cloning/Verify_BehaviorCloning.ipynb :\n",
      " behavior_cloning/bc_lstm_0001_verify\n",
      "--> Verify_BehaviorCloning_behavior_cloning_bc_lstm_0001_verify_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86acbe48d70545c3811c3290a104152f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [20:07<08:00, 120.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating behavior_cloning/Train_BehaviorCloning.ipynb :\n",
      " behavior_cloning/bc_lstm_residual_0001\n",
      "--> Train_BehaviorCloning_behavior_cloning_bc_lstm_residual_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3144207373b4c61966e8ed222c6c267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [20:55<04:46, 95.51s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating behavior_cloning/Verify_BehaviorCloning.ipynb :\n",
      " behavior_cloning/bc_lstm_residual_0001_verify\n",
      "--> Verify_BehaviorCloning_behavior_cloning_bc_lstm_residual_0001_verify_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d0b93fdcd14c988c64562012549dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [21:25<02:28, 74.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating behavior_cloning/Train_BehaviorCloning.ipynb :\n",
      " behavior_cloning/bc_lstm_mdn_0001\n",
      "--> Train_BehaviorCloning_behavior_cloning_bc_lstm_mdn_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c840f7cc984f3ca4e273fdf2057262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "experiment = \"automate\"\n",
    "run = \"flow_bc\"\n",
    "exp = Config().get_experiment(experiment, run)\n",
    "\n",
    "print(f\"***Starting automated running of the flow.\\n The path for the output notebooks is\\n{result_path}\")\n",
    "\n",
    "for item in tqdm.tqdm(exp[\"exps_to_run\"]):\n",
    "    print(f\"***Automating {item['notebook']} :\\n {item['params']['experiment']}/{item['params']['run']}\")\n",
    "    notebook_path = pathlib.Path(\"..\", item[\"notebook\"])\n",
    "    output_filename = f\"{notebook_path.stem}_{item['params']['experiment']}_{item['params']['run']}_output{notebook_path.suffix}\"\n",
    "    print(f\"--> {output_filename}\")\n",
    "    # pprint.pprint(item[\"params\"])\n",
    "    output_path = pathlib.Path(result_path, output_filename)\n",
    "    try:\n",
    "        papermill.execute_notebook(\n",
    "            notebook_path,\n",
    "            output_path.absolute(),\n",
    "            cwd=notebook_path.parent,\n",
    "            parameters=item[\"params\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"There was an exception {e}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37c8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
