{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff7ba93",
   "metadata": {},
   "source": [
    "# Run behavior cloning\n",
    "\n",
    "Run a behavior cloning based robot controller on a real robot. \n",
    "\n",
    "* Initialize the robot controller and the camera controller, based on the exp\n",
    "* Load the behavior cloning controller based on the exp, together with the sp\n",
    "* Initialize a loop which loads an image through the camera, passes it through the sp, the controller and applies the controller output to the robot. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c8793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approxend module not found, cannot use gamepad\n",
      "***ExpRun**: Loading pointer config file:\n",
      "\tC:\\Users\\lboloni\\.config\\BerryPicker\\mainsettings.yaml\n",
      "***ExpRun**: Loading machine-specific config file:\n",
      "\tG:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\settings-LotziYoga.yaml\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# the gamepad is only available on some machines, and only on Linux\n",
    "available_gamepad = True\n",
    "try:\n",
    "    from robotcontrol.gamepad_controller import GamepadController\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Approxend module not found, cannot use gamepad\")\n",
    "    available_gamepad = False\n",
    "    \n",
    "from robotcontrol.keyboard_controller import KeyboardController\n",
    "from robotcontrol.program_controller import ProgramController\n",
    "\n",
    "# the robot is not always available, this allows us to run the demonstration \n",
    "# without the robot\n",
    "available_robot = False\n",
    "if available_robot:\n",
    "    from robot.al5d_position_controller import PositionController, RobotPosition\n",
    "\n",
    "from camera.camera_controller import CameraController\n",
    "from sensorprocessing.sp_helper import get_transform_to_sp\n",
    "from sensorprocessing.sp_factory import create_sp\n",
    "from bc_factory import create_bc_model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e826508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Configuration for exp/run: behavior_cloning/bc_run_00 successfully loaded\n",
      "***ExpRun**: Experiment default config C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\controllers\\_defaults_controllers.yaml was empty, ok.\n",
      "***ExpRun**: Configuration for exp/run: controllers/robot_position_controller successfully loaded\n",
      "***ExpRun**: Experiment default config C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\controllers\\_defaults_controllers.yaml was empty, ok.\n",
      "***ExpRun**: Configuration for exp/run: controllers/camera_cam0_controller successfully loaded\n",
      "***ExpRun**: Configuration for exp/run: behavior_cloning/bc_mlp_00 successfully loaded\n",
      "***ExpRun**: Configuration for exp/run: sensorprocessing_conv_vae/sp_vae_256 successfully loaded\n"
     ]
    }
   ],
   "source": [
    "experiment = \"behavior_cloning\"\n",
    "run = \"bc_run_00\"\n",
    "\n",
    "exp = Config().get_experiment(experiment, run)\n",
    "\n",
    "exp_robot_controller = Config().get_experiment(exp[\"exp_robot_controller\"], exp[\"run_robot_controller\"])\n",
    "exp_camera_controller = Config().get_experiment(exp[\"exp_camera_controller\"], exp[\"run_camera_controller\"])\n",
    "\n",
    "# the behavior cloning exp/run\n",
    "exp_bc = Config().get_experiment(exp[\"exp_bc\"], exp[\"run_bc\"])\n",
    "# the sensor processing exp/run\n",
    "exp_sp = Config().get_experiment(exp_bc[\"exp_sp\"], exp_bc[\"run_sp\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3391a695",
   "metadata": {},
   "source": [
    "## Initialize the controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f5691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap0 works\n",
      "Warning: logging configuration file is not found in logger\\logger_config.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lboloni\\AppData\\Local\\Temp\\ipykernel_133288\\3986934847.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starting the robot controller\n",
    "if available_robot:\n",
    "    robot_controller = PositionController(exp_robot_controller)\n",
    "else:\n",
    "    robot_controller = None\n",
    "# starting the camere controller\n",
    "camera_controller = CameraController(exp_camera_controller)\n",
    "camera_controller.visualize = True\n",
    "\n",
    "# starting the sensor processing\n",
    "sp = create_sp(exp_sp, device)\n",
    "\n",
    "# load the behavior cloning controller\n",
    "model, _, _ = create_bc_model(exp_bc, exp_sp, device)\n",
    "model_path = pathlib.Path(exp_bc.data_dir(), exp_bc[\"controller_file\"])\n",
    "model.load_state_dict(torch.load(model_path))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789db256",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_interval = 0\n",
    "controller_interval = 0.1\n",
    "\n",
    "# the backlog of the last sequence length steps\n",
    "z_back = []\n",
    "\n",
    "while True:\n",
    "    start_time = time.time() \n",
    "\n",
    "    # Let us assume that the first image here is the one\n",
    "    image = camera_controller.images[0]\n",
    "    # FIXME: this is totally won't work like this\n",
    "    # there should be a notebook with the input processing???\n",
    "    sensor_readings = image\n",
    "    z = sp.process(sensor_readings)\n",
    "    z_back.append(z)\n",
    "    if exp_bc[\"sequence_length\"]: # no sequence processsing\n",
    "        if len(z_back) < exp_bc[\"sequence_length\"]:\n",
    "            ## we don't have enough in the queue, wait.\n",
    "            print(\"Not acting, waiting on the queue\")\n",
    "            pass\n",
    "        else:\n",
    "            # FIXME: this should be applied online, not step by step\n",
    "            input_list = z_back[-exp_bc[\"sequence_length\"]:]\n",
    "            input_nd = np.array(input_list)\n",
    "            z_tensor = torch.tensor(input_nd).unsqueeze(0).to(device)\n",
    "    else:\n",
    "        z_tensor = torch.tensor(input_nd).unsqueeze(0).to(device)\n",
    "    if not model.stochastic:                \n",
    "        a_pred = model(z_tensor)\n",
    "    else:\n",
    "        a_pred = model.forward_and_sample(z_tensor)\n",
    "\n",
    "    # move the robot\n",
    "    pos_target = PositionController.from_normalized_vector(a_pred, exp_robot_controller)\n",
    "    robot_controller.move(pos_target)\n",
    "\n",
    "    # ensuring that the execution happens \n",
    "    end_time = time.time() \n",
    "    execution_time = end_time - start_time \n",
    "    last_interval = execution_time\n",
    "    time_to_sleep = max(0.0, controller_interval - execution_time) \n",
    "    time.sleep(time_to_sleep) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
