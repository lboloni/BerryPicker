{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train behavior cloning\n",
    "\n",
    "Train a behavior cloning based robot controller. \n",
    "* Code for loading and pre-processing the training data, typically from a set of demonstrations as specified in an exp/run\n",
    "* Train the behavior cloning controller. \n",
    "* The trained controllers should be saved into the exp/run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Loading pointer config file:\n",
      "\tC:\\Users\\lboloni\\.config\\BerryPicker\\mainsettings.yaml\n",
      "***ExpRun**: Loading machine-specific config file:\n",
      "\tG:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\settings-LotziYoga.yaml\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import torch\n",
    "torch.manual_seed(1)\n",
    "\n",
    "from bc_trainingdata import create_trainingdata_bc\n",
    "from bc_factory import create_bc_model\n",
    "# FIXME: factor this out\n",
    "from bc_LSTM_MDN import bc_LSTM_MDN, mdn_loss\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\behavior_cloning\\bc_lstm_mdn_00_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: behavior_cloning/bc_lstm_mdn_00 successfully loaded\n",
      "Experiment:\n",
      "    control_size: 6\n",
      "    controller: bc_LSTM_MDN\n",
      "    controller_file: controller.pth\n",
      "    data_dir: c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\behavior_cloning\\bc_lstm_mdn_00\n",
      "    epochs: 10\n",
      "    exp_run_sys_indep_file: C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\behavior_cloning\\bc_lstm_mdn_00.yaml\n",
      "    experiment_name: behavior_cloning\n",
      "    hidden_size: 32\n",
      "    loss: MSELoss\n",
      "    mdn_experiment: behavior_cloning\n",
      "    mdn_run: mdn_for_bc_00\n",
      "    name: bc_lstm_mdn_00\n",
      "    optimizer: Adam\n",
      "    optimizer_lr: 0.001\n",
      "    run_name: bc_lstm_mdn_00\n",
      "    sequence_lenght: 10\n",
      "    sequence_length: 10\n",
      "    sp_experiment: sensorprocessing_conv_vae\n",
      "    sp_run: sp_vae_256\n",
      "    subrun_name: null\n",
      "    test_data:\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_23_19'\n",
      "      - dev2\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_24_52'\n",
      "      - dev2\n",
      "    training_data:\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_15_53'\n",
      "      - dev2\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_16_57'\n",
      "      - dev2\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_19_12'\n",
      "      - dev2\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_21_28'\n",
      "      - dev2\n",
      "\n",
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\sensorprocessing_conv_vae\\sp_vae_256_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: sensorprocessing_conv_vae/sp_vae_256 successfully loaded\n",
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\robot_al5d\\position_controller_00_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: robot_al5d/position_controller_00 successfully loaded\n"
     ]
    }
   ],
   "source": [
    "experiment = \"behavior_cloning\"\n",
    "# run = \"bc_mlp_00\"\n",
    "# run = \"bc_lstm_00\"\n",
    "# run = \"bc_lstm_resid_00\"\n",
    "run = \"bc_lstm_mdn_00\"\n",
    "exp = Config().get_experiment(experiment, run)\n",
    "\n",
    "#exp = Config().get_experiment(experiment, run, creation_style=\"discard-old\")\n",
    "pprint.pprint(exp)\n",
    "spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
    "\n",
    "robot_exp = Config().get_experiment(\"robot_al5d\", \"position_controller_00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an RNN model\n",
    "Functions for training an RNN type model. These models assume that the input is a sequence $[z_{t-k},...z_{t}]$ while the output is the next action $a_{t+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_bc_rnn(model, criterion, data, device):\n",
    "    \"\"\"Calculates the average validation error for the behavior cloning model using an RNN with the specific criterion function. Uses the z_validation an a_validation fields in \"data\". The inputs and the targets a list of individual input and target. \n",
    "    CHECK: I think that the target is supposed to be the last output of the RNN when the whole input string had been passed through it. \n",
    "    The model is reset before each of the strings (i.e. state is not transferred)\n",
    "    model: an LSTM or similar model that can consume a sequence of inputs\n",
    "    criterion: any function that calculates the distance between the targets\n",
    "    \"\"\"\n",
    "    num_sequences = data[\"z_validation\"].shape[0]\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for i in range(num_sequences):\n",
    "            # Forward pass\n",
    "            input_seq = data[\"z_validation\"][i].to(device)\n",
    "            target = data[\"a_validation\"][i].to(device)\n",
    "            # Reshape for batch compatibility\n",
    "            input_seq = input_seq.unsqueeze(0)  # Shape: [1, sequence_length, latent_size]\n",
    "            target = target.unsqueeze(0)        # Shape: [1, latent_size]\n",
    "            if not isinstance(model, bc_LSTM_MDN):\n",
    "                outputs = model(input_seq)\n",
    "                loss = criterion(outputs, target)\n",
    "            else: # for MDN, the output is sampling (in the future) but still using the criterion even if we didn't use it for training\n",
    "                outputs = model.forward_and_sample(input_seq)\n",
    "                # unclear why this is necessary\n",
    "                # outputs = outputs.to(device)\n",
    "                loss = criterion(outputs, target)\n",
    "                # outputs = model.forward(input_seq)\n",
    "                #loss = mdn_loss(target, *outputs)\n",
    "            # Accumulate loss\n",
    "            val_loss += loss.item()\n",
    "    avg_loss = val_loss / num_sequences\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bc_rnn(model, optimizer, criterion, data, num_epochs, writer = None):\n",
    "    \"\"\"Train a behavior cloning model using a sequence model (eg. an RNN)\n",
    "    Uses a writer for TensorBoard _and_ tqdm\n",
    "    \"\"\"\n",
    "    exp.start_timer(\"train\")\n",
    "    num_sequences = data[\"z_train\"].shape[0]\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        \n",
    "        # Loop over each sequence in the batch\n",
    "        training_loss = 0\n",
    "        for i in range(num_sequences):\n",
    "            # Prepare input and target\n",
    "            input_seq = data[\"z_train\"][i].to(device)\n",
    "            target = data[\"a_train\"][i].to(device)\n",
    "\n",
    "            # Reshape for batch compatibility\n",
    "            input_seq = input_seq.unsqueeze(0)  # Shape: [1, sequence_length, latent_size]\n",
    "            target = target.unsqueeze(0)        # Shape: [1, latent_size]\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(input_seq)\n",
    "            # Check for MDN, that is different\n",
    "            if not isinstance(model, bc_LSTM_MDN):\n",
    "                loss = criterion(output, target)\n",
    "            else: \n",
    "                loss = mdn_loss(target, *output)\n",
    "            training_loss += loss.item()\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_training_loss = training_loss / num_sequences\n",
    "        avg_validation_loss = validate_bc_rnn(model, criterion, data, device)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"TrainingLoss\", avg_training_loss, epoch)\n",
    "            writer.add_scalar(\"ValidationLoss\", avg_validation_loss, epoch)\n",
    "            writer.flush()\n",
    "        if (epoch+1) % 2 == 0: # was 0\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_training_loss:.4f} Validation Loss: {avg_validation_loss:.4f} ')\n",
    "    print(\"Training complete.\")\n",
    "    exp.end_timer(\"train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model \n",
    "\n",
    "Creates and trains a behavior cloning model specified by the exp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\behavior_cloning\\mdn_for_bc_00_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: behavior_cloning/mdn_for_bc_00 successfully loaded\n",
      "bc_LSTM_MDN(\n",
      "  (lstm_1): LSTM(256, 32, batch_first=True)\n",
      "  (lstm_2): LSTM(32, 32, batch_first=True)\n",
      "  (lstm_3): LSTM(32, 32, batch_first=True)\n",
      "  (mdn): MDN(\n",
      "    (fc1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (fc3): Linear(in_features=32, out_features=90, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model, criterion, optimizer = create_bc_model(exp, spexp, device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Timer*** data_preparation started\n",
      "***Timer*** data_preparation finished in 0.018721 seconds\n",
      "***Timer*** train started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\lboloni\\Documents\\Code\\_VirtualEnvironments\\Robot\\Robot-venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([1, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|          | 0/10 [00:24<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create a SummaryWriter instance\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# where does the logdir go???\u001b[39;00m\n\u001b[0;32m      7\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(logdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/lboloni/runs/example\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrain_bc_rnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     12\u001b[0m controller_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(exp\u001b[38;5;241m.\u001b[39mdata_dir(), exp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontroller_file\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[4], line 36\u001b[0m, in \u001b[0;36mtrain_bc_rnn\u001b[1;34m(model, optimizer, criterion, data, num_epochs, writer)\u001b[0m\n\u001b[0;32m     33\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     35\u001b[0m avg_training_loss \u001b[38;5;241m=\u001b[39m training_loss \u001b[38;5;241m/\u001b[39m num_sequences\n\u001b[1;32m---> 36\u001b[0m avg_validation_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_bc_rnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainingLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m, avg_training_loss, epoch)\n",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m, in \u001b[0;36mvalidate_bc_rnn\u001b[1;34m(model, criterion, data, device)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# for MDN, the output is sampling (in the future) but still using the criterion even if we didn't use it for training\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward_and_sample(input_seq)\n\u001b[1;32m---> 24\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# outputs = model.forward(input_seq)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m#loss = mdn_loss(target, *outputs)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Accumulate loss\u001b[39;00m\n\u001b[0;32m     28\u001b[0m val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_VirtualEnvironments\\Robot\\Robot-venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_VirtualEnvironments\\Robot\\Robot-venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_VirtualEnvironments\\Robot\\Robot-venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_VirtualEnvironments\\Robot\\Robot-venv\\Lib\\site-packages\\torch\\nn\\functional.py:3384\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3381\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m   3383\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[1;32m-> 3384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "\n",
    "data = create_trainingdata_bc(exp, spexp, robot_exp, device=\"cpu\")\n",
    "# Training Loop\n",
    "num_epochs = exp[\"epochs\"]\n",
    "\n",
    "# Create a SummaryWriter instance\n",
    "# where does the logdir go???\n",
    "writer = SummaryWriter(logdir=\"/home/lboloni/runs/example\")\n",
    "train_bc_rnn(\n",
    "        model, optimizer, criterion, data=data,\n",
    "        num_epochs=num_epochs, writer=writer)\n",
    "writer.close()\n",
    "controller_path = pathlib.Path(exp.data_dir(), exp[\"controller_file\"])\n",
    "torch.save(model.state_dict(), controller_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
