{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train behavior cloning\n",
    "\n",
    "Train a behavior cloning based robot controller. \n",
    "* Code for loading and pre-processing the training data, typically from a set of demonstrations as specified in an exp/run\n",
    "* Train the controller. \n",
    "* The trained controllers should be saved into the exp/run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import torch\n",
    "torch.manual_seed(1)\n",
    "\n",
    "from bc_trainingdata import create_trainingdata_bc\n",
    "from bc_factory import create_bc_model\n",
    "from bc_LSTM_MDN import mdn_loss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp/run initialization\n",
    "Create the exp/run-s that describe the parameters of the training. Some of the code here is structured in such a way as to make the notebook automatizable with papermill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# *** Initialize the variables with default values \n",
    "# *** This cell should be tagged as parameters     \n",
    "# *** If papermill is used, some of the values will be overwritten \n",
    "\n",
    "# If it is set to true, the exprun will be recreated from scratch\n",
    "creation_style = \"exist-ok\"\n",
    "\n",
    "# If not None, set an external experiment path\n",
    "external_path = None\n",
    "# If not None, set an output path\n",
    "data_path = None\n",
    "\n",
    "experiment = \"behavior_cloning\"\n",
    "run = None\n",
    "# run = \"bc_lstm_00\"\n",
    "# run = \"bc_lstm_resid_00\"\n",
    "# run = \"bc_lstm_mdn_00\"\n",
    "# exp = Config().get_experiment(experiment, run)\n",
    "\n",
    "# **** The settings below are used to debug a particular run in flow \n",
    "# **** They do not affect the run of the flow, \n",
    "# **** because they are going to be overwritten by papermill\n",
    "data_path = \"c:/Users/lotzi/Work/_Data/BerryPicker-Flows/BerryPicker-BC/result\"\n",
    "experiment = \"behavior_cloning\"\n",
    "external_path = \"c:/Users/lotzi/Work/_Data/BerryPicker-Flows/BerryPicker-BC/exprun\"\n",
    "run = \"bc_mlp_0001\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if external_path:\n",
    "    external_path = pathlib.Path(external_path)\n",
    "    assert external_path.exists()\n",
    "    Config().set_exprun_path(external_path)\n",
    "    Config().copy_experiment(\"sensorprocessing_conv_vae\")\n",
    "    Config().copy_experiment(\"robot_al5d\")\n",
    "    Config().copy_experiment(\"demonstration\")\n",
    "    Config().copy_experiment(\"behavior_cloning\")\n",
    "if data_path:\n",
    "    data_path = pathlib.Path(data_path)\n",
    "    assert data_path.exists()\n",
    "    Config().set_results_path(data_path)\n",
    "\n",
    "exp = Config().get_experiment(experiment, run, creation_style=creation_style)\n",
    "pprint.pprint(exp)\n",
    "exp_sp = Config().get_experiment(exp[\"exp_sp\"], exp[\"run_sp\"])\n",
    "exp_robot = Config().get_experiment(exp[\"exp_robot\"], exp[\"run_robot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an RNN model\n",
    "Functions for training an RNN type model. These models assume that the input is a sequence $[z_{t-k},...z_{t}]$ while the output is the next action $a_{t+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_bc_rnn(model, validation_loss, data):\n",
    "    \"\"\"Calculates the average validation error for the behavior cloning model using an RNN with the specific criterion function. Uses the z_validation an a_validation fields in \"data\". The inputs and the targets a list of individual input and target. \n",
    "    CHECK: I think that the target is supposed to be the last output of the RNN when the whole input string had been passed through it. \n",
    "    The model is reset before each of the strings (i.e. state is not transferred)\n",
    "    model: an LSTM or similar model that can consume a sequence of inputs\n",
    "    criterion: any function that calculates the distance between the targets\n",
    "    \"\"\"\n",
    "    num_sequences = data[\"z_validation\"].shape[0]\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for i in range(num_sequences):\n",
    "            input_seq = data[\"z_validation\"][i].to(Config().runtime[\"device\"])\n",
    "            target = data[\"a_validation\"][i].to(Config().runtime[\"device\"])\n",
    "            # Reshape for batch compatibility\n",
    "            input_seq = input_seq.unsqueeze(0)  # Shape: [1, sequence_length, latent_size]\n",
    "            target = target.unsqueeze(0)        # Shape: [1, latent_size]\n",
    "            if not model.stochastic:\n",
    "                outputs = model(input_seq)\n",
    "                loss = validation_loss(outputs, target)\n",
    "            else: # for MDN, the output is sampling\n",
    "                outputs = model.forward_and_sample(input_seq)\n",
    "            loss = validation_loss(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "    avg_loss = val_loss / num_sequences\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bc_rnn(model, optimizer, criterion, data, num_epochs, batch_size=32):\n",
    "    \"\"\"Train a behavior cloning model using a sequence model (eg. an RNN)\n",
    "    Uses a writer for TensorBoard _and_ tqdm\n",
    "    Model with batch\n",
    "    \"\"\"\n",
    "\n",
    "    exp.start_timer(\"train\")\n",
    "    num_sequences = data[\"z_train\"].shape[0]\n",
    "    num_batches = num_sequences // batch_size\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):        \n",
    "        model.train()\n",
    "        # Loop over each sequence in the batch\n",
    "        training_loss = 0\n",
    "        for i in range(num_batches):\n",
    "            # Prepare input and target\n",
    "            input_seq = data[\"z_train\"][i * batch_size: (i+1)* batch_size].to(Config().runtime[\"device\"]) # Shape: [batch_size, sequence_length, latent_size]\n",
    "            target = data[\"a_train\"][i * batch_size: (i+1)* batch_size].to(Config().runtime[\"device\"]) # Shape: [batch_size, latent_size]\n",
    "            # Forward pass\n",
    "            output = model(input_seq) # Shape: [batch_size, output_size]\n",
    "            # Check for MDN, that is different\n",
    "            if not model.stochastic:\n",
    "                loss = criterion(output, target)\n",
    "            else: \n",
    "                loss = mdn_loss(target, *output)\n",
    "            training_loss += loss.item()\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()        \n",
    "        avg_training_loss = training_loss / num_sequences\n",
    "\n",
    "        #if writer is not None:\n",
    "        #    writer.add_scalar(\"TrainingLoss\", avg_training_loss, epoch)\n",
    "        #    writer.add_scalar(\"ValidationLoss\", avg_validation_loss, epoch)\n",
    "        #    writer.flush()\n",
    "        if (epoch+1) % 5 == 0: # was 0\n",
    "            avg_validation_loss = validate_bc_rnn(model, criterion, data)\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_training_loss:.4f} Validation Loss: {avg_validation_loss:.4f} ')\n",
    "    print(\"Training complete.\")\n",
    "    exp.end_timer(\"train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model \n",
    "\n",
    "Creates and trains a behavior cloning model specified by the exp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_path = pathlib.Path(exp.data_dir(), exp[\"controller_file\"])\n",
    "\n",
    "if controller_path.exists():\n",
    "    print(\"***Train_BehaviorCloning: Controller exists. Re-run with creation-style=discard-old to recompute.\")\n",
    "else:\n",
    "    print(\"***Train_BehaviorCloning: Proceeding to train the controller.\")\n",
    "    model, validation_loss, optimizer = create_bc_model(exp, exp_sp, device)\n",
    "    print(model)\n",
    "\n",
    "    # data = create_trainingdata_bc(exp, exp_sp, exp_robot, device=\"cpu\")\n",
    "    data = create_trainingdata_bc(exp, exp_sp, exp_robot)\n",
    "    # Training Loop\n",
    "    num_epochs = exp[\"epochs\"]\n",
    "    batch_size = exp[\"batch_size\"]\n",
    "\n",
    "    # Create a SummaryWriter instance\n",
    "    # where does the logdir go???\n",
    "    # writer = SummaryWriter(logdir=\"/home/lboloni/runs/example\")\n",
    "    train_bc_rnn(\n",
    "            model, optimizer, validation_loss, data=data,\n",
    "            num_epochs=num_epochs, batch_size=batch_size)\n",
    "    # writer.close()\n",
    "    torch.save(model.state_dict(), controller_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
