{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bea14d",
   "metadata": {},
   "source": [
    "# Visual proprioception flow\n",
    "\n",
    "Create the full flow for training models for visual proprioception. This notebook programmatically generates a set of exp/runs that cover all the necessary components for a visual proprioception system (sensor processing,  visual proprioception regressor and verification notebooks).\n",
    "\n",
    "Then, it writes the exp/runs into an external directory full separated from the github source, and creates an automation script that runs them. A separate directory for the results is also created. \n",
    "\n",
    "Finally, it runs the necessary notebooks to execute the whole flow using papermill.\n",
    "\n",
    "The results directory contain the output of this flow, both in terms of trained models, as well as results (in the verification exp/run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a83531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pprint\n",
    "import copy\n",
    "import socket\n",
    "import pathlib\n",
    "import yaml\n",
    "import tqdm\n",
    "import papermill\n",
    "# from automate import automate_exprun\n",
    "import visproprio_helper \n",
    "from demonstration.demonstration import list_demos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b173f38",
   "metadata": {},
   "source": [
    "# Setting up the separate directory\n",
    "Setting up a separate directory for generated exp/run config files and the results. This cell will create a new directory. \n",
    "\n",
    "__Note__\n",
    "Currently, as of 2025-09-03, we don't have a way to put the training data into this directory. Which means that once the code below creates the new directories, we need to manually copy the demonstrations as follows:\n",
    "* the demonstration descriptor (eg. {demonstration_run}.yaml) into {directory_name}/exprun/demonstration\n",
    "* the demonstration runs into {directory_name}/result/demonstration/{demonstration_run}/\n",
    "\n",
    "It would be useful to set up a special import mechanism for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ac9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most likely changing names.\n",
    "directory_name = \"VisualProprioception_flow_00\"\n",
    "demonstration_cam = \"dev0\"\n",
    "demonstration_run = \"touch-apple\"\n",
    "\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "print(f\"***Hostname is {hostname}\")\n",
    "if hostname == \"raven\":\n",
    "    rootdir = pathlib.Path(f\"~/WORK/_DataExternal/\").expanduser()\n",
    "elif hostname == \"szenes.local\":\n",
    "    rootdir = pathlib.Path(f\"~/Documents/Develop/Data/\").expanduser()\n",
    "elif hostname == \"glassy\":\n",
    "    rootdir = pathlib.Path(f\"~/Work/_DataExternal/\").expanduser()\n",
    "else:\n",
    "    rootdir = pathlib.Path(Config()[\"experiment_external\"])\n",
    "exprun_path, result_path = visproprio_helper.external_setup(directory_name, rootdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d27c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sensorprocessing_conv_vae(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the training of the conv-vae sensorprocessing with the right training data and parameters. Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation. \n",
    "    NOTE: a similar function is in Flow_BehaviorCloning.\n",
    "    \"\"\"\n",
    "    val = {}\n",
    "    val[\"latent_size\"] = params[\"latent_size\"]\n",
    "    val[\"epochs\"] = params[\"epochs\"]\n",
    "    val[\"save_period\"] = 5\n",
    "    val[\"training_data\"] = params[\"training_data\"]\n",
    "    val[\"validation_data\"] = params[\"validation_data\"]\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_experiment_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"Train_SP_Conv-VAE\"\n",
    "    v[\"notebook\"] = \"sensorprocessing/Train-Conv-VAE.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sensorprocessing_propriotuned_cnn(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the training of the propriotuned CNN with the right training data and parameters. \n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation. \n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_experiment_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"Train_SP_Conv-VAE\"\n",
    "    v[\"notebook\"] = \"sensorprocessing/Train-Conv-VAE.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28cd090",
   "metadata": {},
   "source": [
    "### Generate the exp/runs to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b8ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "expruns = []\n",
    "# overall values\n",
    "latent_size = 128\n",
    "#\n",
    "# Configuring the training and validation data, based \n",
    "# on all the demonstrations of a particular type\n",
    "#\n",
    "experiment = \"demonstration\"\n",
    "exp = Config().get_experiment(experiment, demonstration_run)\n",
    "demos = list_demos(exp)\n",
    "print(\"***The demos considered\")\n",
    "pprint.pprint(demos)\n",
    "# create a data structure from all the data directories \n",
    "# we considered\n",
    "data = []\n",
    "for demo in demos:\n",
    "    data.append([demonstration_run, demo, demonstration_cam])\n",
    "# the training data used to train/validate the sensor processor\n",
    "sp_training_data = data[0:2]\n",
    "sp_validation_data = data[2:4]\n",
    "# the training data used to train/validate the visual proprioception regressor\n",
    "vp_training_data = data[4:6]\n",
    "vp_validation_data = data[6:]\n",
    "\n",
    "# determine these values based on experience\n",
    "epochs_sp = 300\n",
    "epochs_bc = 500\n",
    "\n",
    "# generate the vae exprun\n",
    "exp_name = \"sensorprocessing_conv_vae\"\n",
    "run_name = \"sp_conv_vae_0001\"\n",
    "params = {}\n",
    "params[\"latent_size\"] = latent_size\n",
    "params[\"epochs\"] = epochs_sp\n",
    "params[\"training_data\"] = sp_training_data\n",
    "params[\"validation_data\"] = sp_validation_data\n",
    "exprun = generate_sensorprocessing_conv_vae(\n",
    "    exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name = run_name)\n",
    "expruns.append(exprun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472e844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
