{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bea14d",
   "metadata": {},
   "source": [
    "# Visual proprioception flow\n",
    "\n",
    "Create the full flow for training models for visual proprioception. This notebook programmatically generates a set of exp/runs that cover all the necessary components for a visual proprioception system (sensor processing,  visual proprioception regressor and verification notebooks).\n",
    "\n",
    "Then, it writes the exp/runs into an external directory full separated from the github source, and creates an automation script that runs them. A separate directory for the results is also created. \n",
    "\n",
    "Finally, it runs the necessary notebooks to execute the whole flow using papermill.\n",
    "\n",
    "The results directory contain the output of this flow, both in terms of trained models, as well as results (in the verification exp/run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8a83531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import copy\n",
    "import pprint\n",
    "import pathlib\n",
    "import yaml\n",
    "import tqdm\n",
    "import papermill\n",
    "import visproprio_helper\n",
    "from demonstration.demonstration import list_demos\n",
    "from demonstration.demopack import import_demopack, group_chooser_sp_vp_standard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b173f38",
   "metadata": {},
   "source": [
    "# Setting up the separate directory\n",
    "Setting up a separate directory for generated exp/run config files and the results. This cell will create a new directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "997ac9a7",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# the most likely changing things\n",
    "flow_name = \"VisualProprioception_flow_08\"\n",
    "# flow_name = \"cvpr_simulation_054\"\n",
    "#demonstration_run = \"touch-apple\"\n",
    "#demopack_name = \"touch-apple\"\n",
    "# demopack_name = \"automove-pack-01\"\n",
    "# demopack_name = \"cvpr-simulation\"\n",
    "demopack_name = \"random-both-cameras-video\"\n",
    "demonstration_cam = \"dev2\"\n",
    "# demonstration_cam = \"dev054\"\n",
    "\n",
    "do_VAE = False\n",
    "do_VGG = False\n",
    "do_RESNET = False\n",
    "do_VIT = True\n",
    "# determine these values based on experience\n",
    "epochs_sp = 10\n",
    "# epochs_vp = 1000\n",
    "# epochs_sp = 300 # way too much, at least for VAE\n",
    "epochs_vp = 10\n",
    "image_size = [256, 256] # for vgg... etc\n",
    "\n",
    "# Use exist_ok not to-re-run previously successfully run models\n",
    "creation_style = \"exist-ok\"\n",
    "# creation_style = \"discard-old\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8448e1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demopacks base: /home/sa641631/WORK/BerryPicker-Demopacks\n",
      "Base exists: True\n",
      "Demopack path: /home/sa641631/WORK/BerryPicker-Demopacks/random-both-cameras-video\n",
      "Demopack exists: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "demopacks_base = pathlib.Path(Config()[\"demopacks_path\"]).expanduser()\n",
    "demopack_name = \"random-both-cameras-video\"\n",
    "demopack_path = pathlib.Path(demopacks_base, demopack_name)\n",
    "print(f\"Demopacks base: {demopacks_base}\")\n",
    "print(f\"Base exists: {demopacks_base.exists()}\")\n",
    "print(f\"Demopack path: {demopack_path}\")\n",
    "print(f\"Demopack exists: {demopack_path.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83eff4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Path for external experiments:\n",
      "/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_07/exprun\n",
      "***Path for external data:\n",
      "/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_07/result\n",
      "***ExpRun**: Experiment config path changed to /home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_07/exprun\n",
      "***ExpRun**: Experiment data path changed to /home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_07/result\n",
      "***ExpRun**: Experiment demonstration copied to\n",
      "/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_07/exprun/demonstration\n",
      "***ExpRun**: Experiment sensorprocessing_conv_vae copied to\n",
      "/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_07/exprun/sensorprocessing_conv_vae\n",
      "***ExpRun**: Experiment sensorprocessing_propriotuned_cnn copied to\n",
      "/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_07/exprun/sensorprocessing_propriotuned_cnn\n",
      "***ExpRun**: Experiment sensorprocessing_propriotuned_Vit copied to\n",
      "/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_07/exprun/sensorprocessing_propriotuned_Vit\n",
      "***ExpRun**: Experiment sensorprocessing_aruco copied to\n",
      "/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_07/exprun/sensorprocessing_aruco\n",
      "***ExpRun**: Experiment visual_proprioception copied to\n",
      "/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_07/exprun/visual_proprioception\n",
      "*** import_demopack: /home/sa641631/WORK/BerryPicker-Demopacks/random-both-cameras-video, target directory /home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_07/result/demonstration/random-both-cameras-video  already exists, not copying\n",
      "***ExpRun**: Configuration for exp/run: demonstration/random-both-cameras-video successfully loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# exprun_path, result_path = visproprio_helper.external_setup(flow_name, Config()[\"flows_path\"])\n",
    "\n",
    "exprun_path, result_path = visproprio_helper.external_setup(\n",
    "    flow_name,\n",
    "    pathlib.Path(Config()[\"flows_path\"]).expanduser()  # ✅ Added here too my paths were not working with ~ could be a winows vs linux thing?\n",
    ")\n",
    "\n",
    "demopack_path = pathlib.Path(Config()[\"demopacks_path\"], demopack_name).expanduser()\n",
    "selection = import_demopack(demopack_path, group_chooser_sp_vp_standard)\n",
    "#\n",
    "# Configuring the training and validation data, based\n",
    "# on all the demonstrations of a particular type\n",
    "#\n",
    "experiment = \"demonstration\"\n",
    "exp = Config().get_experiment(experiment, demopack_name)\n",
    "\n",
    "sp_training_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"sp_training\"]]\n",
    "sp_validation_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"sp_validation\"]]\n",
    "vp_training_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"vp_training\"]]\n",
    "vp_validation_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"vp_validation\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be9a19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_training': ['sp_training_00000', 'sp_training_00001', 'sp_training_00002', 'sp_training_00003'], 'sp_validation': ['sp_validation_00000', 'sp_validation_00001'], 'sp_testing': ['sp_testing_00000', 'sp_testing_00001'], 'vp_training': ['vp_training_00000', 'vp_training_00001', 'vp_training_00002', 'vp_training_00003'], 'vp_validation': ['vp_validation_00000', 'vp_validation_00001'], 'vp_testing': ['vp_testing_00000', 'vp_testing_00001']}\n"
     ]
    }
   ],
   "source": [
    "print(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca2ada4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sp_training_00001', 'sp_training_00003', 'sp_testing_00000', 'sp_validation_00001', 'sp_testing_00001', 'sp_training_00000', 'sp_training_00002', 'sp_validation_00000']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sp_training_00001',\n",
       " 'sp_training_00003',\n",
       " 'sp_training_00000',\n",
       " 'sp_training_00002']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demos = list_demos(exp)\n",
    "# print(demos)\n",
    "print(list_demos(exp, \"sp\"))\n",
    "[s for s in demos if s.startswith(\"sp_training\" + \"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6d27c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sp_conv_vae(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the training of the conv-vae sensorprocessing with the right training data and parameters. Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation.\n",
    "    NOTE: a similar function is in Flow_BehaviorCloning.\n",
    "    \"\"\"\n",
    "    val = {}\n",
    "    val[\"latent_size\"] = params[\"latent_size\"]\n",
    "    val[\"epochs\"] = params[\"epochs\"]\n",
    "    val[\"save_period\"] = 5\n",
    "    val[\"training_data\"] = params[\"training_data\"]\n",
    "    val[\"validation_data\"] = params[\"validation_data\"]\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file\n",
    "    v = {}\n",
    "    v[\"name\"] = \"Train_SP_Conv-VAE\"\n",
    "    v[\"notebook\"] = \"sensorprocessing/Train_Conv_VAE.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d97895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sp_propriotuned_cnn(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the training of the propriotuned CNN with the right training data and parameters.\n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation.\n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "    val[\"output_size\"] = 6\n",
    "    val[\"batch_size\"] = 32\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file\n",
    "    v = {}\n",
    "    v[\"name\"] = \"Train_SP_CNN\"\n",
    "    v[\"notebook\"] = \"sensorprocessing/Train_ProprioTuned_CNN.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "241edda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sp_propriotuned_vit(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the training of the propriotuned ViT with the right training data and parameters.\n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation.\n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "    val[\"output_size\"] = 6\n",
    "    val[\"batch_size\"] = 32\n",
    "\n",
    "    # val[\"robot_exp\"] = \"robot_al5d\"\n",
    "    # val[\"robot_run\"] = \"robot_al5d\"\n",
    "    # val[\"proprioception_mlp_model_file\"] = \"proprioception_mlp.pth\"\n",
    "\n",
    "    # ViT-specific additions\n",
    "    # val[\"robot_exp\"] = \"robot_al5d\"\n",
    "    # val[\"robot_run\"] = \"robot_al5d\"\n",
    "    # val[\"proprioception_mlp_model_file\"] = \"proprioception_mlp.pth\"\n",
    "\n",
    "    # ViT architecture parameters based on model type\n",
    "    if params[\"vit_model\"] == \"vit_base\":\n",
    "        val[\"vit_model\"] = \"vit_b_16\"\n",
    "        val[\"vit_output_dim\"] = 768\n",
    "        val[\"projection_hidden_dim\"] = 512\n",
    "    elif params[\"vit_model\"] == \"vit_large\":\n",
    "        val[\"vit_model\"] = \"vit_l_16\"\n",
    "        val[\"vit_output_dim\"] = 1024\n",
    "        val[\"projection_hidden_dim\"] = 768\n",
    "\n",
    "    val[\"vit_weights\"] = \"DEFAULT\"\n",
    "    val[\"proprio_step_1\"] = 64\n",
    "    val[\"proprio_step_2\"] = 64\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file\n",
    "    v = {}\n",
    "    v[\"name\"] = \"Train_SP_ViT\"\n",
    "    v[\"notebook\"] = \"sensorprocessing/Train_ProprioTuned_VIT.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "476839eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vp_train(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the training visual proprioception regressor.\n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation.\n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file\n",
    "    v = {}\n",
    "    v[\"name\"] = f\"Train_{run_name}\"\n",
    "    v[\"notebook\"] = \"visual_proprioception/Train_VisualProprioception.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b99c9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vp_verify(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the verification of the visual proprioception regressor.\n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation.\n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file\n",
    "    v = {}\n",
    "    v[\"name\"] = f\"Verify_{run_name}\"\n",
    "    v[\"notebook\"] = \"TODO Verify.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f64e6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vp_compare(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the verification of the visual proprioception regressor.\n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation.\n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "    val[\"name\"] = exp_name\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file\n",
    "    v = {}\n",
    "    v[\"name\"] = f\"Compare_{run_name}\"\n",
    "    v[\"notebook\"] = \"visual_proprioception/Compare_VisualProprioception.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28cd090",
   "metadata": {},
   "source": [
    "### Generate the exp/runs to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "020b8ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensorprocessing_propriotuned_Vit sp_vit_base_128_0001 128\n",
      "sensorprocessing_propriotuned_Vit sp_vit_base_256_0001 256\n"
     ]
    }
   ],
   "source": [
    "expruns = []\n",
    "# overall values\n",
    "latent_sizes = [128, 256] # the possible latent sizes we consider\n",
    "cnntypes = [\"vgg19\", \"resnet50\"] # the CNN architectures we consider\n",
    "vit_types = [\"vit_base\"] #VIT Types, we can add vit-huge here as well\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *******************************************\n",
    "# generate the sensorprocessing models\n",
    "# *******************************************\n",
    "sps = [] # the list of the sensorprocessing models (exp/run)\n",
    "for latent_size in latent_sizes:\n",
    "\n",
    "    # generate the vae exprun\n",
    "    exp_name = \"sensorprocessing_conv_vae\"\n",
    "    run_name = f\"sp_conv_vae_{latent_size}_0001\"\n",
    "    params = {}\n",
    "    params[\"latent_size\"] = latent_size\n",
    "    params[\"epochs\"] = epochs_sp\n",
    "    params[\"training_data\"] = sp_training_data\n",
    "    params[\"validation_data\"] = sp_validation_data\n",
    "    exprun = generate_sp_conv_vae(\n",
    "        exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name = run_name)\n",
    "    exprun[\"latent_size\"] = latent_size\n",
    "    if do_VAE:\n",
    "        sps.append(exprun)\n",
    "        expruns.append(exprun)\n",
    "\n",
    "    if do_VIT:\n",
    "        for vit_type in vit_types:\n",
    "            exp_name = \"sensorprocessing_propriotuned_Vit\"\n",
    "            run_name = f\"sp_{vit_type}_{latent_size}_0001\"\n",
    "            params = {}\n",
    "            params[\"image_size\"] = [224, 224]  # ViT needs 224x224!\n",
    "            params[\"latent_size\"] = latent_size\n",
    "            params[\"epochs\"] = epochs_sp\n",
    "            params[\"training_data\"] = sp_training_data\n",
    "            params[\"validation_data\"] = sp_validation_data\n",
    "            params[\"vit_model\"] = vit_type  # Pass as \"vit_base\" or \"vit_large\"\n",
    "            params[\"class\"] = \"Vit\"\n",
    "            params[\"model\"] = \"VitProprioTunedRegression\"\n",
    "            params[\"freeze_feature_extractor\"] = False\n",
    "            params[\"loss\"] = \"MSELoss\"\n",
    "            params[\"learning_rate\"] = 0.0001\n",
    "\n",
    "            exprun = generate_sp_propriotuned_vit(\n",
    "                exprun_path=exprun_path, result_path=result_path, params=params, exp_name=exp_name, run_name=run_name)\n",
    "            exprun[\"latent_size\"] = latent_size\n",
    "            exprun[\"vittype\"] = vit_type\n",
    "            sps.append(exprun)\n",
    "            expruns.append(exprun)\n",
    "    # generate the propriotuned expruns\n",
    "    for cnntype in cnntypes:\n",
    "        exp_name = \"sensorprocessing_propriotuned_cnn\"\n",
    "        run_name = f\"sp_{cnntype}_{latent_size}_0001\"\n",
    "        params = {}\n",
    "        params[\"image_size\"] = image_size\n",
    "        params[\"latent_size\"] = latent_size\n",
    "        params[\"epochs\"] = epochs_sp\n",
    "        params[\"training_data\"] = sp_training_data\n",
    "        params[\"validation_data\"] = sp_validation_data\n",
    "        if cnntype == \"vgg19\":\n",
    "            if not do_VGG:\n",
    "                continue\n",
    "            params[\"class\"] = \"VGG19ProprioTunedSensorProcessing\"\n",
    "            params[\"model\"] = \"VGG19ProprioTunedRegression\"\n",
    "        elif cnntype == \"resnet50\":\n",
    "            if not do_RESNET:\n",
    "                continue\n",
    "            params[\"class\"] = \"ResNetProprioTunedSensorProcessing\"\n",
    "            params[\"model\"] = \"ResNetProprioTunedRegression\"\n",
    "            params[\"freeze_feature_extractor\"] = True\n",
    "            params[\"reductor_step_1\"] = 512\n",
    "            params[\"proprio_step_1\"] = 64\n",
    "            params[\"proprio_step_2\"] = 16\n",
    "        else:\n",
    "            raise Exception(f\"Unknown cnntype {cnntype}\")\n",
    "        params[\"loss\"] = \"MSELoss\" # alternative L1Loss\n",
    "        params[\"learning_rate\"] = 0.001\n",
    "        # alternative\n",
    "        exprun = generate_sp_propriotuned_cnn(\n",
    "            exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name = run_name)\n",
    "        exprun[\"latent_size\"] = latent_size\n",
    "        exprun[\"cnntype\"] = cnntype\n",
    "        sps.append(exprun)\n",
    "        expruns.append(exprun)\n",
    "\n",
    "    # FIXME: add here the ViT models\n",
    "\n",
    "# *******************************************\n",
    "# generate the proprioception models\n",
    "# *******************************************\n",
    "vpruns = []\n",
    "vpruns_latent = {128:[], 256:[]}\n",
    "for spexp, sprun,latent_size in [(a[\"experiment\"],a[\"run\"],a[\"latent_size\"]) for a in sps]:\n",
    "    print(spexp, sprun, latent_size)\n",
    "    # *** generate the vp train expruns ***\n",
    "    exp_name = \"visual_proprioception\"\n",
    "    run_name = \"vp_\" + sprun[3:]\n",
    "    vpruns.append(run_name)\n",
    "    vpruns_latent[latent_size].append(run_name)\n",
    "    params = {}\n",
    "    params[\"name\"] = run_name\n",
    "    params[\"output_size\"] = 6\n",
    "    params[\"encoding_size\"] = latent_size\n",
    "    params[\"training_data\"] = vp_training_data\n",
    "    params[\"validation_data\"] = vp_validation_data\n",
    "\n",
    "    params[\"regressor_hidden_size_1\"] = 64\n",
    "    params[\"regressor_hidden_size_1\"] = 64\n",
    "    params[\"loss\"] = \"MSE\"\n",
    "    params[\"epochs\"] = epochs_vp\n",
    "    params[\"batch_size\"] = 64\n",
    "    # FIXME this is hackish, should not do it this way\n",
    "    if \"vae\" in sprun.lower():\n",
    "        params[\"sensor_processing\"] = \"ConvVaeSensorProcessing\"\n",
    "    elif \"resnet\" in sprun.lower():\n",
    "        params[\"sensor_processing\"] = \"ResNetProprioTunedSensorProcessing\"\n",
    "    elif \"vgg19\" in sprun.lower():\n",
    "        params[\"sensor_processing\"] = \"VGG19ProprioTunedSensorProcessing\"\n",
    "    elif \"vit\" in sprun.lower():  # Added for VIT\n",
    "        params[\"sensor_processing\"] = \"VitSensorProcessing\"\n",
    "    else:\n",
    "        raise Exception(f\"Unexpected sprun {sprun}\")\n",
    "\n",
    "    params[\"sp_experiment\"] = spexp\n",
    "    params[\"sp_run\"] = sprun\n",
    "\n",
    "    exprun = generate_vp_train(exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name=run_name)\n",
    "    # *** generate the vp verify expruns FIXME: not implemented yet ***\n",
    "    params_verify = {}\n",
    "\n",
    "    expruns.append(exprun)\n",
    "# *******************************************\n",
    "# generate the comparisons: all, for latents 128 and 256\n",
    "# *******************************************\n",
    "exp_name = \"visual_proprioception\"\n",
    "# all\n",
    "run_name = \"vp_comp_flow_all\"\n",
    "params = {}\n",
    "params[\"name\"] = run_name\n",
    "params[\"tocompare\"] = vpruns\n",
    "exprun = generate_vp_compare(exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name=run_name)\n",
    "expruns.append(exprun)\n",
    "# by latent\n",
    "for latent_size in [128, 256]:\n",
    "    run_name = f\"vp_comp_flow_{latent_size}\"\n",
    "    params = {}\n",
    "    params[\"name\"] = run_name\n",
    "    params[\"tocompare\"] = vpruns_latent[latent_size]\n",
    "    exprun = generate_vp_compare(exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name=run_name)\n",
    "    expruns.append(exprun)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef389ef",
   "metadata": {},
   "source": [
    "### Run the flow\n",
    "\n",
    "Run the flow, that is, run a series of notebooks with papermill. In order to follow the execution inside these notebooks, one needs to open the output notebook, which is in the output_filename. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21aab023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Starting automated running of the flow.\n",
      " The path for the output notebooks is\n",
      "/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_07/result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating sensorprocessing/Train_ProprioTuned_VIT.ipynb :\n",
      " sensorprocessing_propriotuned_Vit/sp_vit_base_128_0001\n",
      "--> Train_ProprioTuned_VIT_sensorprocessing_propriotuned_Vit_sp_vit_base_128_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  83%|████████▎ | 19/23 [00:13<00:02,  1.46cell/s]\n",
      " 14%|█▍        | 1/7 [00:13<01:18, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [14]\":\n",
      "---------------------------------------------------------------------------\n",
      "NameError                                 Traceback (most recent call last)\n",
      "Cell In[14], line 32\n",
      "     29         print()\n",
      "     31 # Test the sensor processing\n",
      "---> 32 test_sensor_processing(sp, inputs_validation, targets_validation)\n",
      "\n",
      "NameError: name 'inputs_validation' is not defined\n",
      "\n",
      "***Automating sensorprocessing/Train_ProprioTuned_VIT.ipynb :\n",
      " sensorprocessing_propriotuned_Vit/sp_vit_base_256_0001\n",
      "--> Train_ProprioTuned_VIT_sensorprocessing_propriotuned_Vit_sp_vit_base_256_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  83%|████████▎ | 19/23 [00:10<00:02,  1.77cell/s]\n",
      " 29%|██▊       | 2/7 [00:23<00:58, 11.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [14]\":\n",
      "---------------------------------------------------------------------------\n",
      "NameError                                 Traceback (most recent call last)\n",
      "Cell In[14], line 32\n",
      "     29         print()\n",
      "     31 # Test the sensor processing\n",
      "---> 32 test_sensor_processing(sp, inputs_validation, targets_validation)\n",
      "\n",
      "NameError: name 'inputs_validation' is not defined\n",
      "\n",
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_vit_base_128_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_vit_base_128_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(f\"***Starting automated running of the flow.\\n The path for the output notebooks is\\n{result_path}\")\n",
    "\n",
    "for exprun in tqdm.tqdm(expruns):\n",
    "    print(f\"***Automating {exprun['notebook']} :\\n {exprun['experiment']}/{exprun['run']}\")\n",
    "    notebook_path = pathlib.Path(\"..\", exprun[\"notebook\"])\n",
    "    output_filename = f\"{notebook_path.stem}_{exprun['experiment']}_{exprun['run']}_output{notebook_path.suffix}\"\n",
    "    print(f\"--> {output_filename}\")\n",
    "    # parameters that we are passing on to the notebook\n",
    "    params = {}\n",
    "    params[\"experiment\"] = exprun[\"experiment\"]\n",
    "    params[\"run\"] = exprun[\"run\"]\n",
    "    params[\"external_path\"] = exprun[\"external_path\"]\n",
    "    params[\"data_path\"] = exprun[\"data_path\"]\n",
    "    output_path = pathlib.Path(result_path, output_filename)\n",
    "    try:\n",
    "        papermill.execute_notebook(\n",
    "            notebook_path,\n",
    "            output_path.absolute(),\n",
    "            cwd=notebook_path.parent,\n",
    "            parameters=params\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"There was an exception {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8455f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
