{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bea14d",
   "metadata": {},
   "source": [
    "# Visual proprioception flow\n",
    "\n",
    "Create the full flow for training models for visual proprioception. This notebook programmatically generates a set of exp/runs that cover all the necessary components for a visual proprioception system (sensor processing,  visual proprioception regressor and verification notebooks).\n",
    "\n",
    "Then, it writes the exp/runs into an external directory full separated from the github source, and creates an automation script that runs them. A separate directory for the results is also created. \n",
    "\n",
    "Finally, it runs the necessary notebooks to execute the whole flow using papermill.\n",
    "\n",
    "The results directory contain the output of this flow, both in terms of trained models, as well as results (in the verification exp/run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a83531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import copy\n",
    "import pprint\n",
    "import pathlib\n",
    "import yaml\n",
    "import tqdm\n",
    "import papermill\n",
    "import visproprio_helper\n",
    "from demonstration.demonstration import list_demos\n",
    "from demonstration.demopack import import_demopack, group_chooser_sp_vp_standard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b173f38",
   "metadata": {},
   "source": [
    "# Setting up the separate directory\n",
    "Setting up a separate directory for generated exp/run config files and the results. This cell will create a new directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "997ac9a7",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# the most likely changing things\n",
    "flow_name = \"VisualProprioception_flow_01\"\n",
    "# flow_name = \"cvpr_simulation_054\"\n",
    "#demonstration_run = \"touch-apple\"\n",
    "#demopack_name = \"touch-apple\"\n",
    "# demopack_name = \"automove-pack-01\"\n",
    "# demopack_name = \"cvpr-simulation\"\n",
    "demopack_name = \"random-both-cameras-video\"\n",
    "demonstration_cam = \"dev2\"\n",
    "# demonstration_cam = \"dev054\"\n",
    "\n",
    "do_VAE = True\n",
    "do_VGG = True\n",
    "do_RESNET = True\n",
    "do_VIT = True\n",
    "# determine these values based on experience\n",
    "epochs_sp = 10\n",
    "# epochs_vp = 1000\n",
    "# epochs_sp = 300 # way too much, at least for VAE\n",
    "epochs_vp = 1000\n",
    "image_size = [256, 256] # for vgg... etc\n",
    "\n",
    "# Use exist_ok not to-re-run previously successfully run models\n",
    "creation_style = \"exist-ok\"\n",
    "# creation_style = \"discard-old\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8448e1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demopacks base: /home/sa641631/WORK/BerryPicker-Demopacks\n",
      "Base exists: True\n",
      "Demopack path: /home/sa641631/WORK/BerryPicker-Demopacks/random-both-cameras-video\n",
      "Demopack exists: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "demopacks_base = pathlib.Path(Config()[\"demopacks_path\"]).expanduser()\n",
    "demopack_name = \"random-both-cameras-video\"\n",
    "demopack_path = pathlib.Path(demopacks_base, demopack_name)\n",
    "print(f\"Demopacks base: {demopacks_base}\")\n",
    "print(f\"Base exists: {demopacks_base.exists()}\")\n",
    "print(f\"Demopack path: {demopack_path}\")\n",
    "print(f\"Demopack exists: {demopack_path.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83eff4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Path for external experiments:\n",
      "~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/exprun\n",
      "***Path for external data:\n",
      "~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/result\n",
      "***ExpRun**: Experiment config path changed to ~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/exprun\n",
      "***ExpRun**: Experiment data path changed to ~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/result\n",
      "***ExpRun**: Experiment demonstration copied to\n",
      "~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/exprun/demonstration\n",
      "***ExpRun**: Experiment sensorprocessing_conv_vae copied to\n",
      "~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/exprun/sensorprocessing_conv_vae\n",
      "***ExpRun**: Experiment sensorprocessing_propriotuned_cnn copied to\n",
      "~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/exprun/sensorprocessing_propriotuned_cnn\n",
      "***ExpRun**: Experiment sensorprocessing_propriotuned_Vit copied to\n",
      "~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/exprun/sensorprocessing_propriotuned_Vit\n",
      "***ExpRun**: Experiment sensorprocessing_aruco copied to\n",
      "~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/exprun/sensorprocessing_aruco\n",
      "***ExpRun**: Experiment visual_proprioception copied to\n",
      "~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/exprun/visual_proprioception\n",
      "*** import_demopack: /home/sa641631/WORK/BerryPicker-Demopacks/random-both-cameras-video, target directory ~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/result/demonstration/random-both-cameras-video  already exists, not copying\n",
      "***ExpRun**: Configuration for exp/run: demonstration/random-both-cameras-video successfully loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "exprun_path, result_path = visproprio_helper.external_setup(flow_name, Config()[\"flows_path\"])\n",
    "\n",
    "demopack_path = pathlib.Path(Config()[\"demopacks_path\"], demopack_name).expanduser()\n",
    "selection = import_demopack(demopack_path, group_chooser_sp_vp_standard)\n",
    "#\n",
    "# Configuring the training and validation data, based\n",
    "# on all the demonstrations of a particular type\n",
    "#\n",
    "experiment = \"demonstration\"\n",
    "exp = Config().get_experiment(experiment, demopack_name)\n",
    "\n",
    "sp_training_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"sp_training\"]]\n",
    "sp_validation_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"sp_validation\"]]\n",
    "vp_training_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"vp_training\"]]\n",
    "vp_validation_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"vp_validation\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be9a19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_training': ['sp_training_00000', 'sp_training_00001', 'sp_training_00002', 'sp_training_00003'], 'sp_validation': ['sp_validation_00000', 'sp_validation_00001'], 'sp_testing': ['sp_testing_00000', 'sp_testing_00001'], 'vp_training': ['vp_training_00000', 'vp_training_00001', 'vp_training_00002', 'vp_training_00003'], 'vp_validation': ['vp_validation_00000', 'vp_validation_00001'], 'vp_testing': ['vp_testing_00000', 'vp_testing_00001']}\n"
     ]
    }
   ],
   "source": [
    "print(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca2ada4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demos = list_demos(exp)\n",
    "# print(demos)\n",
    "print(list_demos(exp, \"sp\"))\n",
    "[s for s in demos if s.startswith(\"sp_training\" + \"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6d27c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sp_conv_vae(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the training of the conv-vae sensorprocessing with the right training data and parameters. Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation.\n",
    "    NOTE: a similar function is in Flow_BehaviorCloning.\n",
    "    \"\"\"\n",
    "    val = {}\n",
    "    val[\"latent_size\"] = params[\"latent_size\"]\n",
    "    val[\"epochs\"] = params[\"epochs\"]\n",
    "    val[\"save_period\"] = 5\n",
    "    val[\"training_data\"] = params[\"training_data\"]\n",
    "    val[\"validation_data\"] = params[\"validation_data\"]\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file\n",
    "    v = {}\n",
    "    v[\"name\"] = \"Train_SP_Conv-VAE\"\n",
    "    v[\"notebook\"] = \"sensorprocessing/Train_Conv_VAE.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d97895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sp_propriotuned_cnn(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the training of the propriotuned CNN with the right training data and parameters.\n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation.\n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "    val[\"output_size\"] = 6\n",
    "    val[\"batch_size\"] = 32\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file\n",
    "    v = {}\n",
    "    v[\"name\"] = \"Train_SP_CNN\"\n",
    "    v[\"notebook\"] = \"sensorprocessing/Train_ProprioTuned_CNN.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "476839eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vp_train(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the training visual proprioception regressor.\n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation.\n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file\n",
    "    v = {}\n",
    "    v[\"name\"] = f\"Train_{run_name}\"\n",
    "    v[\"notebook\"] = \"visual_proprioception/Train_VisualProprioception.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b99c9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vp_verify(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the verification of the visual proprioception regressor.\n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation.\n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file\n",
    "    v = {}\n",
    "    v[\"name\"] = f\"Verify_{run_name}\"\n",
    "    v[\"notebook\"] = \"TODO Verify.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f64e6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vp_compare(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the verification of the visual proprioception regressor.\n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation.\n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "    val[\"name\"] = exp_name\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file\n",
    "    v = {}\n",
    "    v[\"name\"] = f\"Compare_{run_name}\"\n",
    "    v[\"notebook\"] = \"visual_proprioception/Compare_VisualProprioception.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28cd090",
   "metadata": {},
   "source": [
    "### Generate the exp/runs to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "020b8ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensorprocessing_conv_vae sp_conv_vae_128_0001 128\n",
      "sensorprocessing_propriotuned_cnn sp_vgg19_128_0001 128\n",
      "sensorprocessing_propriotuned_cnn sp_resnet50_128_0001 128\n",
      "sensorprocessing_conv_vae sp_conv_vae_256_0001 256\n",
      "sensorprocessing_propriotuned_cnn sp_vgg19_256_0001 256\n",
      "sensorprocessing_propriotuned_cnn sp_resnet50_256_0001 256\n"
     ]
    }
   ],
   "source": [
    "expruns = []\n",
    "# overall values\n",
    "latent_sizes = [128, 256] # the possible latent sizes we consider\n",
    "cnntypes = [\"vgg19\", \"resnet50\"] # the CNN architectures we consider\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *******************************************\n",
    "# generate the sensorprocessing models\n",
    "# *******************************************\n",
    "sps = [] # the list of the sensorprocessing models (exp/run)\n",
    "for latent_size in latent_sizes:\n",
    "\n",
    "    # generate the vae exprun\n",
    "    exp_name = \"sensorprocessing_conv_vae\"\n",
    "    run_name = f\"sp_conv_vae_{latent_size}_0001\"\n",
    "    params = {}\n",
    "    params[\"latent_size\"] = latent_size\n",
    "    params[\"epochs\"] = epochs_sp\n",
    "    params[\"training_data\"] = sp_training_data\n",
    "    params[\"validation_data\"] = sp_validation_data\n",
    "    exprun = generate_sp_conv_vae(\n",
    "        exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name = run_name)\n",
    "    exprun[\"latent_size\"] = latent_size\n",
    "    if do_VAE:\n",
    "        sps.append(exprun)\n",
    "        expruns.append(exprun)\n",
    "\n",
    "    # generate the propriotuned expruns\n",
    "    for cnntype in cnntypes:\n",
    "        exp_name = \"sensorprocessing_propriotuned_cnn\"\n",
    "        run_name = f\"sp_{cnntype}_{latent_size}_0001\"\n",
    "        params = {}\n",
    "        params[\"image_size\"] = image_size\n",
    "        params[\"latent_size\"] = latent_size\n",
    "        params[\"epochs\"] = epochs_sp\n",
    "        params[\"training_data\"] = sp_training_data\n",
    "        params[\"validation_data\"] = sp_validation_data\n",
    "        if cnntype == \"vgg19\":\n",
    "            if not do_VGG:\n",
    "                continue\n",
    "            params[\"class\"] = \"VGG19ProprioTunedSensorProcessing\"\n",
    "            params[\"model\"] = \"VGG19ProprioTunedRegression\"\n",
    "        elif cnntype == \"resnet50\":\n",
    "            if not do_RESNET:\n",
    "                continue\n",
    "            params[\"class\"] = \"ResNetProprioTunedSensorProcessing\"\n",
    "            params[\"model\"] = \"ResNetProprioTunedRegression\"\n",
    "            params[\"freeze_feature_extractor\"] = True\n",
    "            params[\"reductor_step_1\"] = 512\n",
    "            params[\"proprio_step_1\"] = 64\n",
    "            params[\"proprio_step_2\"] = 16\n",
    "        else:\n",
    "            raise Exception(f\"Unknown cnntype {cnntype}\")\n",
    "        params[\"loss\"] = \"MSELoss\" # alternative L1Loss\n",
    "        params[\"learning_rate\"] = 0.001\n",
    "        # alternative\n",
    "        exprun = generate_sp_propriotuned_cnn(\n",
    "            exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name = run_name)\n",
    "        exprun[\"latent_size\"] = latent_size\n",
    "        exprun[\"cnntype\"] = cnntype\n",
    "        sps.append(exprun)\n",
    "        expruns.append(exprun)\n",
    "\n",
    "    # FIXME: add here the ViT models\n",
    "\n",
    "# *******************************************\n",
    "# generate the proprioception models\n",
    "# *******************************************\n",
    "vpruns = []\n",
    "vpruns_latent = {128:[], 256:[]}\n",
    "for spexp, sprun,latent_size in [(a[\"experiment\"],a[\"run\"],a[\"latent_size\"]) for a in sps]:\n",
    "    print(spexp, sprun, latent_size)\n",
    "    # *** generate the vp train expruns ***\n",
    "    exp_name = \"visual_proprioception\"\n",
    "    run_name = \"vp_\" + sprun[3:]\n",
    "    vpruns.append(run_name)\n",
    "    vpruns_latent[latent_size].append(run_name)\n",
    "    params = {}\n",
    "    params[\"name\"] = run_name\n",
    "    params[\"output_size\"] = 6\n",
    "    params[\"encoding_size\"] = latent_size\n",
    "    params[\"training_data\"] = vp_training_data\n",
    "    params[\"validation_data\"] = vp_validation_data\n",
    "\n",
    "    params[\"regressor_hidden_size_1\"] = 64\n",
    "    params[\"regressor_hidden_size_1\"] = 64\n",
    "    params[\"loss\"] = \"MSE\"\n",
    "    params[\"epochs\"] = epochs_vp\n",
    "    params[\"batch_size\"] = 64\n",
    "    # FIXME this is hackish, should not do it this way\n",
    "    if \"vae\" in sprun.lower():\n",
    "        params[\"sensor_processing\"] = \"ConvVaeSensorProcessing\"\n",
    "    elif \"resnet\" in sprun.lower():\n",
    "        params[\"sensor_processing\"] = \"ResNetProprioTunedSensorProcessing\"\n",
    "    elif \"vgg19\" in sprun.lower():\n",
    "        params[\"sensor_processing\"] = \"VGG19ProprioTunedSensorProcessing\"\n",
    "    else:\n",
    "        raise Exception(f\"Unexpected sprun {sprun}\")\n",
    "\n",
    "    params[\"sp_experiment\"] = spexp\n",
    "    params[\"sp_run\"] = sprun\n",
    "\n",
    "    exprun = generate_vp_train(exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name=run_name)\n",
    "    # *** generate the vp verify expruns FIXME: not implemented yet ***\n",
    "    params_verify = {}\n",
    "\n",
    "    expruns.append(exprun)\n",
    "# *******************************************\n",
    "# generate the comparisons: all, for latents 128 and 256\n",
    "# *******************************************\n",
    "exp_name = \"visual_proprioception\"\n",
    "# all\n",
    "run_name = \"vp_comp_flow_all\"\n",
    "params = {}\n",
    "params[\"name\"] = run_name\n",
    "params[\"tocompare\"] = vpruns\n",
    "exprun = generate_vp_compare(exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name=run_name)\n",
    "expruns.append(exprun)\n",
    "# by latent\n",
    "for latent_size in [128, 256]:\n",
    "    run_name = f\"vp_comp_flow_{latent_size}\"\n",
    "    params = {}\n",
    "    params[\"name\"] = run_name\n",
    "    params[\"tocompare\"] = vpruns_latent[latent_size]\n",
    "    exprun = generate_vp_compare(exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name=run_name)\n",
    "    expruns.append(exprun)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef389ef",
   "metadata": {},
   "source": [
    "### Run the flow\n",
    "\n",
    "Run the flow, that is, run a series of notebooks with papermill. In order to follow the execution inside these notebooks, one needs to open the output notebook, which is in the output_filename. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21aab023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Starting automated running of the flow.\n",
      " The path for the output notebooks is\n",
      "~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating sensorprocessing/Train_Conv_VAE.ipynb :\n",
      " sensorprocessing_conv_vae/sp_conv_vae_128_0001\n",
      "--> Train_Conv_VAE_sensorprocessing_conv_vae_sp_conv_vae_128_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa641631/WORK/BerryPicker/vm/berrypickervenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Executing:  55%|█████▍    | 6/11 [00:12<00:10,  2.05s/cell]\n",
      "  7%|▋         | 1/15 [00:12<02:56, 12.62s/it]WARNING:papermill:Passed unknown parameter: experiment\n",
      "WARNING:papermill:Passed unknown parameter: run\n",
      "WARNING:papermill:Passed unknown parameter: external_path\n",
      "WARNING:papermill:Passed unknown parameter: data_path\n",
      "WARNING:papermill:Input notebook does not contain a cell with tag 'parameters'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [4]\":\n",
      "---------------------------------------------------------------------------\n",
      "AssertionError                            Traceback (most recent call last)\n",
      "Cell In[4], line 3\n",
      "      1 if external_path:\n",
      "      2     external_path = pathlib.Path(external_path)\n",
      "----> 3     assert external_path.exists()\n",
      "      4     Config().set_exprun_path(external_path)\n",
      "      5     Config().copy_experiment(\"sensorprocessing_conv_vae\")\n",
      "\n",
      "AssertionError: \n",
      "\n",
      "***Automating sensorprocessing/Train_ProprioTuned_CNN.ipynb :\n",
      " sensorprocessing_propriotuned_cnn/sp_vgg19_128_0001\n",
      "--> Train_ProprioTuned_CNN_sensorprocessing_propriotuned_cnn_sp_vgg19_128_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 13/13 [00:07<00:00,  1.83cell/s]\n",
      " 13%|█▎        | 2/15 [00:19<02:02,  9.39s/it]WARNING:papermill:Passed unknown parameter: experiment\n",
      "WARNING:papermill:Passed unknown parameter: run\n",
      "WARNING:papermill:Passed unknown parameter: external_path\n",
      "WARNING:papermill:Passed unknown parameter: data_path\n",
      "WARNING:papermill:Input notebook does not contain a cell with tag 'parameters'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating sensorprocessing/Train_ProprioTuned_CNN.ipynb :\n",
      " sensorprocessing_propriotuned_cnn/sp_resnet50_128_0001\n",
      "--> Train_ProprioTuned_CNN_sensorprocessing_propriotuned_cnn_sp_resnet50_128_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 13/13 [00:07<00:00,  1.84cell/s]\n",
      " 20%|██        | 3/15 [00:26<01:39,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating sensorprocessing/Train_Conv_VAE.ipynb :\n",
      " sensorprocessing_conv_vae/sp_conv_vae_256_0001\n",
      "--> Train_Conv_VAE_sensorprocessing_conv_vae_sp_conv_vae_256_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  55%|█████▍    | 6/11 [00:08<00:06,  1.34s/cell]\n",
      " 27%|██▋       | 4/15 [00:34<01:30,  8.22s/it]WARNING:papermill:Passed unknown parameter: experiment\n",
      "WARNING:papermill:Passed unknown parameter: run\n",
      "WARNING:papermill:Passed unknown parameter: external_path\n",
      "WARNING:papermill:Passed unknown parameter: data_path\n",
      "WARNING:papermill:Input notebook does not contain a cell with tag 'parameters'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [4]\":\n",
      "---------------------------------------------------------------------------\n",
      "AssertionError                            Traceback (most recent call last)\n",
      "Cell In[4], line 3\n",
      "      1 if external_path:\n",
      "      2     external_path = pathlib.Path(external_path)\n",
      "----> 3     assert external_path.exists()\n",
      "      4     Config().set_exprun_path(external_path)\n",
      "      5     Config().copy_experiment(\"sensorprocessing_conv_vae\")\n",
      "\n",
      "AssertionError: \n",
      "\n",
      "***Automating sensorprocessing/Train_ProprioTuned_CNN.ipynb :\n",
      " sensorprocessing_propriotuned_cnn/sp_vgg19_256_0001\n",
      "--> Train_ProprioTuned_CNN_sensorprocessing_propriotuned_cnn_sp_vgg19_256_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 13/13 [00:07<00:00,  1.85cell/s]\n",
      " 33%|███▎      | 5/15 [00:41<01:18,  7.81s/it]WARNING:papermill:Passed unknown parameter: experiment\n",
      "WARNING:papermill:Passed unknown parameter: run\n",
      "WARNING:papermill:Passed unknown parameter: external_path\n",
      "WARNING:papermill:Passed unknown parameter: data_path\n",
      "WARNING:papermill:Input notebook does not contain a cell with tag 'parameters'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating sensorprocessing/Train_ProprioTuned_CNN.ipynb :\n",
      " sensorprocessing_propriotuned_cnn/sp_resnet50_256_0001\n",
      "--> Train_ProprioTuned_CNN_sensorprocessing_propriotuned_cnn_sp_resnet50_256_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 13/13 [00:06<00:00,  2.14cell/s]\n",
      " 40%|████      | 6/15 [00:48<01:04,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_conv_vae_128_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_conv_vae_128_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  44%|████▍     | 7/16 [00:08<00:10,  1.15s/cell]\n",
      " 47%|████▋     | 7/15 [00:56<00:59,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [5]\":\n",
      "---------------------------------------------------------------------------\n",
      "FileNotFoundError                         Traceback (most recent call last)\n",
      "Cell In[5], line 22\n",
      "     20 # Create the sp object described in the experiment\n",
      "     21 spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
      "---> 22 sp = create_sp(spexp, device)\n",
      "     23 exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/sp_factory.py:14, in create_sp(spexp, device)\n",
      "     12 # spexp = Config().get_experiment(exp['sp_experiment'], exp['sp_run'])\n",
      "     13 if spexp[\"class\"] == \"ConvVaeSensorProcessing\":\n",
      "---> 14     return sp_conv_vae.ConvVaeSensorProcessing(spexp, device)\n",
      "     15 if spexp[\"class\"] == \"ConvVaeSensorProcessing_concat_multiview\":\n",
      "     16     return sp_conv_vae_concat_multiview.ConcatConvVaeSensorProcessing(spexp, device)\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/sp_conv_vae.py:63, in ConvVaeSensorProcessing.__init__(self, exp, device)\n",
      "     60 self.resume_model_pthfile = Path(exp.data_dir(), \"model.pth\")\n",
      "     61 # self.conv_vae_jsonfile = conv_vae_jsonfile\n",
      "     62 # self.resume_model_pthfile = resume_model_pthfile\n",
      "---> 63 self.vae_config = get_conv_vae_config(\n",
      "     64     self.conv_vae_jsonfile, \n",
      "     65     self.resume_model_pthfile, \n",
      "     66     inference_only=True)\n",
      "     67 # build model architecture\n",
      "     68 self.model = self.vae_config.init_obj('arch', module_arch)\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/conv_vae.py:217, in get_conv_vae_config(jsonfile, resume_model, inference_only)\n",
      "    215 savedargv = sys.argv\n",
      "    216 sys.argv = value\n",
      "--> 217 config = ConfigParser.from_args(args)\n",
      "    218 sys.argv = savedargv\n",
      "    219 # print(json.dumps(config.config, indent=4))\n",
      "    220 #\n",
      "    221 # THIS was an attempt to fix some kind of weird bug where an empty \n",
      "    222 # directory was created... it is not needed on 2024.11.17???\n",
      "    223 # if it is inference only, remove the superfluously created directories.\n",
      "    224 #\n",
      "\n",
      "File ~/WORK/BerryPicker/src/Conv-VAE-PyTorch/parse_config.py:71, in ConfigParser.from_args(cls, args, options)\n",
      "     68     resume = None\n",
      "     69     cfg_fname = Path(args.config)\n",
      "---> 71 config = read_json(cfg_fname)\n",
      "     72 if args.config and resume:\n",
      "     73     # update new config for fine-tuning\n",
      "     74     config.update(read_json(args.config))\n",
      "\n",
      "File ~/WORK/BerryPicker/src/Conv-VAE-PyTorch/utils/util.py:16, in read_json(fname)\n",
      "     14 def read_json(fname):\n",
      "     15     fname = Path(fname)\n",
      "---> 16     with fname.open('rt') as handle:\n",
      "     17         return json.load(handle, object_hook=OrderedDict)\n",
      "\n",
      "File /apps/anaconda/anaconda-2023.09/lib/python3.11/pathlib.py:1044, in Path.open(self, mode, buffering, encoding, errors, newline)\n",
      "   1042 if \"b\" not in mode:\n",
      "   1043     encoding = io.text_encoding(encoding)\n",
      "-> 1044 return io.open(self, mode, buffering, encoding, errors, newline)\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_01/result/sensorprocessing_conv_vae/sp_conv_vae_128_0001/config.json'\n",
      "\n",
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_vgg19_128_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_vgg19_128_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  44%|████▍     | 7/16 [00:07<00:09,  1.09s/cell]\n",
      " 53%|█████▎    | 8/15 [01:03<00:52,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [5]\":\n",
      "---------------------------------------------------------------------------\n",
      "AssertionError                            Traceback (most recent call last)\n",
      "Cell In[5], line 22\n",
      "     20 # Create the sp object described in the experiment\n",
      "     21 spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
      "---> 22 sp = create_sp(spexp, device)\n",
      "     23 exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/sp_factory.py:20, in create_sp(spexp, device)\n",
      "     18     return sp_conv_vae_concat_multiview.ConvVaeSensorProcessing_multiview(spexp, device)\n",
      "     19 if spexp['class']==\"VGG19ProprioTunedSensorProcessing\":\n",
      "---> 20     return sp_propriotuned_cnn.VGG19ProprioTunedSensorProcessing(spexp, device)\n",
      "     21 if spexp['class']==\"ResNetProprioTunedSensorProcessing\":\n",
      "     22     return sp_propriotuned_cnn.ResNetProprioTunedSensorProcessing(spexp, device)\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/sp_propriotuned_cnn.py:170, in VGG19ProprioTunedSensorProcessing.__init__(self, exp, device)\n",
      "    167 self.enc = self.enc.to(device)\n",
      "    168 modelfile = pathlib.Path(exp[\"data_dir\"], \n",
      "    169                         exp[\"proprioception_mlp_model_file\"])\n",
      "--> 170 assert modelfile.exists()\n",
      "    171 self.enc.load_state_dict(torch.load(modelfile))\n",
      "\n",
      "AssertionError: \n",
      "\n",
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_resnet50_128_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_resnet50_128_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  44%|████▍     | 7/16 [00:06<00:08,  1.01cell/s]\n",
      " 60%|██████    | 9/15 [01:10<00:44,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [5]\":\n",
      "---------------------------------------------------------------------------\n",
      "AssertionError                            Traceback (most recent call last)\n",
      "Cell In[5], line 22\n",
      "     20 # Create the sp object described in the experiment\n",
      "     21 spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
      "---> 22 sp = create_sp(spexp, device)\n",
      "     23 exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/sp_factory.py:22, in create_sp(spexp, device)\n",
      "     20     return sp_propriotuned_cnn.VGG19ProprioTunedSensorProcessing(spexp, device)\n",
      "     21 if spexp['class']==\"ResNetProprioTunedSensorProcessing\":\n",
      "---> 22     return sp_propriotuned_cnn.ResNetProprioTunedSensorProcessing(spexp, device)\n",
      "     23 if spexp['class']==\"VGG19ProprioTunedSensorProcessing_multiview\":\n",
      "     24     return sp_propriotuned_cnn_multiview.MultiViewVGG19SensorProcessing(spexp, device)\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/sp_propriotuned_cnn.py:148, in ResNetProprioTunedSensorProcessing.__init__(self, exp, device)\n",
      "    145 self.enc = ResNetProprioTunedRegression(exp, device)\n",
      "    146 modelfile = pathlib.Path(exp[\"data_dir\"], \n",
      "    147                         exp[\"proprioception_mlp_model_file\"])\n",
      "--> 148 assert modelfile.exists()\n",
      "    149 self.enc.load_state_dict(torch.load(modelfile))\n",
      "\n",
      "AssertionError: \n",
      "\n",
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_conv_vae_256_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_conv_vae_256_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  44%|████▍     | 7/16 [00:05<00:07,  1.25cell/s]\n",
      " 67%|██████▋   | 10/15 [01:16<00:34,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [5]\":\n",
      "---------------------------------------------------------------------------\n",
      "FileNotFoundError                         Traceback (most recent call last)\n",
      "Cell In[5], line 22\n",
      "     20 # Create the sp object described in the experiment\n",
      "     21 spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
      "---> 22 sp = create_sp(spexp, device)\n",
      "     23 exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/sp_factory.py:14, in create_sp(spexp, device)\n",
      "     12 # spexp = Config().get_experiment(exp['sp_experiment'], exp['sp_run'])\n",
      "     13 if spexp[\"class\"] == \"ConvVaeSensorProcessing\":\n",
      "---> 14     return sp_conv_vae.ConvVaeSensorProcessing(spexp, device)\n",
      "     15 if spexp[\"class\"] == \"ConvVaeSensorProcessing_concat_multiview\":\n",
      "     16     return sp_conv_vae_concat_multiview.ConcatConvVaeSensorProcessing(spexp, device)\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/sp_conv_vae.py:63, in ConvVaeSensorProcessing.__init__(self, exp, device)\n",
      "     60 self.resume_model_pthfile = Path(exp.data_dir(), \"model.pth\")\n",
      "     61 # self.conv_vae_jsonfile = conv_vae_jsonfile\n",
      "     62 # self.resume_model_pthfile = resume_model_pthfile\n",
      "---> 63 self.vae_config = get_conv_vae_config(\n",
      "     64     self.conv_vae_jsonfile, \n",
      "     65     self.resume_model_pthfile, \n",
      "     66     inference_only=True)\n",
      "     67 # build model architecture\n",
      "     68 self.model = self.vae_config.init_obj('arch', module_arch)\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/conv_vae.py:217, in get_conv_vae_config(jsonfile, resume_model, inference_only)\n",
      "    215 savedargv = sys.argv\n",
      "    216 sys.argv = value\n",
      "--> 217 config = ConfigParser.from_args(args)\n",
      "    218 sys.argv = savedargv\n",
      "    219 # print(json.dumps(config.config, indent=4))\n",
      "    220 #\n",
      "    221 # THIS was an attempt to fix some kind of weird bug where an empty \n",
      "    222 # directory was created... it is not needed on 2024.11.17???\n",
      "    223 # if it is inference only, remove the superfluously created directories.\n",
      "    224 #\n",
      "\n",
      "File ~/WORK/BerryPicker/src/Conv-VAE-PyTorch/parse_config.py:71, in ConfigParser.from_args(cls, args, options)\n",
      "     68     resume = None\n",
      "     69     cfg_fname = Path(args.config)\n",
      "---> 71 config = read_json(cfg_fname)\n",
      "     72 if args.config and resume:\n",
      "     73     # update new config for fine-tuning\n",
      "     74     config.update(read_json(args.config))\n",
      "\n",
      "File ~/WORK/BerryPicker/src/Conv-VAE-PyTorch/utils/util.py:16, in read_json(fname)\n",
      "     14 def read_json(fname):\n",
      "     15     fname = Path(fname)\n",
      "---> 16     with fname.open('rt') as handle:\n",
      "     17         return json.load(handle, object_hook=OrderedDict)\n",
      "\n",
      "File /apps/anaconda/anaconda-2023.09/lib/python3.11/pathlib.py:1044, in Path.open(self, mode, buffering, encoding, errors, newline)\n",
      "   1042 if \"b\" not in mode:\n",
      "   1043     encoding = io.text_encoding(encoding)\n",
      "-> 1044 return io.open(self, mode, buffering, encoding, errors, newline)\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_01/result/sensorprocessing_conv_vae/sp_conv_vae_256_0001/config.json'\n",
      "\n",
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_vgg19_256_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_vgg19_256_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  44%|████▍     | 7/16 [00:06<00:08,  1.08cell/s]\n",
      " 73%|███████▎  | 11/15 [01:22<00:26,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [5]\":\n",
      "---------------------------------------------------------------------------\n",
      "AssertionError                            Traceback (most recent call last)\n",
      "Cell In[5], line 22\n",
      "     20 # Create the sp object described in the experiment\n",
      "     21 spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
      "---> 22 sp = create_sp(spexp, device)\n",
      "     23 exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/sp_factory.py:20, in create_sp(spexp, device)\n",
      "     18     return sp_conv_vae_concat_multiview.ConvVaeSensorProcessing_multiview(spexp, device)\n",
      "     19 if spexp['class']==\"VGG19ProprioTunedSensorProcessing\":\n",
      "---> 20     return sp_propriotuned_cnn.VGG19ProprioTunedSensorProcessing(spexp, device)\n",
      "     21 if spexp['class']==\"ResNetProprioTunedSensorProcessing\":\n",
      "     22     return sp_propriotuned_cnn.ResNetProprioTunedSensorProcessing(spexp, device)\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/sp_propriotuned_cnn.py:170, in VGG19ProprioTunedSensorProcessing.__init__(self, exp, device)\n",
      "    167 self.enc = self.enc.to(device)\n",
      "    168 modelfile = pathlib.Path(exp[\"data_dir\"], \n",
      "    169                         exp[\"proprioception_mlp_model_file\"])\n",
      "--> 170 assert modelfile.exists()\n",
      "    171 self.enc.load_state_dict(torch.load(modelfile))\n",
      "\n",
      "AssertionError: \n",
      "\n",
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_resnet50_256_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_resnet50_256_0001_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  44%|████▍     | 7/16 [00:06<00:08,  1.12cell/s]\n",
      " 80%|████████  | 12/15 [01:29<00:19,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [5]\":\n",
      "---------------------------------------------------------------------------\n",
      "AssertionError                            Traceback (most recent call last)\n",
      "Cell In[5], line 22\n",
      "     20 # Create the sp object described in the experiment\n",
      "     21 spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
      "---> 22 sp = create_sp(spexp, device)\n",
      "     23 exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/sp_factory.py:22, in create_sp(spexp, device)\n",
      "     20     return sp_propriotuned_cnn.VGG19ProprioTunedSensorProcessing(spexp, device)\n",
      "     21 if spexp['class']==\"ResNetProprioTunedSensorProcessing\":\n",
      "---> 22     return sp_propriotuned_cnn.ResNetProprioTunedSensorProcessing(spexp, device)\n",
      "     23 if spexp['class']==\"VGG19ProprioTunedSensorProcessing_multiview\":\n",
      "     24     return sp_propriotuned_cnn_multiview.MultiViewVGG19SensorProcessing(spexp, device)\n",
      "\n",
      "File /lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/../sensorprocessing/sp_propriotuned_cnn.py:148, in ResNetProprioTunedSensorProcessing.__init__(self, exp, device)\n",
      "    145 self.enc = ResNetProprioTunedRegression(exp, device)\n",
      "    146 modelfile = pathlib.Path(exp[\"data_dir\"], \n",
      "    147                         exp[\"proprioception_mlp_model_file\"])\n",
      "--> 148 assert modelfile.exists()\n",
      "    149 self.enc.load_state_dict(torch.load(modelfile))\n",
      "\n",
      "AssertionError: \n",
      "\n",
      "***Automating visual_proprioception/Compare_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_comp_flow_all\n",
      "--> Compare_VisualProprioception_visual_proprioception_vp_comp_flow_all_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  29%|██▊       | 6/21 [00:06<00:17,  1.15s/cell]\n",
      " 87%|████████▋ | 13/15 [01:36<00:13,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [5]\":\n",
      "---------------------------------------------------------------------------\n",
      "FileNotFoundError                         Traceback (most recent call last)\n",
      "Cell In[5], line 44\n",
      "     41 model = VisProprio_SimpleMLPRegression(subexp)\n",
      "     42 modelfile = pathlib.Path(subexp[\"data_dir\"],\n",
      "     43                         subexp[\"proprioception_mlp_model_file\"])\n",
      "---> 44 model.load_state_dict(torch.load(modelfile))\n",
      "     45 model.to(device)\n",
      "     46 models.append(model)\n",
      "\n",
      "File ~/WORK/BerryPicker/vm/berrypickervenv/lib/python3.11/site-packages/torch/serialization.py:1479, in load(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\n",
      "   1476 if \"encoding\" not in pickle_load_args.keys():\n",
      "   1477     pickle_load_args[\"encoding\"] = \"utf-8\"\n",
      "-> 1479 with _open_file_like(f, \"rb\") as opened_file:\n",
      "   1480     if _is_zipfile(opened_file):\n",
      "   1481         # The zipfile reader is going to advance the current file position.\n",
      "   1482         # If we want to actually tail call to torch.jit.load, we need to\n",
      "   1483         # reset back to the original position.\n",
      "   1484         orig_position = opened_file.tell()\n",
      "\n",
      "File ~/WORK/BerryPicker/vm/berrypickervenv/lib/python3.11/site-packages/torch/serialization.py:759, in _open_file_like(name_or_buffer, mode)\n",
      "    757 def _open_file_like(name_or_buffer: FileLike, mode: str) -> _opener[IO[bytes]]:\n",
      "    758     if _is_path(name_or_buffer):\n",
      "--> 759         return _open_file(name_or_buffer, mode)\n",
      "    760     else:\n",
      "    761         if \"w\" in mode:\n",
      "\n",
      "File ~/WORK/BerryPicker/vm/berrypickervenv/lib/python3.11/site-packages/torch/serialization.py:740, in _open_file.__init__(self, name, mode)\n",
      "    739 def __init__(self, name: Union[str, os.PathLike[str]], mode: str) -> None:\n",
      "--> 740     super().__init__(open(name, mode))\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_01/result/visual_proprioception/vit_base/proprioception_mlp.pth'\n",
      "\n",
      "***Automating visual_proprioception/Compare_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_comp_flow_128\n",
      "--> Compare_VisualProprioception_visual_proprioception_vp_comp_flow_128_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  29%|██▊       | 6/21 [00:06<00:16,  1.11s/cell]\n",
      " 93%|█████████▎| 14/15 [01:42<00:06,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [5]\":\n",
      "---------------------------------------------------------------------------\n",
      "FileNotFoundError                         Traceback (most recent call last)\n",
      "Cell In[5], line 44\n",
      "     41 model = VisProprio_SimpleMLPRegression(subexp)\n",
      "     42 modelfile = pathlib.Path(subexp[\"data_dir\"],\n",
      "     43                         subexp[\"proprioception_mlp_model_file\"])\n",
      "---> 44 model.load_state_dict(torch.load(modelfile))\n",
      "     45 model.to(device)\n",
      "     46 models.append(model)\n",
      "\n",
      "File ~/WORK/BerryPicker/vm/berrypickervenv/lib/python3.11/site-packages/torch/serialization.py:1479, in load(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\n",
      "   1476 if \"encoding\" not in pickle_load_args.keys():\n",
      "   1477     pickle_load_args[\"encoding\"] = \"utf-8\"\n",
      "-> 1479 with _open_file_like(f, \"rb\") as opened_file:\n",
      "   1480     if _is_zipfile(opened_file):\n",
      "   1481         # The zipfile reader is going to advance the current file position.\n",
      "   1482         # If we want to actually tail call to torch.jit.load, we need to\n",
      "   1483         # reset back to the original position.\n",
      "   1484         orig_position = opened_file.tell()\n",
      "\n",
      "File ~/WORK/BerryPicker/vm/berrypickervenv/lib/python3.11/site-packages/torch/serialization.py:759, in _open_file_like(name_or_buffer, mode)\n",
      "    757 def _open_file_like(name_or_buffer: FileLike, mode: str) -> _opener[IO[bytes]]:\n",
      "    758     if _is_path(name_or_buffer):\n",
      "--> 759         return _open_file(name_or_buffer, mode)\n",
      "    760     else:\n",
      "    761         if \"w\" in mode:\n",
      "\n",
      "File ~/WORK/BerryPicker/vm/berrypickervenv/lib/python3.11/site-packages/torch/serialization.py:740, in _open_file.__init__(self, name, mode)\n",
      "    739 def __init__(self, name: Union[str, os.PathLike[str]], mode: str) -> None:\n",
      "--> 740     super().__init__(open(name, mode))\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_01/result/visual_proprioception/vit_base/proprioception_mlp.pth'\n",
      "\n",
      "***Automating visual_proprioception/Compare_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_comp_flow_256\n",
      "--> Compare_VisualProprioception_visual_proprioception_vp_comp_flow_256_output.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  29%|██▊       | 6/21 [00:06<00:16,  1.10s/cell]\n",
      "100%|██████████| 15/15 [01:49<00:00,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [5]\":\n",
      "---------------------------------------------------------------------------\n",
      "FileNotFoundError                         Traceback (most recent call last)\n",
      "Cell In[5], line 44\n",
      "     41 model = VisProprio_SimpleMLPRegression(subexp)\n",
      "     42 modelfile = pathlib.Path(subexp[\"data_dir\"],\n",
      "     43                         subexp[\"proprioception_mlp_model_file\"])\n",
      "---> 44 model.load_state_dict(torch.load(modelfile))\n",
      "     45 model.to(device)\n",
      "     46 models.append(model)\n",
      "\n",
      "File ~/WORK/BerryPicker/vm/berrypickervenv/lib/python3.11/site-packages/torch/serialization.py:1479, in load(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\n",
      "   1476 if \"encoding\" not in pickle_load_args.keys():\n",
      "   1477     pickle_load_args[\"encoding\"] = \"utf-8\"\n",
      "-> 1479 with _open_file_like(f, \"rb\") as opened_file:\n",
      "   1480     if _is_zipfile(opened_file):\n",
      "   1481         # The zipfile reader is going to advance the current file position.\n",
      "   1482         # If we want to actually tail call to torch.jit.load, we need to\n",
      "   1483         # reset back to the original position.\n",
      "   1484         orig_position = opened_file.tell()\n",
      "\n",
      "File ~/WORK/BerryPicker/vm/berrypickervenv/lib/python3.11/site-packages/torch/serialization.py:759, in _open_file_like(name_or_buffer, mode)\n",
      "    757 def _open_file_like(name_or_buffer: FileLike, mode: str) -> _opener[IO[bytes]]:\n",
      "    758     if _is_path(name_or_buffer):\n",
      "--> 759         return _open_file(name_or_buffer, mode)\n",
      "    760     else:\n",
      "    761         if \"w\" in mode:\n",
      "\n",
      "File ~/WORK/BerryPicker/vm/berrypickervenv/lib/python3.11/site-packages/torch/serialization.py:740, in _open_file.__init__(self, name, mode)\n",
      "    739 def __init__(self, name: Union[str, os.PathLike[str]], mode: str) -> None:\n",
      "--> 740     super().__init__(open(name, mode))\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/sa641631/WORK/BerryPicker-Flows/VisualProprioception_flow_01/result/visual_proprioception/vit_base/proprioception_mlp.pth'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"***Starting automated running of the flow.\\n The path for the output notebooks is\\n{result_path}\")\n",
    "\n",
    "for exprun in tqdm.tqdm(expruns):\n",
    "    print(f\"***Automating {exprun['notebook']} :\\n {exprun['experiment']}/{exprun['run']}\")\n",
    "    notebook_path = pathlib.Path(\"..\", exprun[\"notebook\"])\n",
    "    output_filename = f\"{notebook_path.stem}_{exprun['experiment']}_{exprun['run']}_output{notebook_path.suffix}\"\n",
    "    print(f\"--> {output_filename}\")\n",
    "    # parameters that we are passing on to the notebook\n",
    "    params = {}\n",
    "    params[\"experiment\"] = exprun[\"experiment\"]\n",
    "    params[\"run\"] = exprun[\"run\"]\n",
    "    params[\"external_path\"] = exprun[\"external_path\"]\n",
    "    params[\"data_path\"] = exprun[\"data_path\"]\n",
    "    output_path = pathlib.Path(result_path, output_filename)\n",
    "    try:\n",
    "        papermill.execute_notebook(\n",
    "            notebook_path,\n",
    "            output_path.absolute(),\n",
    "            cwd=notebook_path.parent,\n",
    "            parameters=params\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"There was an exception {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8455f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
