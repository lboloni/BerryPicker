{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sensor processing model using a Convolutional Variational Autoencoder \n",
    "\n",
    "Using the Julian-8897-Conv-VAE-PyTorch implementation to train a sensor processing model based on convolutional variational autoencoder. \n",
    "\n",
    "The parameters of the training are described by an experiment run of type \"sensorprocessing_conv_vae\". The result of runing the code in this notebook is the model files that are stored in the experiment directory. \n",
    "\n",
    "As the model files will have unpredictable date-time dependent names, after running a satisfactory model, the mode name and directory will need to be copied to the experiment/run yaml file, in the model_subdir and model_checkpoint fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\\\python313.zip', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\\\DLLs', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\\\Lib', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0', 'c:\\\\Users\\\\lotzi\\\\Work\\\\_VirtualEnvs\\\\BerryPicker', '', 'c:\\\\Users\\\\lotzi\\\\Work\\\\_VirtualEnvs\\\\BerryPicker\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\lotzi\\\\Work\\\\_VirtualEnvs\\\\BerryPicker\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\lotzi\\\\Work\\\\_VirtualEnvs\\\\BerryPicker\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\lotzi\\\\Work\\\\_VirtualEnvs\\\\BerryPicker\\\\Lib\\\\site-packages\\\\Pythonwin', '..', '..', '..', 'c:\\\\Users\\\\lotzi\\\\Work\\\\_Code\\\\Conv-VAE-PyTorch', '..', '..', 'c:\\\\Users\\\\lotzi\\\\Work\\\\_Code\\\\Conv-VAE-PyTorch']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import pprint\n",
    "from demonstration.demonstration import Demonstration, get_simple_transform\n",
    "\n",
    "# adding the Julian-8897-Conv-VAE-PyTorch into the path\n",
    "vaepath = pathlib.Path(Config()[\"conv_vae\"][\"code_dir\"]).expanduser()\n",
    "sys.path.append(str(vaepath))\n",
    "print(sys.path)\n",
    "\n",
    "# At some point in the development, this hack was necessary for some reason. \n",
    "# It seems that as of Feb 2025, the code runs on Windows and Linux without it.\n",
    "#temp = pathlib.PosixPath\n",
    "#pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "from conv_vae import get_conv_vae_config, create_configured_vae_json, train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp/run initialization\n",
    "Create the exp/run-s that describe the parameters of the training. \n",
    "Some of the code here is structured in such a way as to make the notebook automatizable with papermill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# *** Initialize the variables with default values \n",
    "# *** This cell should be tagged as parameters     \n",
    "# *** If papermill is used, some of the values will be overwritten \n",
    "\n",
    "# If it is set to true, the exprun will be recreated from scratch\n",
    "creation_style = \"exist-ok\"\n",
    "\n",
    "# If not None, set an external experiment path\n",
    "external_path = None\n",
    "# If not None, set an output path\n",
    "data_path = None\n",
    "# If not None, set the epochs to something different than the exp\n",
    "epochs = None\n",
    "\n",
    "# Specify and load the experiment\n",
    "experiment = \"sensorprocessing_conv_vae\"\n",
    "run = \"sp_vae_128\" \n",
    "# run = \"sp_vae_128_300epochs\" \n",
    "# run = \"sp_vae_256\" \n",
    "# run = \"sp_vae_256_300epochs\" \n",
    "\n",
    "#### Temporary values - these would be overwritten by the flow  #####\n",
    "creation_style = \"exist-ok\"\n",
    "data_path = \"c:/Users/lotzi/Work/_Data/BerryPicker-Flows/BC-touch-apple/result\"\n",
    "experiment = \"sensorprocessing_conv_vae\"\n",
    "external_path = \"c:/Users/lotzi/Work/_Data/BerryPicker-Flows/BC-touch-apple/exprun\"\n",
    "run = \"_flow_sp_conv_vae_0001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Experiment config path changed to c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\exprun\n",
      "***ExpRun**: Experiment sensorprocessing_conv_vae copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\exprun\\sensorprocessing_conv_vae\n",
      "***ExpRun**: Experiment robot_al5d copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\exprun\\robot_al5d\n",
      "***ExpRun**: Experiment demonstration copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\exprun\\demonstration\n",
      "***ExpRun**: Experiment data path changed to c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\result\n",
      "***ExpRun**: Configuration for exp/run: sensorprocessing_conv_vae/_flow_sp_conv_vae_0001 successfully loaded\n",
      "Experiment:\n",
      "    class: ConvVaeSensorProcessing\n",
      "    clean_checkpoints: true\n",
      "    data_dir: c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\result\\sensorprocessing_conv_vae\\_flow_sp_conv_vae_0001\n",
      "    epochs: 15\n",
      "    exp_run_sys_indep_file: c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\exprun\\sensorprocessing_conv_vae\\_flow_sp_conv_vae_0001.yaml\n",
      "    experiment_name: sensorprocessing_conv_vae\n",
      "    image_size:\n",
      "    - 64\n",
      "    - 64\n",
      "    json_template_name: conv-vae-config-default.json\n",
      "    latent_size: 128\n",
      "    model_dir: models\n",
      "    model_name: VAE_Robot\n",
      "    run_name: _flow_sp_conv_vae_0001\n",
      "    save_period: 5\n",
      "    subrun_name: null\n",
      "    time_started: '2025-12-05 14:54:35.668804'\n",
      "    training_data:\n",
      "    - - touch-apple\n",
      "      - sp_training_00000\n",
      "      - dev0\n",
      "    - - touch-apple\n",
      "      - sp_training_00001\n",
      "      - dev0\n",
      "    - - touch-apple\n",
      "      - sp_training_00002\n",
      "      - dev0\n",
      "    - - touch-apple\n",
      "      - sp_training_00003\n",
      "      - dev0\n",
      "    training_data_dir: vae-training-data\n",
      "    validation_data:\n",
      "    - - touch-apple\n",
      "      - sp_validation_00000\n",
      "      - dev0\n",
      "    - - touch-apple\n",
      "      - sp_validation_00001\n",
      "      - dev0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if external_path:\n",
    "    external_path = pathlib.Path(external_path)\n",
    "    assert external_path.exists()\n",
    "    Config().set_exprun_path(external_path)\n",
    "    Config().copy_experiment(\"sensorprocessing_conv_vae\")\n",
    "    Config().copy_experiment(\"robot_al5d\")\n",
    "    Config().copy_experiment(\"demonstration\")\n",
    "if data_path:\n",
    "    data_path = pathlib.Path(data_path)\n",
    "    assert data_path.exists()\n",
    "    Config().set_results_path(data_path)\n",
    "\n",
    "exp = Config().get_experiment(experiment, run, creation_style=creation_style)\n",
    "if epochs:\n",
    "    exp[\"epochs\"] = epochs\n",
    "pprint.pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training data for the Conv-VAE\n",
    "\n",
    "We collect the training data for the Conv-VAE by gathering all the pictures from all the demonstrations of a specific task. One can select the pictures by creating a specific task, and copy there all the relevant demonstrations. \n",
    "\n",
    "The collected pictures are put in a newly created training directory for the run:\n",
    "\n",
    "```\n",
    "$experiment\\vae-training-data\\Images\\*.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_to_training_dir(exp, training_image_dir):\n",
    "    \"\"\"Copy all the images specified in the training_data field to the training directory.\"\"\"\n",
    "    count = 0\n",
    "    transform = get_simple_transform()\n",
    "    print(\"***Train-Conv-VAE***: Copying training images to training directory\")\n",
    "    for val in exp[\"training_data\"]:\n",
    "        run, demo_name, camera = val\n",
    "        exp_demo = Config().get_experiment(\"demonstration\", run)\n",
    "        demo = Demonstration(exp_demo, demo_name)\n",
    "        for i in range(demo.metadata[\"maxsteps\"]):\n",
    "            training_image_path = pathlib.Path(training_image_dir, f\"train_{count:05d}.jpg\")\n",
    "            demo.write_image(i, training_image_path, camera=camera, transform=transform)\n",
    "            count += 1\n",
    "    print(f\"***Train-Conv-VAE***: Copying training images to training directory done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Train-Conv-VAE***: Copying training images to training directory\n",
      "***ExpRun**: Configuration for exp/run: demonstration/touch-apple successfully loaded\n",
      "***ExpRun**: Configuration for exp/run: demonstration/touch-apple successfully loaded\n",
      "***ExpRun**: Configuration for exp/run: demonstration/touch-apple successfully loaded\n",
      "***ExpRun**: Configuration for exp/run: demonstration/touch-apple successfully loaded\n",
      "***Train-Conv-VAE***: Copying training images to training directory done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deciding on the location of the training data\n",
    "training_data_dir = pathlib.Path(exp.data_dir(), exp[\"training_data_dir\"])\n",
    "training_image_dir = pathlib.Path(training_data_dir, \"Images\")\n",
    "# We assume that if the directory, exists, it had been previously populated with images\n",
    "if not training_image_dir.exists():\n",
    "    training_image_dir.mkdir(exist_ok = False, parents=True)\n",
    "    copy_images_to_training_dir(exp, training_image_dir=training_image_dir)\n",
    "else:\n",
    "    print(f\"***Train-Conv-VAE***: Training image dir {training_image_dir} already exists. Do not repeat the copying.\")            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the training\n",
    "\n",
    "Actually run the training. This is done by creating the json-based configuration file of the Conv-VAE library with the parameters specified in the library. Then we call the code of the library to perform the training, and copy the last checkpoint as the final model.\n",
    "If the final model exists, just exit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\sensorprocessing\\conv-vae-config-default.json\n",
      "{'name': 'VAE_Robot', 'n_gpu': 1, 'arch': {'type': 'VanillaVAE', 'args': {'in_channels': 3, 'latent_dims': 128, 'flow': False}}, 'data_loader': {'type': 'CelebDataLoader', 'args': {'data_dir': 'c:\\\\Users\\\\lotzi\\\\Work\\\\_Data\\\\BerryPicker-Flows\\\\BC-touch-apple\\\\result\\\\sensorprocessing_conv_vae\\\\_flow_sp_conv_vae_0001\\\\vae-training-data', 'batch_size': 64, 'shuffle': True, 'validation_split': 0.2, 'num_workers': 2}}, 'optimizer': {'type': 'Adam', 'args': {'lr': 0.005, 'weight_decay': 0.0, 'amsgrad': True}}, 'loss': 'elbo_loss', 'metrics': [], 'lr_scheduler': {'type': 'StepLR', 'args': {'step_size': 50, 'gamma': 0.1}}, 'trainer': {'epochs': 15, 'save_dir': 'c:\\\\Users\\\\lotzi\\\\Work\\\\_Data\\\\BerryPicker-Flows\\\\BC-touch-apple\\\\result\\\\sensorprocessing_conv_vae\\\\_flow_sp_conv_vae_0001\\\\models', 'save_period': 5, 'verbosity': 2, 'monitor': 'min val_loss', 'early_stop': 10, 'tensorboard': True}}\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\result\\sensorprocessing_conv_vae\\_flow_sp_conv_vae_0001\\models\\conv-vae-configured.json\n",
      "Warning: logging configuration file is not found in logger\\logger_config.json.\n",
      "***Train-Conv-VAE***: Running the trainer from scratch for 15 epochs\n",
      "***Timer*** training started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\utils\\util.py:59: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\utils\\util.py:60: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\utils\\util.py:61: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n",
      "DEBUG:trainer:Train Epoch: 1 [0/732 (0%)] Loss: 352143.343750\n",
      "DEBUG:trainer:Train Epoch: 1 [512/732 (70%)] Loss: 64465.968750\n",
      "INFO:trainer:    epoch          : 1\n",
      "INFO:trainer:    loss           : 98122.58138020833\n",
      "WARNING:trainer:Warning: Metric 'val_loss' is not found. Model performance monitoring is disabled.\n",
      "DEBUG:trainer:Train Epoch: 2 [0/732 (0%)] Loss: 56779.199219\n",
      "DEBUG:trainer:Train Epoch: 2 [512/732 (70%)] Loss: 38332.609375\n",
      "INFO:trainer:    epoch          : 2\n",
      "INFO:trainer:    loss           : 43143.468587239586\n",
      "DEBUG:trainer:Train Epoch: 3 [0/732 (0%)] Loss: 51580.398438\n",
      "DEBUG:trainer:Train Epoch: 3 [512/732 (70%)] Loss: 41581.320312\n",
      "INFO:trainer:    epoch          : 3\n",
      "INFO:trainer:    loss           : 43326.16748046875\n",
      "DEBUG:trainer:Train Epoch: 4 [0/732 (0%)] Loss: 40265.539062\n",
      "DEBUG:trainer:Train Epoch: 4 [512/732 (70%)] Loss: 42011.742188\n",
      "INFO:trainer:    epoch          : 4\n",
      "INFO:trainer:    loss           : 37474.740885416664\n",
      "DEBUG:trainer:Train Epoch: 5 [0/732 (0%)] Loss: 44180.093750\n",
      "DEBUG:trainer:Train Epoch: 5 [512/732 (70%)] Loss: 35631.265625\n",
      "INFO:trainer:    epoch          : 5\n",
      "INFO:trainer:    loss           : 35808.47111002604\n",
      "INFO:trainer:Saving checkpoint: c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\result\\sensorprocessing_conv_vae\\_flow_sp_conv_vae_0001\\models\\models\\VAE_Robot\\1205_145441\\checkpoint-epoch5.pth ...\n",
      "DEBUG:trainer:Train Epoch: 6 [0/732 (0%)] Loss: 34587.085938\n",
      "DEBUG:trainer:Train Epoch: 6 [512/732 (70%)] Loss: 36051.027344\n",
      "INFO:trainer:    epoch          : 6\n",
      "INFO:trainer:    loss           : 31838.068684895832\n",
      "DEBUG:trainer:Train Epoch: 7 [0/732 (0%)] Loss: 32423.496094\n",
      "DEBUG:trainer:Train Epoch: 7 [512/732 (70%)] Loss: 29431.400391\n",
      "INFO:trainer:    epoch          : 7\n",
      "INFO:trainer:    loss           : 29126.970296223957\n",
      "DEBUG:trainer:Train Epoch: 8 [0/732 (0%)] Loss: 28865.638672\n",
      "DEBUG:trainer:Train Epoch: 8 [512/732 (70%)] Loss: 26931.945312\n",
      "INFO:trainer:    epoch          : 8\n",
      "INFO:trainer:    loss           : 25915.481119791668\n",
      "DEBUG:trainer:Train Epoch: 9 [0/732 (0%)] Loss: 25805.044922\n",
      "DEBUG:trainer:Train Epoch: 9 [512/732 (70%)] Loss: 22598.843750\n",
      "INFO:trainer:    epoch          : 9\n",
      "INFO:trainer:    loss           : 22010.820882161457\n",
      "DEBUG:trainer:Train Epoch: 10 [0/732 (0%)] Loss: 20214.593750\n",
      "DEBUG:trainer:Train Epoch: 10 [512/732 (70%)] Loss: 18892.162109\n",
      "INFO:trainer:    epoch          : 10\n",
      "INFO:trainer:    loss           : 17932.813069661457\n",
      "INFO:trainer:Saving checkpoint: c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\result\\sensorprocessing_conv_vae\\_flow_sp_conv_vae_0001\\models\\models\\VAE_Robot\\1205_145441\\checkpoint-epoch10.pth ...\n",
      "DEBUG:trainer:Train Epoch: 11 [0/732 (0%)] Loss: 17819.179688\n",
      "DEBUG:trainer:Train Epoch: 11 [512/732 (70%)] Loss: 16842.810547\n",
      "INFO:trainer:    epoch          : 11\n",
      "INFO:trainer:    loss           : 15871.915893554688\n",
      "DEBUG:trainer:Train Epoch: 12 [0/732 (0%)] Loss: 15897.035156\n",
      "DEBUG:trainer:Train Epoch: 12 [512/732 (70%)] Loss: 14401.636719\n",
      "INFO:trainer:    epoch          : 12\n",
      "INFO:trainer:    loss           : 14471.052083333334\n",
      "DEBUG:trainer:Train Epoch: 13 [0/732 (0%)] Loss: 13994.810547\n",
      "DEBUG:trainer:Train Epoch: 13 [512/732 (70%)] Loss: 15014.422852\n",
      "INFO:trainer:    epoch          : 13\n",
      "INFO:trainer:    loss           : 13700.641276041666\n",
      "DEBUG:trainer:Train Epoch: 14 [0/732 (0%)] Loss: 13481.182617\n",
      "DEBUG:trainer:Train Epoch: 14 [512/732 (70%)] Loss: 12867.892578\n",
      "INFO:trainer:    epoch          : 14\n",
      "INFO:trainer:    loss           : 12782.088989257812\n",
      "DEBUG:trainer:Train Epoch: 15 [0/732 (0%)] Loss: 13483.922852\n",
      "DEBUG:trainer:Train Epoch: 15 [512/732 (70%)] Loss: 15277.635742\n",
      "INFO:trainer:    epoch          : 15\n",
      "INFO:trainer:    loss           : 13407.490885416666\n",
      "INFO:trainer:Saving checkpoint: c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\result\\sensorprocessing_conv_vae\\_flow_sp_conv_vae_0001\\models\\models\\VAE_Robot\\1205_145441\\checkpoint-epoch15.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Train-Conv-VAE***: Copying the checkpoint from c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\result\\sensorprocessing_conv_vae\\_flow_sp_conv_vae_0001\\models\\models\\VAE_Robot\\1205_145441\\checkpoint-epoch15.pth to c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\result\\sensorprocessing_conv_vae\\_flow_sp_conv_vae_0001\\model.pth\n",
      "removing checkpoint file: c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\result\\sensorprocessing_conv_vae\\_flow_sp_conv_vae_0001\\models\\models\\VAE_Robot\\1205_145441\\checkpoint-epoch5.pth\n",
      "removing checkpoint file: c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\BC-touch-apple\\result\\sensorprocessing_conv_vae\\_flow_sp_conv_vae_0001\\models\\models\\VAE_Robot\\1205_145441\\checkpoint-epoch10.pth\n"
     ]
    }
   ],
   "source": [
    "model_target_path = pathlib.Path(exp.data_dir(), \"model.pth\")\n",
    "json_target_path = pathlib.Path(exp.data_dir(), \"config.json\")\n",
    "\n",
    "if model_target_path.exists():\n",
    "    print(\"***Train-Conv-VAE*** already completed for this exp/run\")\n",
    "else:\n",
    "    # Create the vae configuration, based on the experiment\n",
    "    file = create_configured_vae_json(exp)\n",
    "    print(file)\n",
    "    vae_config = get_conv_vae_config(file)\n",
    "    # actually run the training\n",
    "    print(f'***Train-Conv-VAE***: Running the trainer from scratch for {vae_config[\"trainer\"][\"epochs\"]} epochs')\n",
    "    exp.start_timer(\"training\")\n",
    "    trainer = train(vae_config)\n",
    "    checkpoint_path = pathlib.Path(trainer.checkpoint_dir, f\"checkpoint-epoch{trainer.epochs}.pth\")\n",
    "\n",
    "    json_path = pathlib.Path(trainer.checkpoint_dir, \"config.json\")\n",
    "\n",
    "    if checkpoint_path.exists():\n",
    "        print(f\"***Train-Conv-VAE***: Copying the checkpoint from {checkpoint_path} to {model_target_path}\")\n",
    "        model_target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(checkpoint_path, model_target_path)\n",
    "        # target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(json_path, json_target_path)\n",
    "        if exp[\"clean_checkpoints\"]:\n",
    "            for i in range(trainer.epochs+1):\n",
    "                checkpoint = pathlib.Path(trainer.checkpoint_dir, f\"checkpoint-epoch{i}.pth\")\n",
    "                if checkpoint.exists():\n",
    "                    print(f\"removing checkpoint file: {checkpoint}\")\n",
    "                    checkpoint.unlink()\n",
    "    else:\n",
    "        print(f\"***Train-Conv-VAE***: The checkpoint file {checkpoint_path} does not exist. Cannot copy it to model.pth\")    \n",
    "        exp.end_timer(\"training\")\n",
    "    # cleaning up the checkpoints\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
