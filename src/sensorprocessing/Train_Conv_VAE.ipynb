{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sensor processing model using a Convolutional Variational Autoencoder \n",
    "\n",
    "Using the Julian-8897-Conv-VAE-PyTorch implementation to train a sensor processing model based on convolutional variational autoencoder. \n",
    "\n",
    "The parameters of the training are described by an experiment run of type \"sensorprocessing_conv_vae\". The result of runing the code in this notebook is the model files that are stored in the experiment directory. \n",
    "\n",
    "As the model files will have unpredictable date-time dependent names, after running a satisfactory model, the mode name and directory will need to be copied to the experiment/run yaml file, in the model_subdir and model_checkpoint fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Loading pointer config file:\n",
      "\t/Users/lboloni/.config/BerryPicker/mainsettings.yaml\n",
      "***ExpRun**: Loading machine-specific config file:\n",
      "\t/Users/lboloni/Google Drive/My Drive/LotziStudy/Code/PackageTracking/BerryPicker/settings/settings-szenes.yaml\n",
      "['/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python313.zip', '/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13', '/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/lib-dynload', '', '/Users/lboloni/Documents/Develop/VirtualEnvs/BerryPicker/lib/python3.13/site-packages', '..', '..', '..', '/var/folders/md/0nymjxfj0739zq6dqz0v7g840000gn/T/tmpl24wm6xf', '/Users/lboloni/Documents/Develop/Github/Conv-VAE-PyTorch/Conv-VAE-PyTorch']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import pprint\n",
    "from demonstration.demonstration import Demonstration, get_simple_transform\n",
    "\n",
    "\n",
    "# adding the Julian-8897-Conv-VAE-PyTorch into the path\n",
    "sys.path.append(Config()[\"conv_vae\"][\"code_dir\"])\n",
    "print(sys.path)\n",
    "# At some point in the development, this hack was necessary for some reason. \n",
    "# It seems that as of Feb 2025, the code runs on Windows and Linux without it.\n",
    "#temp = pathlib.PosixPath\n",
    "#pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "from conv_vae import get_conv_vae_config, create_configured_vae_json, train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp/run initialization\n",
    "Create the exp/run-s that describe the parameters of the training. \n",
    "Some of the code here is structured in such a way as to make the notebook automatizable with papermill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# *** Initialize the variables with default values \n",
    "# *** This cell should be tagged as parameters     \n",
    "# *** If papermill is used, some of the values will be overwritten \n",
    "\n",
    "# If it is set to true, the exprun will be recreated from scratch\n",
    "creation_style = \"exist-ok\"\n",
    "\n",
    "# If not None, set an external experiment path\n",
    "external_path = None\n",
    "# If not None, set an output path\n",
    "data_path = None\n",
    "# If not None, set the epochs to something different than the exp\n",
    "epochs = None\n",
    "\n",
    "# Specify and load the experiment\n",
    "experiment = \"sensorprocessing_conv_vae\"\n",
    "run = \"sp_vae_128\" \n",
    "# run = \"sp_vae_128_300epochs\" \n",
    "# run = \"sp_vae_256\" \n",
    "# run = \"sp_vae_256_300epochs\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Configuration for exp/run: sensorprocessing_conv_vae/sp_vae_128 successfully loaded\n",
      "Experiment:\n",
      "    class: ConvVaeSensorProcessing\n",
      "    data_dir: c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\sp_vae_128\n",
      "    epochs: 5\n",
      "    exp_run_sys_indep_file: C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\sensorprocessing_conv_vae\\sp_vae_128.yaml\n",
      "    experiment_name: sensorprocessing_conv_vae\n",
      "    image_size:\n",
      "    - 64\n",
      "    - 64\n",
      "    json_template_name: conv-vae-config-default.json\n",
      "    latent_size: 128\n",
      "    model_dir: models\n",
      "    model_name: VAE_Robot\n",
      "    run_name: sp_vae_128\n",
      "    save_period: 5\n",
      "    subrun_name: null\n",
      "    training_data:\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_15_53'\n",
      "      - dev2\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_16_57'\n",
      "      - dev2\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_19_12'\n",
      "      - dev2\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_21_28'\n",
      "      - dev2\n",
      "    training_data_dir: vae-training-data\n",
      "    validation_data:\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_23_19'\n",
      "      - dev2\n",
      "    - - random-both-cameras-video\n",
      "      - '2025_03_08__14_24_52'\n",
      "      - dev2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if external_path:\n",
    "    external_path = pathlib.Path(external_path)\n",
    "    assert external_path.exists()\n",
    "    Config().set_exprun_path(external_path)\n",
    "    Config().copy_experiment(\"sensorprocessing_conv_vae\")\n",
    "    Config().copy_experiment(\"robot_al5d\")\n",
    "    Config().copy_experiment(\"demonstration\")\n",
    "if data_path:\n",
    "    data_path = pathlib.Path(data_path)\n",
    "    assert data_path.exists()\n",
    "    Config().set_results_path(data_path)\n",
    "\n",
    "exp = Config().get_experiment(experiment, run, creation_style=creation_style)\n",
    "if epochs:\n",
    "    exp[\"epochs\"] = epochs\n",
    "pprint.pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training data for the Conv-VAE\n",
    "\n",
    "We collect the training data for the Conv-VAE by gathering all the pictures from all the demonstrations of a specific task. One can select the pictures by creating a specific task, and copy there all the relevant demonstrations. \n",
    "\n",
    "The collected pictures are put in a newly created training directory for the run:\n",
    "\n",
    "```\n",
    "$experiment\\vae-training-data\\Images\\*.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_to_training_dir(exp, training_image_dir):\n",
    "    \"\"\"Copy all the images specified in the training_data field to the training directory.\"\"\"\n",
    "    count = 0\n",
    "    transform = get_simple_transform()\n",
    "    print(\"***Train-Conv-VAE***: Copying training images to training directory\")\n",
    "    for val in exp[\"training_data\"]:\n",
    "        run, demo_name, camera = val\n",
    "        exp_demo = Config().get_experiment(\"demonstration\", run)\n",
    "        demo = Demonstration(exp_demo, demo_name)\n",
    "        for i in range(demo.metadata[\"maxsteps\"]):\n",
    "            training_image_path = pathlib.Path(training_image_dir, f\"train_{count:05d}.jpg\")\n",
    "            demo.write_image(i, training_image_path, camera=camera, transform=transform)\n",
    "            count += 1\n",
    "    print(f\"***Train-Conv-VAE***: Copying training images to training directory done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Train-Conv-VAE***: There are already images in training image dir {training_image_dir}. Do not repeat the copying.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deciding on the location of the training data\n",
    "training_data_dir = pathlib.Path(exp.data_dir(), exp[\"training_data_dir\"])\n",
    "training_image_dir = pathlib.Path(training_data_dir, \"Images\")\n",
    "# We assume that if the directory, exists, it had been previously populated with images\n",
    "if not training_image_dir.exists():\n",
    "    training_image_dir.mkdir(exist_ok = False, parents=True)\n",
    "    copy_images_to_training_dir(exp, training_image_dir=training_image_dir)\n",
    "else:\n",
    "    print(f\"***Train-Conv-VAE***: Training image dir {training_image_dir} already exists. Do not repeat the copying.\")            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the training\n",
    "\n",
    "Actually run the training. This is done by creating the json-based configuration file of the Conv-VAE library with the parameters specified in the library. Then we call the code of the library to perform the training, and copy the last checkpoint as the final model.\n",
    "If the final model exists, just exit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Train-Conv-VAE*** already completed for this exp/run\n"
     ]
    }
   ],
   "source": [
    "model_target_path = pathlib.Path(exp.data_dir(), \"model.pth\")\n",
    "json_target_path = pathlib.Path(exp.data_dir(), \"config.json\")\n",
    "\n",
    "if model_target_path.exists():\n",
    "    print(\"***Train-Conv-VAE*** already completed for this exp/run\")\n",
    "else:\n",
    "    # Create the vae configuration, based on the experiment\n",
    "    file = create_configured_vae_json(exp)\n",
    "    print(file)\n",
    "    vae_config = get_conv_vae_config(file)\n",
    "    # actually run the training\n",
    "    print(f'***Train-Conv-VAE***: Running the trainer from scratch for {vae_config[\"trainer\"][\"epochs\"]} epochs')\n",
    "    exp.start_timer(\"training\")\n",
    "    trainer = train(vae_config)\n",
    "    checkpoint_path = pathlib.Path(trainer.checkpoint_dir, f\"checkpoint-epoch{trainer.epochs}.pth\")\n",
    "\n",
    "    json_path = pathlib.Path(trainer.checkpoint_dir, \"config.json\")\n",
    "\n",
    "    if checkpoint_path.exists():\n",
    "        print(f\"***Train-Conv-VAE***: Copying the checkpoint from {checkpoint_path} to {model_target_path}\")\n",
    "        model_target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(checkpoint_path, model_target_path)\n",
    "        # target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(json_path, json_target_path)\n",
    "    else:\n",
    "        print(f\"***Train-Conv-VAE***: The checkpoint file {checkpoint_path} does not exist. Cannot copy it to model.pth\")    \n",
    "        exp.end_timer(\"training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
