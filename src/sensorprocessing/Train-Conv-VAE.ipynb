{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sensor processing model using a Convolutional Variational Autoencoder \n",
    "\n",
    "Using the Julian-8897-Conv-VAE-PyTorch implementation to train a sensor processing model based on convolutional variational autoencoder. \n",
    "\n",
    "The parameters of the training are described by an experiment run of type \"sensorprocessing_conv_vae\". The result of runing the code in this notebook is the model files that are stored in the experiment directory. \n",
    "\n",
    "As the model files will have unpredictable date-time dependent names, after running a satisfactory model, the mode name and directory will need to be copied to the experiment/run yaml file, in the model_subdir and model_checkpoint fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Loading pointer config file:\n",
      "\tC:\\Users\\lboloni\\.config\\BerryPicker\\mainsettings.yaml\n",
      "***ExpRun**: Loading machine-specific config file:\n",
      "\tG:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\settings-LotziYoga.yaml\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import pprint\n",
    "from demonstration.demonstration import Demonstration, get_simple_transform\n",
    "\n",
    "\n",
    "# adding the Julian-8897-Conv-VAE-PyTorch into the path\n",
    "sys.path.append(Config()[\"conv_vae\"][\"code_dir\"])\n",
    "\n",
    "# At some point in the development, this hack was necessary for some reason. \n",
    "# It seems that as of Feb 2025, the code runs on Windows and Linux without it.\n",
    "#temp = pathlib.PosixPath\n",
    "#pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "from conv_vae import get_conv_vae_config, create_configured_vae_json, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Configuration for exp/run: sensorprocessing_conv_vae/proprio_256 successfully loaded\n",
      "Experiment:\n",
      "    data_dir: c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\proprio_256\n",
      "    epochs: 5\n",
      "    exp_run_sys_dep_file: G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\sensorprocessing_conv_vae\\proprio_256_sysdep.yaml\n",
      "    exp_run_sys_indep_file: C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\sensorprocessing_conv_vae\\proprio_256.yaml\n",
      "    experiment_name: sensorprocessing_conv_vae\n",
      "    image_size:\n",
      "    - 64\n",
      "    - 64\n",
      "    json_template_name: conv-vae-config-default.json\n",
      "    latent_size: 256\n",
      "    model_checkpoint: checkpoint-epoch300.pth\n",
      "    model_dir: models\n",
      "    model_name: VAE_Robot\n",
      "    model_subdir: 0304_101805\n",
      "    run_name: proprio_256\n",
      "    save_period: 5\n",
      "    subrun_name: null\n",
      "    training_data:\n",
      "    - - freeform\n",
      "      - '2024_12_26__16_40_20'\n",
      "      - dev2\n",
      "    - - freeform\n",
      "      - '2024_12_26__16_44_06'\n",
      "      - dev2\n",
      "    training_data_dir: vae-training-data\n",
      "    validation_data:\n",
      "    - - freeform\n",
      "      - '2024_12_26__16_40_20'\n",
      "      - dev2\n",
      "    - - freeform\n",
      "      - '2024_12_26__16_44_06'\n",
      "      - dev2\n",
      "    validation_demo: '2025_02_25__15_46_11'\n",
      "    validation_task: proprio_sp_validation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If it is set to true, no actual copying will be done\n",
    "dry_run = False\n",
    "\n",
    "# Specify and load the experiment\n",
    "experiment = \"sensorprocessing_conv_vae\"\n",
    "# run = \"proprio_128\" \n",
    "run = \"proprio_256\" \n",
    "exp = Config().get_experiment(experiment, run)\n",
    "pprint.pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training data for the Conv-VAE\n",
    "\n",
    "We collect the training data for the Conv-VAE by gathering all the pictures from all the demonstrations of a specific task. One can select the pictures by creating a specific task, and copy there all the relevant demonstrations. \n",
    "\n",
    "The collected pictures are put in a newly created training directory for the run:\n",
    "\n",
    "```\n",
    "$experiment\\vae-training-data\\Images\\*.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_to_training_dir(exp, training_image_dir):\n",
    "    \"\"\"Copy all the images specified in the training_data field to the training directory.\"\"\"\n",
    "    count = 0\n",
    "    transform = get_simple_transform()\n",
    "    print(\"***Train-Conv-VAE***: Copying training images to training directory\")\n",
    "    for val in exp[\"training_data\"]:\n",
    "        run, demo_name, camera = val\n",
    "        exp_demo = Config().get_experiment(\"demonstration\", run)\n",
    "        demo = Demonstration(exp_demo, demo_name)\n",
    "        for i in range(demo.metadata[\"maxsteps\"]):\n",
    "            training_image_path = pathlib.Path(training_image_dir, f\"train_{count:05d}.jpg\")\n",
    "            demo.write_image(i, training_image_path, camera=camera, transform=transform)\n",
    "            count += 1\n",
    "    print(f\"***Train-Conv-VAE***: Copying training images to training directory done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Train-Conv-VAE***: There are already images in training image dir {training_image_dir}. Do not repeat the copying.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deciding on the location of the training data\n",
    "training_data_dir = pathlib.Path(exp.data_dir(), exp[\"training_data_dir\"])\n",
    "training_image_dir = pathlib.Path(training_data_dir, \"Images\")\n",
    "# We assume that if the directory, exists, it had been previously populated with images\n",
    "if not training_image_dir.exists():\n",
    "    training_image_dir.mkdir(exist_ok = False, parents=True)\n",
    "    copy_images_to_training_dir(exp, training_image_dir=training_image_dir)\n",
    "else:\n",
    "    print(\"***Train-Conv-VAE***: There are already images in training image dir {training_image_dir}. Do not repeat the copying.\")            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the training\n",
    "\n",
    "Actually run the training. This is done by creating the json-based configuration file of the Conv-VAE library with the parameters specified in the library. Then we call the code of the library to perform the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\sensorprocessing\\conv-vae-config-default.json\n",
      "{'name': 'VAE_Robot', 'n_gpu': 1, 'arch': {'type': 'VanillaVAE', 'args': {'in_channels': 3, 'latent_dims': 256, 'flow': False}}, 'data_loader': {'type': 'CelebDataLoader', 'args': {'data_dir': 'c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-experiments\\\\sensorprocessing_conv_vae\\\\proprio_256\\\\vae-training-data', 'batch_size': 64, 'shuffle': True, 'validation_split': 0.2, 'num_workers': 2}}, 'optimizer': {'type': 'Adam', 'args': {'lr': 0.005, 'weight_decay': 0.0, 'amsgrad': True}}, 'loss': 'elbo_loss', 'metrics': [], 'lr_scheduler': {'type': 'StepLR', 'args': {'step_size': 50, 'gamma': 0.1}}, 'trainer': {'epochs': 5, 'save_dir': 'c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-experiments\\\\sensorprocessing_conv_vae\\\\proprio_256\\\\models', 'save_period': 5, 'verbosity': 2, 'monitor': 'min val_loss', 'early_stop': 10, 'tensorboard': True}}\n",
      "c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\proprio_256\\models\\conv-vae-configured.json\n",
      "Warning: logging configuration file is not found in logger\\logger_config.json.\n",
      "***Train-Conv-VAE***: Running the trainer from scratch for 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:59: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:60: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:61: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n",
      "DEBUG:trainer:Train Epoch: 1 [0/789 (0%)] Loss: 344064.375000\n",
      "DEBUG:trainer:Train Epoch: 1 [512/789 (65%)] Loss: 62226.156250\n",
      "INFO:trainer:    epoch          : 1\n",
      "INFO:trainer:    loss           : 109345.08713942308\n",
      "WARNING:trainer:Warning: Metric 'val_loss' is not found. Model performance monitoring is disabled.\n",
      "DEBUG:trainer:Train Epoch: 2 [0/789 (0%)] Loss: 60686.335938\n",
      "DEBUG:trainer:Train Epoch: 2 [512/789 (65%)] Loss: 73526.468750\n",
      "INFO:trainer:    epoch          : 2\n",
      "INFO:trainer:    loss           : 55180.428034855766\n",
      "DEBUG:trainer:Train Epoch: 3 [0/789 (0%)] Loss: 57402.609375\n",
      "DEBUG:trainer:Train Epoch: 3 [512/789 (65%)] Loss: 43018.933594\n",
      "INFO:trainer:    epoch          : 3\n",
      "INFO:trainer:    loss           : 45826.92653245192\n",
      "DEBUG:trainer:Train Epoch: 4 [0/789 (0%)] Loss: 45669.062500\n",
      "DEBUG:trainer:Train Epoch: 4 [512/789 (65%)] Loss: 38549.109375\n",
      "INFO:trainer:    epoch          : 4\n",
      "INFO:trainer:    loss           : 36903.039738581734\n",
      "DEBUG:trainer:Train Epoch: 5 [0/789 (0%)] Loss: 35032.886719\n",
      "DEBUG:trainer:Train Epoch: 5 [512/789 (65%)] Loss: 32714.998047\n",
      "INFO:trainer:    epoch          : 5\n",
      "INFO:trainer:    loss           : 31719.704852764422\n",
      "INFO:trainer:Saving checkpoint: c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\proprio_256\\models\\models\\VAE_Robot\\0526_185207\\checkpoint-epoch5.pth ...\n"
     ]
    }
   ],
   "source": [
    "# Create the vae configuration, based on the experiment\n",
    "file = create_configured_vae_json(exp)\n",
    "print(file)\n",
    "vae_config = get_conv_vae_config(file)\n",
    "\n",
    "# actually run the training\n",
    "print(f'***Train-Conv-VAE***: Running the trainer from scratch for {vae_config[\"trainer\"][\"epochs\"]}')\n",
    "trainer = train(vae_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<utils.util.MetricTracker object at 0x0000025D3227DF90>\n",
      "<utils.util.MetricTracker object at 0x0000025D47BC1950>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>counts</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>412356.163086</td>\n",
       "      <td>13</td>\n",
       "      <td>31719.704853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              total counts       average\n",
       "loss  412356.163086     13  31719.704853"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the metrics recorded\n",
    "# they are of utils/util.py / MetricTracker which has a pandas dataframe as data\n",
    "print(trainer.train_metrics)\n",
    "print(trainer.valid_metrics)\n",
    "# \n",
    "trainer.train_metrics._data\n",
    "# trainer.valid_metrics._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important__ After the training finished, in order to use the resulting system, one need to edit the run file (eg: vae_01.yaml) and enter into it the location of the checkpoint. This is the content printed by the code cell below\n",
    "\n",
    "__Important__ Right now, it is set up such that only every 5. epoch is checkmarked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_subdir: '0526_185207'\n",
      "model_checkpoint: 'checkpoint-epoch5.pth'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"model_subdir: '{trainer.checkpoint_dir.name}'\")\n",
    "print(f\"model_checkpoint: 'checkpoint-epoch{trainer.epochs}.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text above to be put into \n",
      " the system dependent experiment run file G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\sensorprocessing_conv_vae\\proprio_256_sysdep.yaml\n"
     ]
    }
   ],
   "source": [
    "if \"exp_run_sys_dep_file\" in exp:\n",
    "    print(f'The text above to be put into \\n the system dependent experiment run file {exp[\"exp_run_sys_dep_file\"]}')\n",
    "else:\n",
    "    print(f'As the system dependent experiment run file does not exist,\\n the text can be put into the system independent file\\n {exp[\"exp_run_sys_indep_file\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m json_target_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(exp\u001b[38;5;241m.\u001b[39mdata_dir(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***Train-Conv-VAE***: Copying the checkpoint from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtarget_path\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     target_path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopy(checkpoint_path, model_target_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target_path' is not defined"
     ]
    }
   ],
   "source": [
    "checkpoint_path = pathlib.Path(trainer.checkpoint_dir, f\"checkpoint-epoch{trainer.epochs}.pth\")\n",
    "model_target_path = pathlib.Path(exp.data_dir(), \"model.pth\")\n",
    "\n",
    "json_path = pathlib.Path(trainer.checkpoint_dir, \"config.json\")\n",
    "json_target_path = pathlib.Path(exp.data_dir(), \"config.json\")\n",
    "\n",
    "if checkpoint_path.exists():\n",
    "    print(f\"***Train-Conv-VAE***: Copying the checkpoint from {checkpoint_path} to {target_path}\")\n",
    "    target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(checkpoint_path, model_target_path)\n",
    "    target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(json_path, json_target_path)\n",
    "else:\n",
    "    print(f\"***Train-Conv-VAE***: The checkpoint file {checkpoint_path} does not exist. Cannot copy it to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.checkpoint_dir)\n",
    "print(trainer.checkpoint_dir.exists())\n",
    "print(checkpoint_path)\n",
    "print(checkpoint_path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
