{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sensor processing model using a Convolutional Variational Autoencoder \n",
    "\n",
    "Using the Julian-8897-Conv-VAE-PyTorch implementation to train a sensor processing model based on convolutional variational autoencoder. \n",
    "\n",
    "The parameters of the training are described by an experiment run of type \"sensorprocessing_conv_vae\". The result of runing the code in this notebook is the model files that are stored in the experiment directory. \n",
    "\n",
    "As the model files will have unpredictable date-time dependent names, after running a satisfactory model, the mode name and directory will need to be copied to the experiment/run yaml file, in the model_subdir and model_checkpoint fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Loading pointer config file:\n",
      "\tC:\\Users\\lboloni\\.config\\BerryPicker\\mainsettings.yaml\n",
      "***ExpRun**: Loading machine-specific config file:\n",
      "\tG:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\settings-LotziYoga.yaml\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "from pprint import pprint\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "from demonstration.demonstration import Demonstration\n",
    "\n",
    "\n",
    "# adding the Julian-8897-Conv-VAE-PyTorch into the path\n",
    "sys.path.append(Config()[\"conv_vae\"][\"code_dir\"])\n",
    "\n",
    "# At some point in the development, this hack was necessary for some reason. \n",
    "# It seems that as of Feb 2025, the code runs on Windows and Linux without it.\n",
    "#temp = pathlib.PosixPath\n",
    "#pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "from conv_vae import get_conv_vae_config, create_configured_vae_json, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Configuration for exp/run: sensorprocessing_conv_vae/proprio_128 successfully loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: {'training_data_dir': 'vae-training-data', 'json_template_name': 'conv-vae-config-default.json', 'model_name': 'VAE_Robot', 'model_dir': 'models', 'latent_size': 128, 'epochs': 300, 'save_period': 5, 'experiment_name': 'sensorprocessing_conv_vae', 'training_data': [['freeform', '2024_12_26__16_40_20'], ['freeform', '2024_12_26__16_44_06']], 'validation_data': [['freeform', '2024_12_26__16_40_20'], ['freeform', '2024_12_26__16_44_06']], 'model_subdir': '0227_211544', 'model_checkpoint': 'checkpoint-epoch300.pth', 'run_name': 'proprio_128', 'exp_run_sys_indep_file': 'C:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_Checkouts\\\\BerryPicker\\\\src\\\\experiment_configs\\\\sensorprocessing_conv_vae\\\\proprio_128.yaml', 'validation_task': 'proprio_sp_validation', 'validation_demo': '2025_02_25__15_46_11', 'exp_run_sys_dep_file': 'G:\\\\My Drive\\\\LotziStudy\\\\Code\\\\PackageTracking\\\\BerryPicker\\\\settings\\\\experiment-config\\\\LotziYoga\\\\sensorprocessing_conv_vae\\\\proprio_128_sysdep.yaml', 'data_dir': 'c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-experiments\\\\sensorprocessing_conv_vae\\\\proprio_128', 'subrun_name': None, 'time_started': '2025-05-17 17:07:00'}\n"
     ]
    }
   ],
   "source": [
    "# If it is set to true, no actual copying will be done\n",
    "dry_run = False\n",
    "\n",
    "# Specify and load the experiment\n",
    "experiment = \"sensorprocessing_conv_vae\"\n",
    "run = \"proprio_128\" \n",
    "# run = \"proprio_256\" \n",
    "exp = Config().get_experiment(experiment, run)\n",
    "pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training data for the Conv-VAE\n",
    "\n",
    "We collect the training data for the Conv-VAE by gathering all the pictures from all the demonstrations of a specific task. One can select the pictures by creating a specific task, and copy there all the relevant demonstrations. \n",
    "\n",
    "The collected pictures are put in a newly created training directory for the run:\n",
    "\n",
    "```\n",
    "$experiment\\vae-training-data\\Images\\*.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def copy_images_to_training_dir(taskname, training_image_dir):\n",
    "    \"\"\"Copy all the images from a specific task into the training image dir.\"\"\"\n",
    "    task_dir = pathlib.Path(demos_dir, taskname)\n",
    "    # _, task_dir = ui_choose_task(offer_task_creation=True)\n",
    "    for demo in task_dir.iterdir():\n",
    "        if not demo.is_dir(): continue\n",
    "        for item in demo.iterdir():\n",
    "            if item.suffix != \".jpg\": continue\n",
    "            name = f\"{demo.name}_{item.stem}.jpg\"\n",
    "            destination = pathlib.Path(training_image_dir, name)\n",
    "            print(f\"copy {item} to \\n{destination}\")\n",
    "            if not dry_run:\n",
    "                shutil.copyfile(item, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def copy_images_to_training_dir(exp, training_image_dir):\n",
    "    \"\"\"Copy all the images specified in the training_data field to the training directory.\"\"\"\n",
    "    count = 0\n",
    "    print(\"***Train-Conv-VAE***: Copying training images to training directory\")\n",
    "    for val in exp[\"training_data\"]:\n",
    "        run = val[0]\n",
    "        demo_name = val[1]\n",
    "        exp_demo = Config().get_experiment(\"demonstration\", run)\n",
    "        demo = Demonstration(exp_demo, demo_name)\n",
    "        for i in range(demo.metadata[\"maxsteps\"]):\n",
    "            training_image_path = pathlib.Path(training_image_dir, f\"train_{count:05d}.jpg\")\n",
    "            sensor, im = demo.get_image(i)\n",
    "            image = sensor[0].permute(1, 2, 0).cpu().numpy()  # to H x W x C\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "            image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(training_image_path, image_bgr)\n",
    "            count += 1\n",
    "    print(f\"***Train-Conv-VAE***: Copying training images to training directory done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of demo directories: 17\n",
      "Training data dir=c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\proprio_128\\vae-training-data\\Images\n",
      "Number of image files in training dir: 0\n",
      "***Train-Conv-VAE***: Copying training images to training directory\n",
      "***ExpRun**: Experiment default config C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\demonstration\\_demonstration.yaml was empty, ok.\n",
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\demonstration\\freeform_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: demonstration/freeform successfully loaded\n",
      "***ExpRun**: Experiment default config C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\demonstration\\_demonstration.yaml was empty, ok.\n",
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\demonstration\\freeform_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: demonstration/freeform successfully loaded\n",
      "***Train-Conv-VAE***: Copying training images to training directory done\n"
     ]
    }
   ],
   "source": [
    "demos_top = pathlib.Path(Config()[\"demos\"][\"directory\"])\n",
    "demos_dir = pathlib.Path(demos_top, \"demos\")\n",
    "\n",
    "subdir_count = sum(1 for item in demos_dir.iterdir() if item.is_dir())\n",
    "print(f\"Number of demo directories: {subdir_count}\")\n",
    "\n",
    "# Deciding on the location of the training data\n",
    "training_data_dir = pathlib.Path(exp.data_dir(), exp[\"training_data_dir\"])\n",
    "# training_data_dir = pathlib.Path(Config()[\"conv_vae\"][\"training_data_dir\"])\n",
    "training_image_dir = pathlib.Path(training_data_dir, \"Images\")\n",
    "training_image_dir.mkdir(exist_ok = False, parents=True)\n",
    "\n",
    "print(f\"Training data dir={training_image_dir}\")\n",
    "\n",
    "# Define a set of common image file extensions\n",
    "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\", \".tiff\", \".webp\"}\n",
    "# Count the image files\n",
    "image_count = sum(1 for item in training_image_dir.iterdir() if item.suffix.lower() in image_extensions and item.is_file())\n",
    "\n",
    "print(f\"Number of image files in training dir: {image_count}\")\n",
    "\n",
    "if image_count == 0:\n",
    "    copy_images_to_training_dir(exp, training_image_dir=training_image_dir)\n",
    "else:\n",
    "    print(\"***Train-Conv-VAE***: There are already images in training image dir {training_image_dir}. Do not repeat the copying.\")            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the training\n",
    "\n",
    "Actually run the training. This is done by creating the json-based configuration file of the Conv-VAE library with the parameters specified in the library. Then we call the code of the library to perform the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\sensorprocessing\\conv-vae-config-default.json\n",
      "{'name': 'VAE_Robot', 'n_gpu': 1, 'arch': {'type': 'VanillaVAE', 'args': {'in_channels': 3, 'latent_dims': 128, 'flow': False}}, 'data_loader': {'type': 'CelebDataLoader', 'args': {'data_dir': 'c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-experiments\\\\sensorprocessing_conv_vae\\\\proprio_128\\\\vae-training-data', 'batch_size': 64, 'shuffle': True, 'validation_split': 0.2, 'num_workers': 2}}, 'optimizer': {'type': 'Adam', 'args': {'lr': 0.005, 'weight_decay': 0.0, 'amsgrad': True}}, 'loss': 'elbo_loss', 'metrics': [], 'lr_scheduler': {'type': 'StepLR', 'args': {'step_size': 50, 'gamma': 0.1}}, 'trainer': {'epochs': 300, 'save_dir': 'c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-experiments\\\\sensorprocessing_conv_vae\\\\proprio_128\\\\models', 'save_period': 5, 'verbosity': 2, 'monitor': 'min val_loss', 'early_stop': 10, 'tensorboard': True}}\n",
      "c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\proprio_128\\models\\conv-vae-configured.json\n",
      "Warning: logging configuration file is not found in logger\\logger_config.json.\n",
      "Running the trainer from scratch for 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:59: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:60: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:61: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n",
      "DEBUG:trainer:Train Epoch: 1 [0/789 (0%)] Loss: 262209.468750\n",
      "DEBUG:trainer:Train Epoch: 1 [512/789 (65%)] Loss: 68304.109375\n",
      "INFO:trainer:    epoch          : 1\n",
      "INFO:trainer:    loss           : 86703.32061298077\n",
      "WARNING:trainer:Warning: Metric 'val_loss' is not found. Model performance monitoring is disabled.\n",
      "DEBUG:trainer:Train Epoch: 2 [0/789 (0%)] Loss: 58162.976562\n",
      "DEBUG:trainer:Train Epoch: 2 [512/789 (65%)] Loss: 47213.937500\n",
      "INFO:trainer:    epoch          : 2\n",
      "INFO:trainer:    loss           : 51612.25743689904\n",
      "DEBUG:trainer:Train Epoch: 3 [0/789 (0%)] Loss: 47101.308594\n",
      "DEBUG:trainer:Train Epoch: 3 [512/789 (65%)] Loss: 41140.828125\n",
      "INFO:trainer:    epoch          : 3\n",
      "INFO:trainer:    loss           : 39892.761418269234\n",
      "DEBUG:trainer:Train Epoch: 4 [0/789 (0%)] Loss: 37923.925781\n",
      "DEBUG:trainer:Train Epoch: 4 [512/789 (65%)] Loss: 36399.343750\n",
      "INFO:trainer:    epoch          : 4\n",
      "INFO:trainer:    loss           : 34324.38882211538\n",
      "DEBUG:trainer:Train Epoch: 5 [0/789 (0%)] Loss: 33907.082031\n",
      "DEBUG:trainer:Train Epoch: 5 [512/789 (65%)] Loss: 31648.947266\n",
      "INFO:trainer:    epoch          : 5\n",
      "INFO:trainer:    loss           : 30849.690655048078\n",
      "INFO:trainer:Saving checkpoint: c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\proprio_128\\models\\models\\VAE_Robot\\0517_171500\\checkpoint-epoch5.pth ...\n",
      "DEBUG:trainer:Train Epoch: 6 [0/789 (0%)] Loss: 30869.017578\n",
      "DEBUG:trainer:Train Epoch: 6 [512/789 (65%)] Loss: 28535.009766\n",
      "INFO:trainer:    epoch          : 6\n",
      "INFO:trainer:    loss           : 27617.951923076922\n",
      "DEBUG:trainer:Train Epoch: 7 [0/789 (0%)] Loss: 27159.310547\n",
      "DEBUG:trainer:Train Epoch: 7 [512/789 (65%)] Loss: 25667.060547\n",
      "INFO:trainer:    epoch          : 7\n",
      "INFO:trainer:    loss           : 24688.83428485577\n",
      "DEBUG:trainer:Train Epoch: 8 [0/789 (0%)] Loss: 29106.472656\n",
      "DEBUG:trainer:Train Epoch: 8 [512/789 (65%)] Loss: 45573.304688\n"
     ]
    }
   ],
   "source": [
    "# Create the vae configuration, based on the experiment\n",
    "file = create_configured_vae_json(exp)\n",
    "print(file)\n",
    "vae_config = get_conv_vae_config(file)\n",
    "\n",
    "# actually run the training\n",
    "print(f'Running the trainer from scratch for {vae_config[\"trainer\"][\"epochs\"]}')\n",
    "trainer = train(vae_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the metrics recorded\n",
    "# they are of utils/util.py / MetricTracker which has a pandas dataframe as data\n",
    "print(trainer.train_metrics)\n",
    "print(trainer.valid_metrics)\n",
    "# \n",
    "trainer.train_metrics._data\n",
    "# trainer.valid_metrics._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important__ After the training finished, in order to use the resulting system, one need to edit the run file (eg: vae_01.yaml) and enter into it the location of the checkpoint. This is the content printed by the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"model_subdir: '{trainer.checkpoint_dir.name}'\")\n",
    "print(f\"model_checkpoint: 'checkpoint-epoch{trainer.epochs}.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"exp_run_sys_dep_file\" in exp:\n",
    "    print(f'The text above to be put into \\n the system dependent experiment run file {exp[\"exp_run_sys_dep_file\"]}')\n",
    "else:\n",
    "    print(f'As the system dependent experiment run file does not exist,\\n the text can be put into the system independent file\\n {exp[\"exp_run_sys_indep_file\"]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
